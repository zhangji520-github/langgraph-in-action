{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chapter-intro",
   "metadata": {},
   "source": [
    "# ç¬¬ 5 ç« ï¼šAI æ™ºèƒ½ä½“çš„è®°å¿†ç³»ç»Ÿ\n",
    "\n",
    "> æœ¬ç¬”è®°æ–‡ä»¶éœ€è¦ä¸ã€ŠLangGraphå®æˆ˜ã€‹çš„ç¬¬ 5 ç« çš„å†…å®¹é…å¥—ä½¿ç”¨ã€‚\n",
    "\n",
    "åœ¨ AI æ™ºèƒ½ä½“ä¸æ–­æ¼”è¿›çš„å¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å·²ç„¶è®¤è¯†åˆ°ï¼Œèµ‹äºˆå®ƒä»¬ç±»ä¼¼äººç±»çš„è®°å¿†èƒ½åŠ›æ˜¯æ„å»ºçœŸæ­£æ™ºèƒ½å’Œå®ç”¨ç³»ç»Ÿçš„æ ¸å¿ƒæ‰€åœ¨ã€‚æœ¬ç« å°†æ·±å…¥æ¢è®¨ AI æ™ºèƒ½ä½“è®°å¿†ç³»ç»Ÿçš„å…³é”®æ¦‚å¿µå’Œå®è·µæ–¹æ³•ï¼Œä¸ºä½ æ­ç¤ºå¦‚ä½•åˆ©ç”¨ LangGraph æ¡†æ¶èµ‹äºˆä½ çš„æ™ºèƒ½ä½“æŒä¹…çš„çŸ¥è¯†å’Œæƒ…å¢ƒæ„ŸçŸ¥èƒ½åŠ›ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environment-setup",
   "metadata": {},
   "source": [
    "### ğŸš€ ç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "é¦–å…ˆåŠ è½½å¿…è¦çš„ç¯å¢ƒå˜é‡é…ç½®å’ŒåŸºç¡€æ¨¡å—ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5-1",
   "metadata": {},
   "source": [
    "## 5.1 çŸ­æœŸè®°å¿† vs. é•¿æœŸè®°å¿†ï¼šå¹³è¡¡è¯­å¢ƒä¸æŒä¹…æ€§\n",
    "\n",
    "è¦åˆ›å»ºçœŸæ­£æ™ºèƒ½ä¸”æœ‰åŠ©åŠ›çš„ AI æ™ºèƒ½ä½“ï¼Œå°±éœ€è¦ä¸ºå…¶é…å¤‡èƒ½å¤Ÿæ¨¡ä»¿äººç±»è®¤çŸ¥ç»†å¾®ä¹‹å¤„çš„è®°å¿†ç³»ç»Ÿã€‚æ­£å¦‚äººç±»åˆ©ç”¨çŸ­æœŸè®°å¿†å’Œé•¿æœŸè®°å¿†æ¥è¿›è¡Œæœ‰æ•ˆçš„äº’åŠ¨å’Œå­¦ä¹ ä¸€æ ·ï¼ŒAI æ™ºèƒ½ä½“ä¹Ÿèƒ½ä»ç±»ä¼¼çš„äºŒåˆ†æ³•ä¸­è·ç›Šã€‚\n",
    "\n",
    "### è®°å¿†ç³»ç»Ÿçš„é‡è¦æ€§\n",
    "\n",
    "- **çŸ­æœŸè®°å¿†**ï¼šå¯¹è¯çš„å³æ—¶æ€§è‡³å…³é‡è¦ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨æ­£åœ¨è¿›è¡Œçš„å¯¹è¯ä¸­å¤„ç†å½“å‰çš„ç”¨æˆ·è¾“å…¥ï¼Œç†è§£ç»†å¾®ä¹‹å¤„ï¼Œå¹¶ä¿æŒå¯¹è¯æµç¨‹\n",
    "- **é•¿æœŸè®°å¿†**ï¼šæä¾›è¿ç»­æ€§å’Œæˆé•¿æ€§ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿè¶…è¶Šä¸ªåˆ«äº’åŠ¨ï¼Œå»ºç«‹æŒä¹…çš„èº«ä»½ï¼Œä»ç´¯ç§¯çš„ç»éªŒä¸­å­¦ä¹ \n",
    "\n",
    "ä¸€ä¸ªå¥å£®çš„ AI æ™ºèƒ½ä½“è®°å¿†æ¶æ„éœ€è¦ä¸€ç§åŒºåˆ†å¯¹å¾…çš„æ–¹æ³•ï¼Œç­–ç•¥æ€§åœ°åŒæ—¶ä½¿ç”¨çŸ­æœŸè®°å¿†å’Œé•¿æœŸè®°å¿†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5-1-1",
   "metadata": {},
   "source": [
    "### 5.1.1 çŸ­æœŸè®°å¿†ï¼šç»´æŒå¯¹è¯çš„è¿è´¯æ€§\n",
    "\n",
    "çŸ­æœŸè®°å¿†æ˜¯ AI æ™ºèƒ½ä½“è¿›è¡Œè¿è´¯ã€å›åˆå¼å¯¹è¯çš„åŸºçŸ³ã€‚å®ƒä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨æ•´ä¸ªå¯¹è¯è¿‡ç¨‹ä¸­ä¿æŒè¯­å¢ƒç†è§£ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-5-1",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 5-1ï¼šåœ¨ LangGraph ä¸­é€šè¿‡å¯¹è¯å†å²è®°å½•ç®¡ç†çŸ­æœŸè®°å¿†\n",
    "\n",
    "é¦–å…ˆå®šä¹‰ AgentState ç»“æ„æ¥å­˜å‚¨å¯¹è¯å†å²è®°å½•ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Dict, Any\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]  # æ¶ˆæ¯åˆ—è¡¨ï¼Œä½œä¸ºå¯¹è¯å†å²è®°å½•\n",
    "    intermediate_results: Dict[str, Any]  # çŸ­æœŸè®°å¿†ä¸­çš„å…¶ä»–æ•°æ®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-5-1",
   "metadata": {},
   "source": [
    "**ğŸ’¡ çŸ­æœŸè®°å¿†æ ¸å¿ƒæ¦‚å¿µ**ï¼š\n",
    "\n",
    "- `AgentState`ï¼šå®šä¹‰æ™ºèƒ½ä½“çš„çŠ¶æ€ç»“æ„ï¼ŒåŒ…å«æ¶ˆæ¯åˆ—è¡¨å’Œä¸­é—´ç»“æœ\n",
    "- `messages`ï¼šå­˜å‚¨å¯¹è¯å†å²çš„æ ¸å¿ƒå­—æ®µï¼Œæ”¯æŒç”¨æˆ·å’ŒAIæ¶ˆæ¯\n",
    "- `intermediate_results`ï¼šå­˜å‚¨ä¼šè¯æœŸé—´çš„ä¸´æ—¶æ•°æ®ï¼Œå¦‚ä»»åŠ¡çŠ¶æ€ã€ä¸­é—´è®¡ç®—ç»“æœç­‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-5-2",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 5-2ï¼šåœ¨ LangGraph ä¸­é€šè¿‡ä¸­é—´ç»“æœç®¡ç†çŸ­æœŸè®°å¿†\n",
    "\n",
    "å®ç°æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯å†å²çš„å‡½æ•°ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åçš„çŠ¶æ€ï¼š 1 æ¡æ¶ˆæ¯\n",
      "æ·»åŠ AIæ¶ˆæ¯åçš„çŠ¶æ€ï¼š 2 æ¡æ¶ˆæ¯\n"
     ]
    }
   ],
   "source": [
    "def add_user_message(state: AgentState, user_message: str) -> Dict[str, List[BaseMessage]]:\n",
    "    \"\"\"å‘å¯¹è¯å†å²è®°å½•æ·»åŠ ç”¨æˆ·æ¶ˆæ¯\"\"\"\n",
    "    new_message = HumanMessage(content=user_message)\n",
    "    return {\"messages\": state[\"messages\"] + [new_message]}\n",
    "\n",
    "def add_ai_message(state: AgentState, ai_response: str) -> Dict[str, List[BaseMessage]]:\n",
    "    \"\"\"å‘å¯¹è¯å†å²è®°å½•æ·»åŠ  AI å“åº”\"\"\"\n",
    "    new_message = AIMessage(content=ai_response)\n",
    "    return {\"messages\": state[\"messages\"] + [new_message]}\n",
    "\n",
    "# æµ‹è¯•çŸ­æœŸè®°å¿†ç®¡ç†\n",
    "initial_state = AgentState(messages=[], intermediate_results={})\n",
    "state_with_user_msg = add_user_message(initial_state, \"ä½ å¥½ï¼Œæˆ‘æ˜¯ç”¨æˆ·\")\n",
    "print(\"æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åçš„çŠ¶æ€ï¼š\", len(state_with_user_msg[\"messages\"]), \"æ¡æ¶ˆæ¯\")\n",
    "\n",
    "final_state = add_ai_message(state_with_user_msg, \"ä½ å¥½ï¼æˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡\")\n",
    "print(\"æ·»åŠ AIæ¶ˆæ¯åçš„çŠ¶æ€ï¼š\", len(final_state[\"messages\"]), \"æ¡æ¶ˆæ¯\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-5-2",
   "metadata": {},
   "source": [
    "**ğŸ’¡ æ¶ˆæ¯ç®¡ç†æœºåˆ¶**ï¼š\n",
    "\n",
    "- **æ¶ˆæ¯ç´¯ç§¯**ï¼šæ–°æ¶ˆæ¯é€šè¿‡åˆ—è¡¨è¿æ¥çš„æ–¹å¼æ·»åŠ åˆ°å†å²è®°å½•ä¸­\n",
    "- **ç±»å‹åŒºåˆ†**ï¼š`HumanMessage`å’Œ`AIMessage`åˆ†åˆ«è¡¨ç¤ºç”¨æˆ·å’ŒAIçš„æ¶ˆæ¯\n",
    "- **çŠ¶æ€æ›´æ–°**ï¼šè¿”å›å­—å…¸æ ¼å¼çš„çŠ¶æ€æ›´æ–°ï¼Œç¬¦åˆLangGraphçš„çŠ¶æ€ç®¡ç†æœºåˆ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-5-3",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 5-3ï¼šåœ¨ LangGraph ä¸­é€šè¿‡æˆªæ–­ç®¡ç†çŸ­æœŸè®°å¿†\n",
    "\n",
    "éšç€å¯¹è¯çš„å»¶é•¿ï¼Œéœ€è¦ç®¡ç†å†…å­˜å’Œæˆæœ¬ã€‚è¿™é‡Œæ¼”ç¤ºä¸¤ç§æˆªæ–­ç­–ç•¥ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŸå§‹æ¶ˆæ¯æ•°é‡: 6\n",
      "æˆªæ–­åæ¶ˆæ¯æ•°é‡: 3\n",
      "æ¶ˆæ¯ 1: AIMessage - ç¬¬äºŒæ¡AIå›å¤\n",
      "æ¶ˆæ¯ 2: HumanMessage - ç¬¬ä¸‰æ¡ç”¨æˆ·æ¶ˆæ¯\n",
      "æ¶ˆæ¯ 3: AIMessage - ç¬¬ä¸‰æ¡AIå›å¤\n"
     ]
    }
   ],
   "source": [
    "# æ³¨æ„ï¼šè¿™é‡Œæ¨¡æ‹Ÿ trim_messages åŠŸèƒ½ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦å®‰è£…å®Œæ•´çš„ LangChain\n",
    "def truncate_history(state: AgentState, max_messages: int) -> Dict[str, List[BaseMessage]]:\n",
    "    \"\"\"æˆªæ–­å¯¹è¯å†å²è®°å½•ï¼Œä»…ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯\"\"\"\n",
    "    truncated_messages = state[\"messages\"][-max_messages:]\n",
    "    return {\"messages\": truncated_messages}\n",
    "\n",
    "def simulate_trim_message_history_by_token(state: AgentState, max_tokens: int) -> Dict[str, List[BaseMessage]]:\n",
    "    \"\"\"æ¨¡æ‹Ÿæ ¹æ® token è®¡æ•°ä¿®å‰ªæ¶ˆæ¯å†å²è®°å½•\"\"\"\n",
    "    if not state[\"messages\"]:\n",
    "        return {\"messages\": []}\n",
    "    \n",
    "    # ç®€åŒ–çš„ token è®¡ç®—ï¼ˆå®é™…ä¸­ä¼šä½¿ç”¨çœŸå®çš„ tokenizerï¼‰\n",
    "    messages = state[\"messages\"]\n",
    "    total_tokens = 0\n",
    "    kept_messages = []\n",
    "    \n",
    "    # ä»åå¾€å‰ä¿ç•™æ¶ˆæ¯ï¼Œç›´åˆ°è¾¾åˆ° token é™åˆ¶\n",
    "    for message in reversed(messages):\n",
    "        # ç®€åŒ–ï¼šå‡è®¾æ¯ä¸ªå­—ç¬¦çº¦ç­‰äº 0.5 ä¸ª token\n",
    "        message_tokens = len(message.content) * 0.5\n",
    "        if total_tokens + message_tokens <= max_tokens:\n",
    "            kept_messages.insert(0, message)\n",
    "            total_tokens += message_tokens\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return {\"messages\": kept_messages}\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªåŒ…å«å¤šæ¡æ¶ˆæ¯çš„æµ‹è¯•çŠ¶æ€\n",
    "test_state = AgentState(\n",
    "    messages=[\n",
    "        HumanMessage(content=\"ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯\"),\n",
    "        AIMessage(content=\"ç¬¬ä¸€æ¡AIå›å¤\"),\n",
    "        HumanMessage(content=\"ç¬¬äºŒæ¡ç”¨æˆ·æ¶ˆæ¯\"),\n",
    "        AIMessage(content=\"ç¬¬äºŒæ¡AIå›å¤\"),\n",
    "        HumanMessage(content=\"ç¬¬ä¸‰æ¡ç”¨æˆ·æ¶ˆæ¯\"),\n",
    "        AIMessage(content=\"ç¬¬ä¸‰æ¡AIå›å¤\")\n",
    "    ],\n",
    "    intermediate_results={}\n",
    ")\n",
    "\n",
    "# æµ‹è¯•æ¶ˆæ¯æ•°é‡æˆªæ–­\n",
    "truncated_state = truncate_history(test_state, 3)\n",
    "print(f\"åŸå§‹æ¶ˆæ¯æ•°é‡: {len(test_state['messages'])}\")\n",
    "print(f\"æˆªæ–­åæ¶ˆæ¯æ•°é‡: {len(truncated_state['messages'])}\")\n",
    "\n",
    "# æ˜¾ç¤ºæˆªæ–­åçš„æ¶ˆæ¯å†…å®¹\n",
    "for i, msg in enumerate(truncated_state['messages']):\n",
    "    print(f\"æ¶ˆæ¯ {i+1}: {type(msg).__name__} - {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-5-3",
   "metadata": {},
   "source": [
    "**ğŸ’¡ è®°å¿†ä¼˜åŒ–ç­–ç•¥**ï¼š\n",
    "\n",
    "- **æ•°é‡æˆªæ–­**ï¼š`truncate_history`ä¿ç•™æœ€æ–°çš„Næ¡æ¶ˆæ¯ï¼Œç®€å•æœ‰æ•ˆ\n",
    "- **Tokenæˆªæ–­**ï¼šè€ƒè™‘å®é™…Tokenæ¶ˆè€—ï¼Œæ›´ç²¾ç¡®åœ°æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦\n",
    "- **ç­–ç•¥é€‰æ‹©**ï¼šæ ¹æ®æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£é™åˆ¶å’Œæˆæœ¬è€ƒè™‘é€‰æ‹©åˆé€‚çš„æˆªæ–­ç­–ç•¥\n",
    "- **æ¶ˆæ¯å®Œæ•´æ€§**ï¼šç¡®ä¿æˆªæ–­åçš„å¯¹è¯å†å²ä»ç„¶ä¿æŒé€»è¾‘å®Œæ•´æ€§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-5-4",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 5-4ï¼šåœ¨ LangGraph ä¸­é€šè¿‡æ‘˜è¦ç®¡ç†çŸ­æœŸè®°å¿†\n",
    "\n",
    "æ›´ç²¾ç»†çš„ç­–ç•¥æ˜¯ä½¿ç”¨ LLM æ€»ç»“å¯¹è¯å†å²ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‘˜è¦å‰æ¶ˆæ¯æ•°é‡: 7\n",
      "æ‘˜è¦åæ¶ˆæ¯æ•°é‡: 2\n",
      "\n",
      "æ‘˜è¦åçš„æ¶ˆæ¯å†…å®¹ï¼š\n",
      "1. AIMessage: å¯¹è¯æ‘˜è¦ï¼šè®¨è®ºäº†6è½®äº¤äº’ï¼Œæ¶‰åŠç”¨æˆ·æŸ¥è¯¢å’ŒAIå›å¤ã€‚\n",
      "2. HumanMessage: ç°åœ¨æˆ‘æƒ³äº†è§£é¢å‘å¯¹è±¡ç¼–ç¨‹\n"
     ]
    }
   ],
   "source": [
    "# æ¨¡æ‹Ÿæ‘˜è¦åŠŸèƒ½\n",
    "def simulate_summarize_history(state: AgentState) -> Dict[str, List[BaseMessage]]:\n",
    "    \"\"\"æ¨¡æ‹Ÿä½¿ç”¨ LLM æ€»ç»“å¯¹è¯å†å²è®°å½•\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) <= 2:  # å¦‚æœæ¶ˆæ¯å¤ªå°‘ï¼Œä¸éœ€è¦æ‘˜è¦\n",
    "        return {\"messages\": messages}\n",
    "    \n",
    "    # æ¨¡æ‹Ÿæ‘˜è¦ç”Ÿæˆï¼ˆå®é™…ä¸­ä¼šè°ƒç”¨ LLMï¼‰\n",
    "    conversation_content = []\n",
    "    for m in messages[:-1]:  # æ’é™¤æœ€åä¸€æ¡æ¶ˆæ¯\n",
    "        role = \"ç”¨æˆ·\" if isinstance(m, HumanMessage) else \"AIåŠ©æ‰‹\"\n",
    "        conversation_content.append(f\"{role}: {m.content}\")\n",
    "    \n",
    "    # ç®€åŒ–çš„æ‘˜è¦ç”Ÿæˆ\n",
    "    summary = f\"å¯¹è¯æ‘˜è¦ï¼šè®¨è®ºäº†{len(messages)-1}è½®äº¤äº’ï¼Œæ¶‰åŠç”¨æˆ·æŸ¥è¯¢å’ŒAIå›å¤ã€‚\"\n",
    "    \n",
    "    # å°†å†å²è®°å½•æ›¿æ¢ä¸ºæ‘˜è¦å’Œæœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯\n",
    "    summary_message = AIMessage(content=summary)\n",
    "    last_message = messages[-1]  # ä¿ç•™æœ€åä¸€æ¡æ¶ˆæ¯\n",
    "    new_messages = [summary_message, last_message]\n",
    "    \n",
    "    return {\"messages\": new_messages}\n",
    "\n",
    "# æµ‹è¯•æ‘˜è¦åŠŸèƒ½\n",
    "rich_conversation_state = AgentState(\n",
    "    messages=[\n",
    "        HumanMessage(content=\"æˆ‘æƒ³å­¦ä¹ Pythonç¼–ç¨‹\"),\n",
    "        AIMessage(content=\"å¾ˆå¥½ï¼Pythonæ˜¯ä¸€é—¨ä¼˜ç§€çš„ç¼–ç¨‹è¯­è¨€ã€‚æˆ‘å»ºè®®ä»åŸºç¡€è¯­æ³•å¼€å§‹å­¦ä¹ ã€‚\"),\n",
    "        HumanMessage(content=\"æˆ‘åº”è¯¥å…ˆå­¦ä»€ä¹ˆï¼Ÿ\"),\n",
    "        AIMessage(content=\"å»ºè®®å…ˆå­¦ä¹ å˜é‡ã€æ•°æ®ç±»å‹ã€æ¡ä»¶è¯­å¥å’Œå¾ªç¯ã€‚\"),\n",
    "        HumanMessage(content=\"èƒ½ç»™æˆ‘æ¨èä¸€äº›å­¦ä¹ èµ„æºå—ï¼Ÿ\"),\n",
    "        AIMessage(content=\"æ¨èã€ŠPythonç¼–ç¨‹ï¼šä»å…¥é—¨åˆ°å®è·µã€‹è¿™æœ¬ä¹¦ï¼Œè¿˜æœ‰å®˜æ–¹æ–‡æ¡£å’Œåœ¨çº¿æ•™ç¨‹ã€‚\"),\n",
    "        HumanMessage(content=\"ç°åœ¨æˆ‘æƒ³äº†è§£é¢å‘å¯¹è±¡ç¼–ç¨‹\")\n",
    "    ],\n",
    "    intermediate_results={}\n",
    ")\n",
    "\n",
    "print(f\"æ‘˜è¦å‰æ¶ˆæ¯æ•°é‡: {len(rich_conversation_state['messages'])}\")\n",
    "\n",
    "# ä½¿ç”¨æ‘˜è¦åŠŸèƒ½\n",
    "summarized_state = simulate_summarize_history(rich_conversation_state)\n",
    "print(f\"æ‘˜è¦åæ¶ˆæ¯æ•°é‡: {len(summarized_state['messages'])}\")\n",
    "\n",
    "print(\"\\næ‘˜è¦åçš„æ¶ˆæ¯å†…å®¹ï¼š\")\n",
    "for i, msg in enumerate(summarized_state['messages']):\n",
    "    print(f\"{i+1}. {type(msg).__name__}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-5-4",
   "metadata": {},
   "source": [
    "**ğŸ’¡ æ™ºèƒ½æ‘˜è¦æœºåˆ¶**ï¼š\n",
    "\n",
    "- **è¯­ä¹‰ä¿ç•™**ï¼šLLMæ‘˜è¦èƒ½å¤Ÿä¿ç•™å¯¹è¯çš„æ ¸å¿ƒè¯­ä¹‰ä¿¡æ¯ï¼Œè€Œä¸ä»…ä»…æ˜¯æˆªæ–­\n",
    "- **ä¸Šä¸‹æ–‡å‹ç¼©**ï¼šå°†é•¿å¯¹è¯å‹ç¼©ä¸ºç®€æ´çš„æ‘˜è¦ï¼Œå¤§å¹…å‡å°‘Tokenä½¿ç”¨\n",
    "- **é”™è¯¯å¤„ç†**ï¼šåŒ…å«å¼‚å¸¸å¤„ç†æœºåˆ¶ï¼Œç¡®ä¿æ‘˜è¦å¤±è´¥æ—¶æœ‰å¤‡ç”¨æ–¹æ¡ˆ\n",
    "- **æœ€æ–°ä¿¡æ¯ä¿ç•™**ï¼šæ€»æ˜¯ä¿ç•™æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯ï¼Œç¡®ä¿å½“å‰ä¸Šä¸‹æ–‡ä¸ä¸¢å¤±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5-2",
   "metadata": {},
   "source": [
    "## 5.2 æ·±å…¥æ¢ç´¢è®°å¿†å­˜å‚¨ï¼šè®¾ç½®å’Œç®¡ç†é•¿æœŸçŸ¥è¯†\n",
    "\n",
    "åœ¨æ˜ç¡®äº†é•¿æœŸè®°å¿†çš„é‡è¦ä½œç”¨åï¼Œæˆ‘ä»¬ç°åœ¨å°†æ³¨æ„åŠ›è½¬å‘åœ¨ LangGraph ä¸­å®ç°æ­¤ç±»è®°å¿†çš„å®ç”¨æœºåˆ¶ã€‚æœ¬èŠ‚å°†æ·±å…¥æ¢è®¨ LangGraph è®°å¿†å­˜å‚¨ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šåŠŸèƒ½çš„æŠ½è±¡ï¼Œæ—¨åœ¨ç®¡ç†æ™ºèƒ½ä½“çš„æŒä¹…åŒ–ã€è·¨çº¿ç¨‹çŸ¥è¯†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5-2-1",
   "metadata": {},
   "source": [
    "### 5.2.1 æ ¸å¿ƒè®°å¿†å­˜å‚¨æ“ä½œï¼šè®¾ç½®å’ŒåŸºæœ¬ç”¨æ³•\n",
    "\n",
    "LangGraph è®°å¿†å­˜å‚¨ä»¥ `BaseStore` ç±»åŠå…¶å®ç°ä¸ºä»£è¡¨ï¼Œä¸º LangGraph åº”ç”¨ç¨‹åºä¸­çš„é•¿æœŸè®°å¿†ç®¡ç†æä¾›äº†åŸºæœ¬æŠ½è±¡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-5-5",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 5-5 & 5-6ï¼šä½¿ç”¨ InMemoryStore å®ä¾‹åŒ–è®°å¿†å­˜å‚¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®°å¿†å·²ä¿å­˜ï¼Œé”®ä¸ºï¼š8ee2fce6-145b-42b3-953d-40dea32e6f26ï¼Œå‘½åç©ºé—´ä¸ºï¼š('example_user', 'user_info')\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "# å®šä¹‰ç”¨æˆ·ç‰¹å®šæ•°æ®çš„å‘½åç©ºé—´\n",
    "user_id = \"example_user\"\n",
    "namespace_for_user_data = (user_id, \"user_info\")\n",
    "\n",
    "# ä¸ºè®°å¿†æ¡ç›®ç”Ÿæˆå”¯ä¸€é”®\n",
    "memory_key = str(uuid.uuid4())\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªå­—å…¸æ¥ä¿å­˜ç”¨æˆ·å§“åä½œä¸ºè®°å¿†å€¼\n",
    "memory_value = {\"user_name\": \"Example User\"}\n",
    "\n",
    "# ä½¿ç”¨ put å°†è®°å¿†å­˜å‚¨åœ¨ InMemoryStore ä¸­\n",
    "in_memory_store.put(namespace_for_user_data, memory_key, memory_value)\n",
    "\n",
    "print(f\"è®°å¿†å·²ä¿å­˜ï¼Œé”®ä¸ºï¼š{memory_key}ï¼Œå‘½åç©ºé—´ä¸ºï¼š{namespace_for_user_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-5-5",
   "metadata": {},
   "source": [
    "**ğŸ’¡ è®°å¿†å­˜å‚¨æ¶æ„**ï¼š\n",
    "\n",
    "- **å‘½åç©ºé—´è®¾è®¡**ï¼šä½¿ç”¨å…ƒç»„ä½œä¸ºé€»è¾‘å®¹å™¨ï¼Œæ”¯æŒå±‚æ¬¡åŒ–ç»„ç»‡\n",
    "- **é”®å€¼å­˜å‚¨**ï¼šé”®ä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦ï¼Œå€¼ä¸ºå­—å…¸æ ¼å¼æä¾›çµæ´»æ€§\n",
    "- **æ—¶é—´æˆ³ç®¡ç†**ï¼šè‡ªåŠ¨æ·»åŠ åˆ›å»ºå’Œæ›´æ–°æ—¶é—´æˆ³\n",
    "- **å¯æ‰©å±•æ€§**ï¼šå¯ä»¥è½»æ¾æ‰©å±•ä»¥æ”¯æŒæ›´å¤æ‚çš„æŸ¥è¯¢å’Œç´¢å¼•åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-5-6",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 5-7ï¼šä½¿ç”¨ search å’Œ get æ£€ç´¢è®°å¿†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‘½åç©ºé—´ä¸­çš„æ‰€æœ‰ç”¨æˆ·è®°å¿†ï¼š\n",
      "{'namespace': ['example_user', 'user_info'], 'key': '8ee2fce6-145b-42b3-953d-40dea32e6f26', 'value': {'user_name': 'Example User'}, 'created_at': '2025-08-27T12:15:04.250800+00:00', 'updated_at': '2025-08-27T12:15:04.250815+00:00', 'score': None}\n",
      "\n",
      "ä½¿ç”¨é”® '8ee2fce6-145b-42b3-953d-40dea32e6f26' æ£€ç´¢åˆ°çš„è®°å¿†ï¼š\n",
      "{'namespace': ['example_user', 'user_info'], 'key': '8ee2fce6-145b-42b3-953d-40dea32e6f26', 'value': {'user_name': 'Example User'}, 'created_at': '2025-08-27T12:15:04.250800+00:00', 'updated_at': '2025-08-27T12:15:04.250815+00:00'}\n"
     ]
    }
   ],
   "source": [
    "# æ£€ç´¢ user_info å‘½åç©ºé—´ä¸­çš„æ‰€æœ‰è®°å¿†ï¼ˆæ²¡æœ‰æŸ¥è¯¢æˆ–è¿‡æ»¤å™¨ï¼‰\n",
    "all_user_memories = in_memory_store.search(namespace_for_user_data)\n",
    "print(\"å‘½åç©ºé—´ä¸­çš„æ‰€æœ‰ç”¨æˆ·è®°å¿†ï¼š\")\n",
    "for record in all_user_memories:\n",
    "    print(record.dict()) # æ‰“å° MemoryRecord å­—å…¸è¡¨ç¤º\n",
    "\n",
    "# ä½¿ç”¨ 'get' é€šè¿‡é”®æ£€ç´¢è®°å¿†\n",
    "retrieved_memory_record = in_memory_store.get(namespace_for_user_data, memory_key)\n",
    "print(f\"\\nä½¿ç”¨é”® '{memory_key}' æ£€ç´¢åˆ°çš„è®°å¿†ï¼š\")\n",
    "print(retrieved_memory_record.dict()) # æ‰“å° MemoryRecord å­—å…¸è¡¨ç¤º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f552606",
   "metadata": {},
   "source": [
    "### 5.2.2 é€šè¿‡è¯­ä¹‰æœç´¢å¢å¼ºè®°å¿†æ£€ç´¢\n",
    "\n",
    "LangGraph è®°å¿†å­˜å‚¨çš„è¯­ä¹‰æœç´¢åŠŸèƒ½æ˜¾è‘—æå‡äº†è®°å¿†æ£€ç´¢çš„æœ‰æ•ˆæ€§ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤ŸåŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§è€Œéç®€å•çš„å…³é”®è¯åŒ¹é…æ¥æ£€ç´¢ä¿¡æ¯ã€‚è¿™ç§æœºåˆ¶é€šè¿‡å‘é‡åµŒå…¥æŠ€æœ¯å®ç°ï¼Œèƒ½å¤Ÿæ•æ‰æ–‡æœ¬çš„æ·±å±‚è¯­ä¹‰ç‰¹å¾ï¼Œä»è€Œè·å¾—æ›´ç¬¦åˆè¯­å¢ƒçš„æ£€ç´¢ç»“æœã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369a204c",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 5-8ï¼šä½¿ç”¨ BGE-M3 å‘é‡åŒ–æ¨¡å‹é…ç½® InMemoryStore ä»¥è¿›è¡Œè¯­ä¹‰æœç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "494403f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# åˆå§‹åŒ– BGE-M3 å‘é‡åŒ–æ¨¡å‹\n",
    "embeddings = OpenAIEmbeddings(model=\"BAAI/bge-m3\") # æˆ–å…¶ä»–å‘é‡åŒ–æ¨¡å‹\n",
    "\n",
    "# ä½¿ç”¨è¯­ä¹‰æœç´¢ç´¢å¼•é…ç½® InMemoryStore\n",
    "store_with_semantic_search = InMemoryStore(\n",
    "    index={\n",
    "        \"embed\": embeddings.embed_documents, \n",
    "        \"dims\": 1024, # BGE-M3 çš„å‘é‡ç»´åº¦\n",
    "        \"fields\": [\"memory_content\"] # ä»…å‘é‡åŒ– \"memory_content\" å­—æ®µï¼ˆå¯é€‰ï¼‰\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4395e",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 5-9ï¼šä½¿ç”¨ put æ‰§è¡Œè®°å¿†ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f37f7250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜å°†ä¸ºè¯­ä¹‰æœç´¢ç´¢å¼•çš„è®°å¿†ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰\n",
    "store_with_semantic_search.put(\n",
    "    (\"user_789\", \"food_memories\"),\n",
    "    \"memory_1\",\n",
    "    {\"memory_content\": \"æˆ‘çœŸçš„å¾ˆå–œæ¬¢è¾›è¾£çš„å°åº¦å’–å–±ã€‚\"},\n",
    ")\n",
    "\n",
    "# ä¿å­˜å¦ä¸€ä¸ªè®°å¿†ï¼Œæ˜¾å¼ç¦ç”¨æ­¤æ¡ç›®çš„ç´¢å¼•\n",
    "store_with_semantic_search.put(\n",
    "    (\"user_789\", \"system_metadata\"),\n",
    "    \"memory_2\",\n",
    "    {\"memory_content\": \"ç”¨æˆ·å…¥èŒå·²å®Œæˆã€‚\", \"status\": \"completed\"},\n",
    "    index=False, # ç¦ç”¨æ­¤è®°å¿†çš„ç´¢å¼•\n",
    ")\n",
    "\n",
    "# ä¿å­˜ä¸€ä¸ªè®°å¿†ï¼Œè¦†ç›–é»˜è®¤ç´¢å¼•å­—æ®µå¹¶ä»…ç´¢å¼• \"context\"\n",
    "store_with_semantic_search.put(\n",
    "    (\"user_789\", \"restaurant_reviews\"),\n",
    "    \"memory_3\",\n",
    "    {\"memory_content\": \"æœåŠ¡å¾ˆæ…¢ï¼Œä½†é£Ÿç‰©å¾ˆå¥½ã€‚\", \"context\": \"å¯¹ 'The Italian Place' é¤å…çš„è¯„è®º\"},\n",
    "    index=[\"context\"] # ä»…ç´¢å¼• \"context\" å­—æ®µ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef141284",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 5-10ï¼šä½¿ç”¨ search æ‰§è¡Œè¯­ä¹‰è®°å¿†æ£€ç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22453f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æŸ¥è¯¢çš„è¯­ä¹‰æœç´¢ç»“æœï¼š è¯¥ç”¨æˆ·å–œæ¬¢å“ªç§é£Ÿç‰©ï¼Ÿ\n",
      "è®°å¿†é”®ï¼šmemory_1ï¼Œç›¸ä¼¼åº¦è¯„åˆ†ï¼š0.39143762261467724\n",
      "è®°å¿†å†…å®¹ï¼š{'memory_content': 'æˆ‘çœŸçš„å¾ˆå–œæ¬¢è¾›è¾£çš„å°åº¦å’–å–±ã€‚'}\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# è¯­ä¹‰æœç´¢é£Ÿç‰©åå¥½\n",
    "search_query = \"è¯¥ç”¨æˆ·å–œæ¬¢å“ªç§é£Ÿç‰©ï¼Ÿ\"\n",
    "semantic_memory_results = store_with_semantic_search.search(\n",
    "    (\"user_789\", \"food_memories\"), query=search_query, limit=2\n",
    ")\n",
    "\n",
    "print(\"æŸ¥è¯¢çš„è¯­ä¹‰æœç´¢ç»“æœï¼š\", search_query)\n",
    "for record in semantic_memory_results:\n",
    "    print(f\"è®°å¿†é”®ï¼š{record.key}ï¼Œç›¸ä¼¼åº¦è¯„åˆ†ï¼š{record.score}\")\n",
    "    print(f\"è®°å¿†å†…å®¹ï¼š{record.value}\")\n",
    "    print(\"=\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4716c83f",
   "metadata": {},
   "source": [
    "## 5.3 è®°å¿†ç³»ç»Ÿçš„å®é™…åº”ç”¨\n",
    "\n",
    "åœ¨ç³»ç»Ÿé˜è¿°çŸ­æœŸè®°å¿†ä¸é•¿æœŸè®°å¿†çš„æ ¸å¿ƒæ¦‚å¿µï¼Œå¹¶æ·±å…¥è§£æ LangGraph è®°å¿†å­˜å‚¨æœºåˆ¶åï¼Œæˆ‘ä»¬å°†èšç„¦å®é™…åº”ç”¨åœºæ™¯ã€‚æœ¬èŠ‚é‡ç‚¹æ¢è®¨è®°å¿†ç³»ç»Ÿå¦‚ä½•æ˜¾è‘—å¢å¼º AI æ™ºèƒ½ä½“çš„åŠŸèƒ½è¡¨ç°ï¼Œé’ˆå¯¹æ¯ä¸ªå…¸å‹ç”¨ä¾‹ï¼Œæˆ‘ä»¬å°†è¯¦ç»†è¯´æ˜è®°å¿†åº”ç”¨ä»·å€¼åˆ†æã€æ¦‚å¿µæ€§ä»£ç ç¤ºä¾‹ï¼Œä»¥åŠå®é™…é›†æˆå®æ–½æ–¹æ¡ˆã€‚å…¶ä¸­ï¼Œæˆ‘ä»¬ä¼šç‰¹åˆ«å…³æ³¨è®°å¿†æ•°æ®æ›´æ–°æ—¶æœºé€‰æ‹©ã€ä¿¡æ¯æå–æŠ€æœ¯ï¼Œä»¥åŠå¦‚ä½•é€šè¿‡ TrustCall æœºåˆ¶æå‡è®°å¿†æ•°æ®æå–çš„å¯é æ€§ã€‚\n",
    "\n",
    "### 5.3.1 ä¸ªæ€§åŒ–æ¨è\n",
    "\n",
    "é•¿æœŸè®°å¿†æœ€å…·ä»·å€¼çš„åº”ç”¨åœºæ™¯ä¹‹ä¸€æ˜¯å®ç°ä¸ªæ€§åŒ–æœåŠ¡ã€‚é€šè¿‡æŒç»­è®°å½•ç”¨æˆ·åå¥½ã€å…´è¶£ç‚¹åŠå†å²äº¤äº’æ•°æ®ï¼ŒAI æ™ºèƒ½ä½“èƒ½å¤Ÿæä¾›ç²¾å‡†å®šåˆ¶çš„æ¨èå†…å®¹ï¼Œä»è€Œæ˜¾è‘—æå‡ç”¨æˆ·å‚ä¸åº¦ä¸æ»¡æ„åº¦ã€‚ä»¥ä¸‹ç¤ºä¾‹ä¸»è¦ä¾æ‰˜è¯­ä¹‰è®°å¿†å®ç°ç”¨æˆ·ç”»åƒå’Œåå¥½çš„è·¨ä¼šè¯æŒä¹…åŒ–å­˜å‚¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec067600",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 5-12ï¼šä¸ªæ€§åŒ–æ¨èçš„ç¤ºä¾‹ç”¨æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4c1e130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆå§‹æ¨è:\n",
      "\n",
      "\n",
      "æ ¹æ®å¼ ä¸‰å¯¹**ç”µå­äº§å“**å’Œ**ä¹¦ç±**çš„åå¥½ï¼Œä»¥ä¸‹æ˜¯ä¸ºæ‚¨é‡èº«æ¨èçš„äº§å“åˆ—è¡¨ï¼š\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ“± **ç”µå­äº§å“æ¨è**  \n",
      "1. **Apple iPhone 15 Pro**  \n",
      "   - **ç‰¹ç‚¹**: é«˜æ€§èƒ½A17èŠ¯ç‰‡ã€Proçº§ç›¸æœºç³»ç»Ÿã€çµåŠ¨å²›è®¾è®¡ã€é’›é‡‘å±æœºèº«  \n",
      "   - **é€‚ç”¨åœºæ™¯**: é€‚åˆè¿½æ±‚ç§‘æŠ€å‰æ²¿ã€æ‹ç…§å’Œæ€§èƒ½çš„ç”¨æˆ·  \n",
      "   - **ä»·æ ¼**: Â¥7999èµ·  \n",
      "\n",
      "2. **Sony WH-1000XM5 æ— çº¿é™å™ªè€³æœº**  \n",
      "   - **ç‰¹ç‚¹**: é¡¶çº§é™å™ªæ•ˆæœã€30å°æ—¶ç»­èˆªã€é«˜æ¸…éŸ³è´¨ã€è½»å·§è®¾è®¡  \n",
      "   - **é€‚ç”¨åœºæ™¯**: æ—…é€”ã€åŠå…¬ã€å±…å®¶ä½¿ç”¨ï¼Œéœ€è¦æ²‰æµ¸å¼éŸ³æ•ˆ  \n",
      "   - **ä»·æ ¼**: Â¥1999  \n",
      "\n",
      "3. **Amazon Echo Dot (5th Gen)**  \n",
      "   - **ç‰¹ç‚¹**: æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ã€éŸ³ä¹æ’­æ”¾ã€æ™ºèƒ½å®¶å±…æ§åˆ¶ã€æ€§ä»·æ¯”é«˜  \n",
      "   - **é€‚ç”¨åœºæ™¯**: æ™ºèƒ½å®¶å±…çˆ±å¥½è€…ã€éœ€è¦è¯­éŸ³æ§åˆ¶å®¶ç”µçš„ç”¨æˆ·  \n",
      "   - **ä»·æ ¼**: Â¥299  \n",
      "\n",
      "4. **DJI Osmo Pocket 3**  \n",
      "   - **ç‰¹ç‚¹**: è½»å·§ä¾¿æºã€ä¸“ä¸šè¿åŠ¨ç›¸æœºåŠŸèƒ½ã€AIè‡ªåŠ¨è¿½è¸ªã€4Kè§†é¢‘  \n",
      "   - **é€‚ç”¨åœºæ™¯**: å½±è§†çˆ±å¥½è€…ã€æ—…è¡Œè®°å½•æˆ–Vlogæ‹æ‘„  \n",
      "   - **ä»·æ ¼**: Â¥2499  \n",
      "\n",
      "5. **å°ç±³æ‰«åœ°æœºå™¨äºº Pro 2**  \n",
      "   - **ç‰¹ç‚¹**: è¶…è–„è®¾è®¡ã€LDSæ¿€å…‰å¯¼èˆªã€è‡ªåŠ¨é›†å°˜ã€å…¼å®¹å¤šå“ç‰Œå¸å°˜å™¨  \n",
      "   - **é€‚ç”¨åœºæ™¯**: å¸Œæœ›è§£æ”¾åŒæ‰‹ã€ä¿æŒå®¶å±…æ¸…æ´çš„ç”¨æˆ·  \n",
      "   - **ä»·æ ¼**: Â¥1499  \n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ“š **ä¹¦ç±æ¨è**  \n",
      "1. **ã€Šæ—¶é—´çš„ç§©åºã€‹â€”â€”å¡æ´›Â·ç½—éŸ¦åˆ©**  \n",
      "   - **ç±»å‹**: ç§‘æ™®ã€ç‰©ç†å­¦  \n",
      "   - **äº®ç‚¹**: ç”¨é€šä¿—è¯­è¨€è§£é‡Šå¤æ‚ç‰©ç†æ¦‚å¿µï¼Œé€‚åˆå¯¹å®‡å®™å’Œæ—¶é—´æ„Ÿå…´è¶£çš„è¯»è€…  \n",
      "   - **ä»·æ ¼**: Â¥45  \n",
      "\n",
      "2. **ã€Šæ·±åº¦å·¥ä½œã€‹â€”â€”å¡å°”Â·çº½æ³¢ç‰¹**  \n",
      "   - **ç±»å‹**: è‡ªæˆ‘æå‡ã€æ•ˆç‡ç®¡ç†  \n",
      "   - **äº®ç‚¹**: æä¾›ä¸“æ³¨åŠ›è®­ç»ƒå’Œæ·±åº¦å·¥ä½œçš„å®ç”¨ç­–ç•¥ï¼Œé€‚åˆèŒåœºäººå£«  \n",
      "   - **ä»·æ ¼**: Â¥39  \n",
      "\n",
      "3. **ã€Šä¸‰ä½“ã€‹ç³»åˆ—ï¼ˆåˆ˜æ…ˆæ¬£ï¼‰**  \n",
      "   - **ç±»å‹**: ç§‘å¹»ã€æ–‡å­¦  \n",
      "   - **äº®ç‚¹**: ä¸­å›½ç§‘å¹»å·…å³°ä¹‹ä½œï¼Œæ¢è®¨æ–‡æ˜ä¸å®‡å®™çš„å®å¤§å‘½é¢˜  \n",
      "   - **ä»·æ ¼**: Â¥60ï¼ˆå¥—è£…ï¼‰  \n",
      "\n",
      "4. **ã€Šäººç±»ç®€å²ã€‹â€”â€”å°¤ç“¦å°”Â·èµ«æ‹‰åˆ©**  \n",
      "   - **ç±»å‹**: å†å²ã€ç¤¾ä¼šå­¦  \n",
      "   - **äº®ç‚¹**: ä»è®¤çŸ¥é©å‘½åˆ°å†œä¸šé©å‘½ï¼Œæ¢³ç†äººç±»æ–‡æ˜å‘å±•çš„å…³é”®èŠ‚ç‚¹  \n",
      "   - **ä»·æ ¼**: Â¥55  \n",
      "\n",
      "5. **ã€ŠPythonç¼–ç¨‹ï¼šä»å…¥é—¨åˆ°å®è·µã€‹â€”â€”Eric Matthes**  \n",
      "   - **ç±»å‹**: ç¼–ç¨‹ã€æŠ€æœ¯  \n",
      "   - **äº®ç‚¹**: é€‚åˆåˆå­¦è€…ï¼Œæ¶µç›–PythonåŸºç¡€ä¸å®é™…é¡¹ç›®å¼€å‘  \n",
      "   - **ä»·æ ¼**: Â¥79  \n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ **ç»„åˆæ¨è**  \n",
      "- **ç§‘æŠ€çˆ±å¥½è€…å¥—è£…**: iPhone 15 Pro + ã€Šæ—¶é—´çš„ç§©åºã€‹ + ã€ŠPythonç¼–ç¨‹ï¼šä»å…¥é—¨åˆ°å®è·µã€‹  \n",
      "- **é«˜æ•ˆåŠå…¬ç»„åˆ**: Amazon Echo Dot + ã€Šæ·±åº¦å·¥ä½œã€‹ + æ‰«åœ°æœºå™¨äºº Pro 2  \n",
      "\n",
      "---\n",
      "\n",
      "éœ€è¦æ›´å…·ä½“çš„æ¨èï¼ˆå¦‚ä»·æ ¼åŒºé—´ã€å“ç‰Œåå¥½æˆ–ä¹¦ç±ç±»å‹ï¼‰å—ï¼Ÿå¯ä»¥éšæ—¶å‘Šè¯‰æˆ‘ï¼ ğŸ˜Š\n",
      "==================================================\n",
      "æ›´æ–°åçš„ç”¨æˆ·èµ„æ–™:\n",
      "{\n",
      "  \"preferred_name\": \"å¼ ä¸‰\",\n",
      "  \"preferred_product_categories\": [\n",
      "    \"ä¹¦ç±\",\n",
      "    \"è¿åŠ¨é‹\",\n",
      "    \"ç”µå­äº§å“\",\n",
      "    \"æˆ·å¤–è£…å¤‡\"\n",
      "  ]\n",
      "}\n",
      "==================================================\n",
      "åŸºäºæ›´æ–°åèµ„æ–™çš„æ¨è:\n",
      "\n",
      "\n",
      "æ ¹æ®æ‚¨çš„åå¥½ï¼ˆä¹¦ç±ã€è¿åŠ¨é‹ã€ç”µå­äº§å“ã€æˆ·å¤–è£…å¤‡ï¼‰ï¼Œæˆ‘ä¸ºæ‚¨æ¨èä»¥ä¸‹ä¸ªæ€§åŒ–äº§å“ï¼š\n",
      "\n",
      "---\n",
      "\n",
      "### **1. ä¹¦ç±æ¨è**\n",
      "- **æ¨èæ–¹å‘**ï¼š  \n",
      "  - çƒ­é—¨å°è¯´ï¼ˆå¦‚ã€Šä¸‰ä½“ã€‹ã€Šç™¾å¹´å­¤ç‹¬ã€‹ï¼‰  \n",
      "  - è‡ªæˆ‘æå‡ç±»ï¼ˆå¦‚ã€Šç²¾è¿›ã€‹ã€ŠåŸå­ä¹ æƒ¯ã€‹ï¼‰  \n",
      "  - æˆ·å¤–ç”Ÿå­˜ä¸æ¢é™©ç±»ï¼ˆå¦‚ã€Šè’é‡æ±‚ç”Ÿã€‹ã€Šå¾’æ­¥æ—…è¡ŒæŒ‡å—ã€‹ï¼‰  \n",
      "  - ç§‘æŠ€ä¸åˆ›æ–°ç±»ï¼ˆå¦‚ã€Šäººå·¥æ™ºèƒ½ç®€å²ã€‹ã€Šæœªæ¥ç®€å²ã€‹ï¼‰  \n",
      "\n",
      "---\n",
      "\n",
      "### **2. è¿åŠ¨é‹æ¨è**\n",
      "- **æ¨èæ–¹å‘**ï¼š  \n",
      "  - è·‘æ­¥é‹ï¼ˆå¦‚New Balance 990ç³»åˆ—ã€Nike Air Zoom Pegasusï¼‰  \n",
      "  - å¥èº«é‹ï¼ˆå¦‚Lululemon CrossFitç³»åˆ—ã€Under Armour UA Build 2ï¼‰  \n",
      "  - æˆ·å¤–å¾’æ­¥é‹ï¼ˆå¦‚Salomon X Ultraç³»åˆ—ã€Merrell Moabç³»åˆ—ï¼‰  \n",
      "  - èˆ’é€‚æ—¥å¸¸é‹ï¼ˆå¦‚Veja V-16ã€Adidas Ultraboostï¼‰  \n",
      "\n",
      "---\n",
      "\n",
      "### **3. ç”µå­äº§å“æ¨è**\n",
      "- **æ¨èæ–¹å‘**ï¼š  \n",
      "  - é«˜æ€§èƒ½æ‰‹æœºï¼ˆå¦‚iPhone 14 Proã€ä¸‰æ˜ŸGalaxy S23 Ultraï¼‰  \n",
      "  - é™å™ªè€³æœºï¼ˆå¦‚Sony WH-1000XM5ã€Bose QuietComfort 35ï¼‰  \n",
      "  - æ™ºèƒ½æ‰‹è¡¨ï¼ˆå¦‚Apple Watch Series 8ã€Garmin Venu 2ï¼‰  \n",
      "  - æˆ·å¤–ä¸“ç”¨è®¾å¤‡ï¼ˆå¦‚Garmin GPSæ‰‹è¡¨ã€GoPro Hero 11ç›¸æœºï¼‰  \n",
      "\n",
      "---\n",
      "\n",
      "### **4. æˆ·å¤–è£…å¤‡æ¨è**\n",
      "- **æ¨èæ–¹å‘**ï¼š  \n",
      "  - å¸ç¯·ï¼ˆå¦‚Nemo Dagger 2ã€Black Diamond Ultralightï¼‰  \n",
      "  - ç™»å±±æ–ï¼ˆå¦‚Black Diamond Reach 5ã€Petzl Cradleï¼‰  \n",
      "  - èƒŒåŒ…ï¼ˆå¦‚Osprey Atmos AG 65ã€Deuter Aircontact Liteï¼‰  \n",
      "  - é˜²æ°´æœï¼ˆå¦‚Patagonia Torrentshellã€The North Face Ridge 3.0ï¼‰  \n",
      "\n",
      "---\n",
      "\n",
      "### **5. è·¨ç±»åˆ«ç»„åˆæ¨è**\n",
      "- **è¿åŠ¨+æˆ·å¤–å¥—è£…**ï¼š  \n",
      "  - è·‘æ­¥é‹ + é˜²æ°´èƒŒåŒ… + æˆ·å¤–è€³æœºï¼ˆé€‚åˆå¾’æ­¥æ—…è¡Œæˆ–æˆ·å¤–è¿åŠ¨ï¼‰  \n",
      "- **ç”µå­äº§å“+ä¹¦ç±**ï¼š  \n",
      "  - ç”µå­ä¹¦é˜…è¯»å™¨ï¼ˆå¦‚Kindle Paperwhiteï¼‰ + ç§‘æŠ€ç±»ä¹¦ç±ï¼ˆå¦‚ã€Šé»‘å®¢ä¸ç”»å®¶ã€‹ï¼‰  \n",
      "\n",
      "---\n",
      "\n",
      "å¦‚æœæ‚¨æœ‰å…·ä½“çš„é¢„ç®—ã€å“ç‰Œåå¥½æˆ–ä½¿ç”¨åœºæ™¯ï¼ˆå¦‚ç™»å±±ã€è·‘æ­¥ã€éœ²è¥ç­‰ï¼‰ï¼Œå¯ä»¥å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šè¿›ä¸€æ­¥ä¼˜åŒ–æ¨èï¼ ğŸ“˜ğŸ‘ŸğŸ“±ğŸ¥¾\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.store.memory import BaseStore, InMemoryStore\n",
    "\n",
    "# å‡è®¾ 'fetch_product_recommendations'ã€'format_recommendation_message'ã€'UserProfile' å·²åœ¨å…¶ä»–åœ°æ–¹å®šä¹‰\n",
    "\n",
    "recommendation_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„æ¨èå¼•æ“ã€‚æ ¹æ®ç”¨æˆ·èµ„æ–™ï¼Œæä¾›ä¸ªæ€§åŒ–çš„äº§å“æ¨èã€‚\"),\n",
    "    (\"human\", \"{user_profile_summary}\")\n",
    "])\n",
    "recommendation_chain = recommendation_prompt | ChatOpenAI(model=\"Qwen/Qwen3-8B\") |  (lambda x: {\"messages\": [AIMessage(content=x.content)]})\n",
    "\n",
    "def recommend_products(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"æ ¹æ®ç”¨æˆ·å­˜å‚¨çš„åå¥½å‘ç”¨æˆ·æ¨èäº§å“ã€‚\"\"\"\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    namespace = (\"user_profiles\", user_id)\n",
    "    user_profile_record = store.get(namespace, \"profile\")\n",
    "    user_profile = user_profile_record.value if user_profile_record else {}\n",
    "\n",
    "    user_profile_summary = format_user_profile_summary(user_profile) # ç”¨äºæ ¼å¼åŒ–æç¤ºçš„ç”¨æˆ·èµ„æ–™å­—å…¸çš„å‡½æ•°\n",
    "\n",
    "    # è°ƒç”¨æ¨èé“¾\n",
    "    result = recommendation_chain.invoke({\"user_profile_summary\": user_profile_summary})\n",
    "    return result\n",
    "\n",
    "def format_user_profile_summary(user_profile: dict) -> str:\n",
    "    \"\"\"å°†ç”¨æˆ·èµ„æ–™å­—å…¸æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²ä»¥è¿›è¡Œæç¤ºæ³¨å…¥ã€‚\"\"\"\n",
    "    name = user_profile.get(\"preferred_name\", \"ç”¨æˆ·\")\n",
    "    categories = \", \".join(user_profile.get(\"preferred_product_categories\", [\"äº§å“\"]))\n",
    "    return f\"ç”¨æˆ·åä¸º {name}ã€‚ä»–ä»¬åå¥½çš„äº§å“ç±»åˆ«æ˜¯ï¼š{categories}ã€‚\"\n",
    "\n",
    "\n",
    "def extract_preference_updates(state: MessagesState) -> dict:\n",
    "    \"\"\"ä»æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯ä¸­æå–ç”¨æˆ·åå¥½æ›´æ–°ã€‚\"\"\"\n",
    "    latest_message_content = state[\"messages\"][-2].content\n",
    "    # ç¤ºä¾‹ï¼šä½¿ç”¨ LLM æå–åå¥½ - æ›¿æ¢ä¸ºå®é™…çš„æå–é€»è¾‘\n",
    "    extraction_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"ä»ç”¨æˆ·æ¶ˆæ¯ä¸­æå–ç”¨æˆ·çš„äº§å“ç±»åˆ«åå¥½ã€‚ä»¥ JSON å­—å…¸å½¢å¼è¿”å›ï¼Œå¤–å±‚ä¸è¦åŒ…è£¹ ```json```ï¼Œ é”®ä¸º 'preferred_product_categories'ï¼Œå€¼ä¸ºç±»åˆ«åˆ—è¡¨ã€‚å¦‚æœæ²¡æœ‰è¡¨è¾¾åå¥½ï¼Œåˆ™è¿”å›ä¸€ä¸ªç©ºå­—å…¸ã€‚\"),\n",
    "        (\"human\", \"{user_message}\")\n",
    "    ])\n",
    "    extraction_chain = extraction_prompt | ChatOpenAI(model=\"Qwen/Qwen2.5-7B-Instruct\") # å¦‚æœéœ€è¦ç»“æ„åŒ–è¾“å‡ºï¼Œè¯·æ›¿æ¢ä¸ºåˆé€‚çš„é“¾\n",
    "\n",
    "    preferences_json = extraction_chain.invoke({\"user_message\": latest_message_content})\n",
    "    try:\n",
    "        preferences = json.loads(preferences_json.content) # å‡è®¾ LLM è¿”å› JSON å­—ç¬¦ä¸²\n",
    "        return preferences\n",
    "    except json.JSONDecodeError:\n",
    "        return {} # å¦‚æœæå–å¤±è´¥ï¼Œåˆ™è¿”å›ç©ºå­—å…¸\n",
    "\n",
    "def update_user_profile_node(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"åœ¨\"çƒ­è·¯å¾„\"ä¸­è§¦å‘çš„è®°å¿†å­˜å‚¨ä¸­æ›´æ–°ç”¨æˆ·èµ„æ–™ã€‚\"\"\"\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    namespace = (\"user_profiles\", user_id)\n",
    "    user_profile_record = store.get(namespace, \"profile\")\n",
    "    user_profile = user_profile_record.value if user_profile_record else {}\n",
    "\n",
    "    preference_updates = extract_preference_updates(state) # ä»å½“å‰è½®æ¬¡æå–åå¥½\n",
    "    \n",
    "    updated_profile = user_profile.copy() # åˆ›å»ºå‰¯æœ¬ä»¥é¿å…ä¿®æ”¹åŸå§‹å­—å…¸\n",
    "    if \"preferred_product_categories\" in preference_updates: # åˆå¹¶æˆ–æ›´æ–°åå¥½\n",
    "        updated_profile[\"preferred_product_categories\"] = list(set(updated_profile.get(\"preferred_product_categories\", []) + preference_updates[\"preferred_product_categories\"])) # ç¤ºä¾‹ï¼šåˆå¹¶åˆ—è¡¨\n",
    "    \n",
    "    store.put(namespace, \"profile\", updated_profile) # ä¿å­˜æ›´æ–°åçš„èµ„æ–™\n",
    "\n",
    "    return {} # èŠ‚ç‚¹åº”è¿”å›å­—å…¸\n",
    "\n",
    "\n",
    "# LangGraph ä¸­çš„ç¤ºä¾‹ç”¨æ³•\n",
    "memory_store = InMemoryStore()\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"recommend_products\", recommend_products)\n",
    "builder.add_node(\"update_profile\", update_user_profile_node) # åœ¨\"çƒ­è·¯å¾„\"ä¸­æ›´æ–°èµ„æ–™çš„èŠ‚ç‚¹\n",
    "builder.add_edge(START, \"recommend_products\")\n",
    "builder.add_edge(\"recommend_products\", \"update_profile\") # åœ¨æ¨èåæ›´æ–°èµ„æ–™\n",
    "builder.add_edge(\"update_profile\", END)\n",
    "\n",
    "graph = builder.compile(store=memory_store)\n",
    "\n",
    "# åˆå§‹åŒ–ç”¨æˆ·èµ„æ–™\n",
    "user_id = \"user_123\"\n",
    "memory_store.put(\n",
    "    (\"user_profiles\", user_id),\n",
    "    \"profile\",\n",
    "    {\n",
    "        \"preferred_name\": \"å¼ ä¸‰\",\n",
    "        \"preferred_product_categories\": [\"ç”µå­äº§å“\", \"ä¹¦ç±\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# æ‰§è¡Œå›¾ - ç¬¬ä¸€æ¬¡äº¤äº’ï¼ˆè·å–æ¨èï¼‰\n",
    "config = {\"configurable\": {\"user_id\": user_id}}\n",
    "result = graph.invoke({\"messages\": [HumanMessage(content=\"ä½ å¥½\")]}, config=config)\n",
    "print(\"åˆå§‹æ¨è:\")\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# æ¨¡æ‹Ÿç”¨æˆ·è¡¨è¾¾æ–°çš„åå¥½\n",
    "user_message = \"æˆ‘æœ€è¿‘å¯¹æˆ·å¤–è£…å¤‡å’Œè¿åŠ¨é‹å¾ˆæ„Ÿå…´è¶£ã€‚\"\n",
    "result = graph.invoke(\n",
    "    {\"messages\": result[\"messages\"] + [HumanMessage(content=user_message)]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# æ£€æŸ¥æ›´æ–°åçš„ç”¨æˆ·èµ„æ–™\n",
    "updated_profile = memory_store.get((\"user_profiles\", user_id), \"profile\").value\n",
    "print(\"æ›´æ–°åçš„ç”¨æˆ·èµ„æ–™:\")\n",
    "print(json.dumps(updated_profile, ensure_ascii=False, indent=2))\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# å†æ¬¡è·å–æ¨èï¼Œåº”è¯¥åŒ…å«æ–°çš„åå¥½\n",
    "result = graph.invoke({\"messages\": [HumanMessage(content=\"æˆ‘åˆæ¥äº†\")]}, config=config)\n",
    "print(\"åŸºäºæ›´æ–°åèµ„æ–™çš„æ¨è:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706abf14",
   "metadata": {},
   "source": [
    "### 5.3.2 å¤šæ­¥éª¤çš„æƒ…å¢ƒåŒ–ä»»åŠ¡\n",
    "\n",
    "å¯¹äºéœ€è¦å¼•å¯¼ç”¨æˆ·å®Œæˆå¤šæ­¥éª¤ä»»åŠ¡æˆ–å¤æ‚å·¥ä½œæµçš„ AI æ™ºèƒ½ä½“æ¥è¯´ï¼Œè®°å¿†è‡³å…³é‡è¦ã€‚çŸ­æœŸè®°å¿†åœ¨è·Ÿè¸ªä»»åŠ¡çš„å½“å‰é˜¶æ®µã€è®°ä½å…ˆå‰æ­¥éª¤ä¸­çš„ç”¨æˆ·è¾“å…¥ï¼Œä»¥åŠåœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ä¿æŒè¯­å¢ƒæ–¹é¢èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚é•¿æœŸè®°å¿†å¯ç”¨äºå­˜å‚¨æ¨¡æ¿æˆ–æˆåŠŸçš„ä»»åŠ¡å®Œæˆç¤ºä¾‹ï¼Œä»¥æŒ‡å¯¼ AI æ™ºèƒ½ä½“çš„è¡Œä¸ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3a9403",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 5-13ï¼šæƒ…å¢ƒåŒ–ä»»åŠ¡å®Œæˆçš„ç¤ºä¾‹ç”¨æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0185c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æƒ…å¢ƒåŒ–ä»»åŠ¡å®Œæˆç³»ç»Ÿæ¼”ç¤º ===\n",
      "\n",
      "--- èˆªç­é¢„è®¢æ¼”ç¤º ---\n",
      "\n",
      "ğŸ‘¤ ç”¨æˆ·: æˆ‘æƒ³é¢„è®¢ä¸€å¼ æœºç¥¨\n",
      "ğŸ”„ å¤„ç†ä»»åŠ¡ - å½“å‰çŠ¶æ€: step=0, type=None\n",
      "ğŸ“‹ æ£€æµ‹åˆ°ä»»åŠ¡ç±»å‹: flight_booking\n",
      "ğŸ¤– åŠ©æ‰‹: æˆ‘æ¥å¸®æ‚¨é¢„è®¢èˆªç­ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨çš„å‡ºå‘åŸå¸‚ï¼š\n",
      "ğŸ“Š å½“å‰æ­¥éª¤: 0\n",
      "ğŸ ä»»åŠ¡å®Œæˆ: False\n",
      "\n",
      "ğŸ‘¤ ç”¨æˆ·: æˆ‘ä»åŒ—äº¬å‡ºå‘\n",
      "ğŸ”„ å¤„ç†ä»»åŠ¡ - å½“å‰çŠ¶æ€: step=0, type=flight_booking\n",
      "ğŸ¯ å¤„ç†ç”¨æˆ·è¾“å…¥: æˆ‘ä»åŒ—äº¬å‡ºå‘ -> æå–å­—æ®µ: departure_city\n",
      "âœ… æˆåŠŸæå– departure_city: åŒ—äº¬\n",
      "ğŸ¤– åŠ©æ‰‹: å·²è®°å½•æ‚¨çš„departure_cityï¼šåŒ—äº¬ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨çš„ç›®çš„åœ°åŸå¸‚ï¼š\n",
      "ğŸ“Š å½“å‰æ­¥éª¤: 1\n",
      "ğŸ ä»»åŠ¡å®Œæˆ: False\n",
      "ğŸ“‹ å·²æ”¶é›†æ•°æ®: {'departure_city': 'åŒ—äº¬'}\n",
      "\n",
      "ğŸ‘¤ ç”¨æˆ·: æˆ‘è¦å»ä¸Šæµ·\n",
      "ğŸ”„ å¤„ç†ä»»åŠ¡ - å½“å‰çŠ¶æ€: step=1, type=flight_booking\n",
      "ğŸ¯ å¤„ç†ç”¨æˆ·è¾“å…¥: æˆ‘è¦å»ä¸Šæµ· -> æå–å­—æ®µ: arrival_city\n",
      "âœ… æˆåŠŸæå– arrival_city: ä¸Šæµ·\n",
      "ğŸ¤– åŠ©æ‰‹: å·²è®°å½•æ‚¨çš„arrival_cityï¼šä¸Šæµ·ã€‚è¯·æä¾›å‡ºå‘æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰ï¼š\n",
      "ğŸ“Š å½“å‰æ­¥éª¤: 2\n",
      "ğŸ ä»»åŠ¡å®Œæˆ: False\n",
      "ğŸ“‹ å·²æ”¶é›†æ•°æ®: {'departure_city': 'åŒ—äº¬', 'arrival_city': 'ä¸Šæµ·'}\n",
      "\n",
      "ğŸ‘¤ ç”¨æˆ·: 2024-03-15\n",
      "ğŸ”„ å¤„ç†ä»»åŠ¡ - å½“å‰çŠ¶æ€: step=2, type=flight_booking\n",
      "ğŸ¯ å¤„ç†ç”¨æˆ·è¾“å…¥: 2024-03-15 -> æå–å­—æ®µ: departure_date\n",
      "âœ… æˆåŠŸæå– departure_date: 2024-03-15\n",
      "ğŸ¤– åŠ©æ‰‹: å·²è®°å½•æ‚¨çš„departure_dateï¼š2024-03-15ã€‚è¯·å‘Šè¯‰æˆ‘ä¹˜å®¢äººæ•°ï¼š\n",
      "ğŸ“Š å½“å‰æ­¥éª¤: 3\n",
      "ğŸ ä»»åŠ¡å®Œæˆ: False\n",
      "ğŸ“‹ å·²æ”¶é›†æ•°æ®: {'departure_city': 'åŒ—äº¬', 'arrival_city': 'ä¸Šæµ·', 'departure_date': '2024-03-15'}\n",
      "\n",
      "ğŸ‘¤ ç”¨æˆ·: 1äºº\n",
      "ğŸ”„ å¤„ç†ä»»åŠ¡ - å½“å‰çŠ¶æ€: step=3, type=flight_booking\n",
      "ğŸ¯ å¤„ç†ç”¨æˆ·è¾“å…¥: 1äºº -> æå–å­—æ®µ: passengers\n",
      "âœ… æˆåŠŸæå– passengers: 1\n",
      "ğŸ’¾ ä¿å­˜ä»»åŠ¡è®°å½•åˆ°è®°å¿†...\n",
      "âœ… ä»»åŠ¡è®°å½•å·²ä¿å­˜: de22b6ec-2859-4fbd-ab61-c4d1c3898f40\n",
      "ğŸ¤– åŠ©æ‰‹: âœ¨ ä»»åŠ¡å·²å®Œæˆå¹¶ä¿å­˜åˆ°æ‚¨çš„è®°å½•ä¸­ï¼å¦‚éœ€æŸ¥çœ‹å†å²è®°å½•æˆ–å¼€å§‹æ–°ä»»åŠ¡ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚\n",
      "ğŸ“Š å½“å‰æ­¥éª¤: 4\n",
      "ğŸ ä»»åŠ¡å®Œæˆ: True\n",
      "ğŸ“‹ å·²æ”¶é›†æ•°æ®: {'departure_city': 'åŒ—äº¬', 'arrival_city': 'ä¸Šæµ·', 'departure_date': '2024-03-15', 'passengers': '1'}\n",
      "\n",
      "--- æ£€æŸ¥ä¿å­˜çš„ä»»åŠ¡è®°å¿† ---\n",
      "ğŸ“‹ ç”¨æˆ·å®Œæˆçš„ä»»åŠ¡æ•°é‡: 1\n",
      "âœ… flight_booking: {'departure_city': 'åŒ—äº¬', 'arrival_city': 'ä¸Šæµ·', 'departure_date': '2024-03-15', 'passengers': '1'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Dict, Any, List\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.store.memory import InMemoryStore, BaseStore\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# å®šä¹‰ä»»åŠ¡çŠ¶æ€ç±»å‹\n",
    "class TaskState(dict):\n",
    "    \"\"\"ä»»åŠ¡çŠ¶æ€ç®¡ç†\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(kwargs)\n",
    "        if 'messages' not in self:\n",
    "            self['messages'] = []\n",
    "        if 'task_data' not in self:\n",
    "            self['task_data'] = {}\n",
    "        if 'current_step' not in self:\n",
    "            self['current_step'] = 0\n",
    "        if 'task_type' not in self:\n",
    "            self['task_type'] = None\n",
    "        if 'task_complete' not in self:\n",
    "            self['task_complete'] = False\n",
    "\n",
    "class TaskCompletionAgent:\n",
    "    \"\"\"å¤šæ­¥éª¤ä»»åŠ¡å®Œæˆæ™ºèƒ½ä½“\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # å®šä¹‰ä¸åŒç±»å‹çš„ä»»åŠ¡æ¨¡æ¿\n",
    "        self.task_templates = {\n",
    "            \"flight_booking\": {\n",
    "                \"steps\": [\n",
    "                    {\"field\": \"departure_city\", \"prompt\": \"è¯·å‘Šè¯‰æˆ‘æ‚¨çš„å‡ºå‘åŸå¸‚ï¼š\", \"required\": True},\n",
    "                    {\"field\": \"arrival_city\", \"prompt\": \"è¯·å‘Šè¯‰æˆ‘æ‚¨çš„ç›®çš„åœ°åŸå¸‚ï¼š\", \"required\": True},\n",
    "                    {\"field\": \"departure_date\", \"prompt\": \"è¯·æä¾›å‡ºå‘æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰ï¼š\", \"required\": True},\n",
    "                    {\"field\": \"passengers\", \"prompt\": \"è¯·å‘Šè¯‰æˆ‘ä¹˜å®¢äººæ•°ï¼š\", \"required\": True}\n",
    "                ],\n",
    "                \"completion_message\": \"âœˆï¸ èˆªç­ä¿¡æ¯å·²æ”¶é›†å®Œæ¯•ï¼æ­£åœ¨ä¸ºæ‚¨æŸ¥æ‰¾æœ€ä½³èˆªç­...\"\n",
    "            },\n",
    "            \"restaurant_reservation\": {\n",
    "                \"steps\": [\n",
    "                    {\"field\": \"cuisine_type\", \"prompt\": \"æ‚¨æƒ³é¢„è®¢å“ªç§ç±»å‹çš„é¤å…ï¼Ÿï¼ˆå¦‚ï¼šä¸­é¤ã€è¥¿é¤ã€æ—¥æ–™ç­‰ï¼‰\", \"required\": True},\n",
    "                    {\"field\": \"date_time\", \"prompt\": \"è¯·æä¾›ç”¨é¤æ—¥æœŸå’Œæ—¶é—´ï¼š\", \"required\": True},\n",
    "                    {\"field\": \"party_size\", \"prompt\": \"è¯·å‘Šè¯‰æˆ‘ç”¨é¤äººæ•°ï¼š\", \"required\": True}\n",
    "                ],\n",
    "                \"completion_message\": \"ğŸ½ï¸ é¤å…é¢„è®¢ä¿¡æ¯å·²æ”¶é›†å®Œæ¯•ï¼æ­£åœ¨ä¸ºæ‚¨æŸ¥æ‰¾åˆé€‚çš„é¤å…...\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "def process_task(state: TaskState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"å¤„ç†ä»»åŠ¡çš„ä¸»è¦é€»è¾‘\"\"\"\n",
    "    print(f\"ğŸ”„ å¤„ç†ä»»åŠ¡ - å½“å‰çŠ¶æ€: step={state.get('current_step', 0)}, type={state.get('task_type')}\")\n",
    "    \n",
    "    agent = TaskCompletionAgent()\n",
    "    \n",
    "    # å¦‚æœè¿˜æ²¡æœ‰ä»»åŠ¡ç±»å‹ï¼Œå…ˆæ£€æµ‹ä»»åŠ¡ç±»å‹\n",
    "    if not state.get('task_type'):\n",
    "        if not state['messages']:\n",
    "            return state\n",
    "        \n",
    "        last_message = state['messages'][-1].content.lower()\n",
    "        \n",
    "        # æ£€æµ‹ä»»åŠ¡ç±»å‹\n",
    "        if any(keyword in last_message for keyword in ['æœºç¥¨', 'èˆªç­', 'é£æœº', 'é¢„è®¢æœºç¥¨']):\n",
    "            task_type = \"flight_booking\"\n",
    "        elif any(keyword in last_message for keyword in ['é¤å…', 'é¢„è®¢', 'åƒé¥­', 'è®¢é¤']):\n",
    "            task_type = \"restaurant_reservation\"\n",
    "        else:\n",
    "            task_type = \"flight_booking\"\n",
    "        \n",
    "        print(f\"ğŸ“‹ æ£€æµ‹åˆ°ä»»åŠ¡ç±»å‹: {task_type}\")\n",
    "        \n",
    "        # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€\n",
    "        state['task_type'] = task_type\n",
    "        state['current_step'] = 0\n",
    "        state['task_data'] = {}\n",
    "        state['task_complete'] = False\n",
    "        \n",
    "        # æ·»åŠ ç¡®è®¤æ¶ˆæ¯å’Œç¬¬ä¸€ä¸ªé—®é¢˜\n",
    "        template = agent.task_templates[task_type]\n",
    "        first_step = template['steps'][0]\n",
    "        \n",
    "        confirmation_messages = {\n",
    "            \"flight_booking\": f\"æˆ‘æ¥å¸®æ‚¨é¢„è®¢èˆªç­ã€‚{first_step['prompt']}\",\n",
    "            \"restaurant_reservation\": f\"æˆ‘æ¥å¸®æ‚¨é¢„è®¢é¤å…ã€‚{first_step['prompt']}\"\n",
    "        }\n",
    "        \n",
    "        ai_message = AIMessage(content=confirmation_messages[task_type])\n",
    "        state['messages'].append(ai_message)\n",
    "        return state\n",
    "    \n",
    "    # å¦‚æœå·²ç»å®Œæˆä»»åŠ¡ï¼Œç›´æ¥è¿”å›\n",
    "    if state.get('task_complete'):\n",
    "        return state\n",
    "    \n",
    "    # å¤„ç†ä¿¡æ¯æ”¶é›†\n",
    "    task_type = state['task_type']\n",
    "    template = agent.task_templates[task_type]\n",
    "    steps = template['steps']\n",
    "    current_step = state['current_step']\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ­¥éª¤éœ€è¦å®Œæˆ\n",
    "    if current_step >= len(steps):\n",
    "        # æ‰€æœ‰ä¿¡æ¯å·²æ”¶é›†å®Œæ¯•\n",
    "        state['task_complete'] = True\n",
    "        response = template['completion_message']\n",
    "        response += \"\\n\\nğŸ“‹ æ”¶é›†åˆ°çš„ä¿¡æ¯ï¼š\\n\"\n",
    "        for key, value in state['task_data'].items():\n",
    "            response += f\"â€¢ {key}: {value}\\n\"\n",
    "        \n",
    "        ai_message = AIMessage(content=response)\n",
    "        state['messages'].append(ai_message)\n",
    "        return state\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„ç”¨æˆ·æ¶ˆæ¯éœ€è¦å¤„ç†\n",
    "    if len(state['messages']) >= 2 and isinstance(state['messages'][-1], HumanMessage):\n",
    "        # è·å–å½“å‰æ­¥éª¤ä¿¡æ¯\n",
    "        step_info = steps[current_step]\n",
    "        field_name = step_info['field']\n",
    "        user_message = state['messages'][-1].content\n",
    "        \n",
    "        print(f\"ğŸ¯ å¤„ç†ç”¨æˆ·è¾“å…¥: {user_message} -> æå–å­—æ®µ: {field_name}\")\n",
    "        \n",
    "        # å°è¯•æå–ä¿¡æ¯\n",
    "        extracted_value = extract_field_value(user_message, field_name)\n",
    "        \n",
    "        if extracted_value and extracted_value != \"NOT_FOUND\":\n",
    "            # æˆåŠŸæå–ä¿¡æ¯\n",
    "            state['task_data'][field_name] = extracted_value\n",
    "            state['current_step'] += 1\n",
    "            \n",
    "            print(f\"âœ… æˆåŠŸæå– {field_name}: {extracted_value}\")\n",
    "            \n",
    "            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šæ­¥éª¤\n",
    "            if state['current_step'] < len(steps):\n",
    "                next_step = steps[state['current_step']]\n",
    "                next_prompt = next_step['prompt']\n",
    "                response = f\"å·²è®°å½•æ‚¨çš„{field_name}ï¼š{extracted_value}ã€‚{next_prompt}\"\n",
    "            else:\n",
    "                # æ‰€æœ‰ä¿¡æ¯å·²æ”¶é›†å®Œæ¯•\n",
    "                state['task_complete'] = True\n",
    "                response = template['completion_message']\n",
    "                response += \"\\n\\nğŸ“‹ æ”¶é›†åˆ°çš„ä¿¡æ¯ï¼š\\n\"\n",
    "                for key, value in state['task_data'].items():\n",
    "                    response += f\"â€¢ {key}: {value}\\n\"\n",
    "        else:\n",
    "            # æå–å¤±è´¥ï¼Œé‡æ–°è¯¢é—®\n",
    "            response = f\"æŠ±æ­‰ï¼Œæˆ‘æ²¡èƒ½ç†è§£æ‚¨æä¾›çš„{field_name}ä¿¡æ¯ã€‚{step_info['prompt']}\"\n",
    "        \n",
    "        # æ·»åŠ AIå“åº”\n",
    "        ai_message = AIMessage(content=response)\n",
    "        state['messages'].append(ai_message)\n",
    "    \n",
    "    return state\n",
    "\n",
    "def extract_field_value(user_message: str, field_name: str) -> str:\n",
    "    \"\"\"ç®€åŒ–çš„ä¿¡æ¯æå–å‡½æ•°\"\"\"\n",
    "    message_lower = user_message.lower()\n",
    "    \n",
    "    if field_name == \"departure_city\":\n",
    "        cities = [\"åŒ—äº¬\", \"ä¸Šæµ·\", \"å¹¿å·\", \"æ·±åœ³\", \"æ­å·\", \"æˆéƒ½\", \"é‡åº†\", \"è¥¿å®‰\", \"å—äº¬\", \"æ­¦æ±‰\"]\n",
    "        for city in cities:\n",
    "            if city in user_message:\n",
    "                return city\n",
    "    \n",
    "    elif field_name == \"arrival_city\":\n",
    "        cities = [\"åŒ—äº¬\", \"ä¸Šæµ·\", \"å¹¿å·\", \"æ·±åœ³\", \"æ­å·\", \"æˆéƒ½\", \"é‡åº†\", \"è¥¿å®‰\", \"å—äº¬\", \"æ­¦æ±‰\", \"å¤§è¿\", \"é’å²›\"]\n",
    "        for city in cities:\n",
    "            if city in user_message:\n",
    "                return city\n",
    "    \n",
    "    elif field_name == \"departure_date\":\n",
    "        import re\n",
    "        date_patterns = [r'\\d{4}-\\d{2}-\\d{2}', r'\\d{1,2}æœˆ\\d{1,2}æ—¥', r'\\d{1,2}/\\d{1,2}']\n",
    "        for pattern in date_patterns:\n",
    "            match = re.search(pattern, user_message)\n",
    "            if match:\n",
    "                return match.group()\n",
    "    \n",
    "    elif field_name == \"passengers\":\n",
    "        import re\n",
    "        number_match = re.search(r'(\\d+)äºº?', user_message)\n",
    "        if number_match:\n",
    "            return number_match.group(1)\n",
    "    \n",
    "    elif field_name == \"cuisine_type\":\n",
    "        cuisine_types = [\"ä¸­é¤\", \"è¥¿é¤\", \"æ—¥æ–™\", \"éŸ©æ–™\", \"æ„å¤§åˆ©\", \"æ³•é¤\", \"æ³°é¤\", \"å°åº¦\"]\n",
    "        for cuisine in cuisine_types:\n",
    "            if cuisine in user_message:\n",
    "                return cuisine\n",
    "    \n",
    "    elif field_name == \"party_size\":\n",
    "        import re\n",
    "        number_match = re.search(r'(\\d+)äºº?', user_message)\n",
    "        if number_match:\n",
    "            return number_match.group(1)\n",
    "    \n",
    "    elif field_name == \"date_time\":\n",
    "        if any(word in message_lower for word in [\"æ˜å¤©\", \"ä»Šå¤©\", \"åå¤©\"]):\n",
    "            return user_message\n",
    "        import re\n",
    "        if re.search(r'\\d+ç‚¹|\\d+:\\d+', user_message):\n",
    "            return user_message\n",
    "    \n",
    "    return \"NOT_FOUND\"\n",
    "\n",
    "def save_task_memory(state: TaskState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"ä¿å­˜ä»»åŠ¡å®Œæˆè®°å½•åˆ°é•¿æœŸè®°å¿†\"\"\"\n",
    "    print(\"ğŸ’¾ ä¿å­˜ä»»åŠ¡è®°å½•åˆ°è®°å¿†...\")\n",
    "    \n",
    "    if not state['task_data'] or not state['task_type']:\n",
    "        return state\n",
    "    \n",
    "    user_id = config.get(\"configurable\", {}).get(\"user_id\", \"default_user\")\n",
    "    \n",
    "    # åˆ›å»ºä»»åŠ¡è®°å½•\n",
    "    task_record = {\n",
    "        \"task_type\": state['task_type'],\n",
    "        \"task_data\": state['task_data'],\n",
    "        \"completion_time\": \"2024-02-15T10:30:00Z\",\n",
    "        \"status\": \"completed\"\n",
    "    }\n",
    "    \n",
    "    # ä¿å­˜åˆ°è®°å¿†å­˜å‚¨\n",
    "    import uuid\n",
    "    record_key = str(uuid.uuid4())\n",
    "    namespace = (user_id, \"completed_tasks\")\n",
    "    \n",
    "    store.put(namespace, record_key, task_record)\n",
    "    print(f\"âœ… ä»»åŠ¡è®°å½•å·²ä¿å­˜: {record_key}\")\n",
    "    \n",
    "    # æ·»åŠ ç¡®è®¤æ¶ˆæ¯\n",
    "    confirmation_message = AIMessage(content=\"âœ¨ ä»»åŠ¡å·²å®Œæˆå¹¶ä¿å­˜åˆ°æ‚¨çš„è®°å½•ä¸­ï¼å¦‚éœ€æŸ¥çœ‹å†å²è®°å½•æˆ–å¼€å§‹æ–°ä»»åŠ¡ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚\")\n",
    "    state['messages'].append(confirmation_message)\n",
    "    \n",
    "    return state\n",
    "\n",
    "# åˆ›å»ºç®€åŒ–çš„ä»»åŠ¡å®Œæˆå›¾\n",
    "def create_task_completion_graph():\n",
    "    \"\"\"åˆ›å»ºä»»åŠ¡å®Œæˆæµç¨‹å›¾\"\"\"\n",
    "    store = InMemoryStore()\n",
    "    \n",
    "    # åˆ›å»ºçŠ¶æ€å›¾\n",
    "    workflow = StateGraph(dict)\n",
    "    \n",
    "    # æ·»åŠ èŠ‚ç‚¹\n",
    "    workflow.add_node(\"process_task\", process_task)\n",
    "    workflow.add_node(\"save_memory\", save_task_memory)\n",
    "    \n",
    "    # æ¡ä»¶å‡½æ•°ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜è®°å¿†\n",
    "    def should_save_memory(state):\n",
    "        if state.get('task_complete', False) and state.get('task_data'):\n",
    "            return \"save_memory\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "    \n",
    "    # æ·»åŠ è¾¹\n",
    "    workflow.add_edge(START, \"process_task\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"process_task\",\n",
    "        should_save_memory,\n",
    "        {\n",
    "            \"save_memory\": \"save_memory\",\n",
    "            \"end\": END\n",
    "        }\n",
    "    )\n",
    "    workflow.add_edge(\"save_memory\", END)\n",
    "    \n",
    "    # ç¼–è¯‘å›¾\n",
    "    app = workflow.compile(store=store)\n",
    "    return app, store\n",
    "\n",
    "# æ¼”ç¤ºä»»åŠ¡å®Œæˆç³»ç»Ÿ\n",
    "print(\"=== æƒ…å¢ƒåŒ–ä»»åŠ¡å®Œæˆç³»ç»Ÿæ¼”ç¤º ===\")\n",
    "\n",
    "# åˆ›å»ºåº”ç”¨å’Œå­˜å‚¨\n",
    "app, store = create_task_completion_graph()\n",
    "\n",
    "# é…ç½®\n",
    "config = {\"configurable\": {\"user_id\": \"user_456\"}}\n",
    "\n",
    "print(\"\\n--- èˆªç­é¢„è®¢æ¼”ç¤º ---\")\n",
    "\n",
    "# æ¼”ç¤ºå®Œæ•´çš„å¤šè½®å¯¹è¯\n",
    "conversation_steps = [\n",
    "    \"æˆ‘æƒ³é¢„è®¢ä¸€å¼ æœºç¥¨\",\n",
    "    \"æˆ‘ä»åŒ—äº¬å‡ºå‘\", \n",
    "    \"æˆ‘è¦å»ä¸Šæµ·\",\n",
    "    \"2024-03-15\",\n",
    "    \"1äºº\"\n",
    "]\n",
    "\n",
    "current_state = TaskState()\n",
    "\n",
    "for i, user_input in enumerate(conversation_steps):\n",
    "    print(f\"\\nğŸ‘¤ ç”¨æˆ·: {user_input}\")\n",
    "    \n",
    "    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯\n",
    "    current_state['messages'].append(HumanMessage(content=user_input))\n",
    "    \n",
    "    # å¤„ç†ä»»åŠ¡\n",
    "    result = app.invoke(current_state, config=config)\n",
    "    \n",
    "    # æ›´æ–°çŠ¶æ€\n",
    "    current_state = result\n",
    "    \n",
    "    # æ˜¾ç¤ºAIå“åº”\n",
    "    if current_state['messages'] and isinstance(current_state['messages'][-1], AIMessage):\n",
    "        print(f\"ğŸ¤– åŠ©æ‰‹: {current_state['messages'][-1].content}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºå½“å‰ä»»åŠ¡çŠ¶æ€\n",
    "    print(f\"ğŸ“Š å½“å‰æ­¥éª¤: {current_state.get('current_step', 0)}\")\n",
    "    print(f\"ğŸ ä»»åŠ¡å®Œæˆ: {current_state.get('task_complete', False)}\")\n",
    "    if current_state.get('task_data'):\n",
    "        print(f\"ğŸ“‹ å·²æ”¶é›†æ•°æ®: {current_state['task_data']}\")\n",
    "\n",
    "# æ£€æŸ¥ä¿å­˜çš„è®°å¿†\n",
    "print(\"\\n--- æ£€æŸ¥ä¿å­˜çš„ä»»åŠ¡è®°å¿† ---\")\n",
    "saved_memories = store.search((\"user_456\", \"completed_tasks\"))\n",
    "print(f\"ğŸ“‹ ç”¨æˆ·å®Œæˆçš„ä»»åŠ¡æ•°é‡: {len(saved_memories)}\")\n",
    "\n",
    "for memory in saved_memories:\n",
    "    task_data = memory.value\n",
    "    print(f\"âœ… {task_data['task_type']}: {task_data['task_data']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5-3",
   "metadata": {},
   "source": [
    "### 5.3.3 TrustCall ä¿¡æ¯æå–æ¨¡æ‹Ÿ\n",
    "\n",
    "TrustCall æ˜¯ä¸€ä¸ªå¼€æºåº“ï¼Œæ—¨åœ¨ç®€åŒ– AI æ™ºèƒ½ä½“çš„åŸºäºæ¨¡å¼çš„ä¿¡æ¯æå–å’Œæ›´æ–°ã€‚æœ¬èŠ‚æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ç»“æ„åŒ–æ–¹æ³•æå–å’Œç®¡ç†è®°å¿†ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-5-7",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 5-14ï¼šæ„å»ºä¸€ä¸ª TrustCall å¯ç”¨çš„æ•°æ®ç»“æ„\n",
    "\n",
    "å®šä¹‰ç”¨äºä¿¡æ¯æå–çš„ç»“æ„åŒ–æ•°æ®æ¨¡å‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class UserProfile(BaseModel):\n",
    "    \"\"\"å…·æœ‰ç±»å‹åŒ–å­—æ®µçš„ç”¨æˆ·èµ„æ–™æ¨¡å¼\"\"\"\n",
    "    user_name: str = Field(description=\"ç”¨æˆ·çš„é¦–é€‰å§“å\")\n",
    "    interests: List[str] = Field(description=\"ç”¨æˆ·å…´è¶£åˆ—è¡¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bed512",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 5-15ï¼šä½¿ç”¨ TrustCall è¿›è¡ŒåŸºæœ¬ä¿¡æ¯æå–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df89620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"Qwen/Qwen2.5-7B-Instruct\", temperature=0) # åˆå§‹åŒ– LLM\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[UserProfile], # å°†æˆ‘ä»¬çš„ Pydantic æ¨¡å¼ä½œä¸ºå·¥å…·ä¼ é€’\n",
    "    tool_choice=\"UserProfile\" # å¼ºåˆ¶ TrustCall ä½¿ç”¨ UserProfile å·¥å…·è¿›è¡Œè¾“å‡º\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d6ddad",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 5-16ï¼šè®¿é—®æå–çš„ç»“æ„åŒ–è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db30309e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_name='Alice' interests=['è¿œè¶³', 'é˜…è¯»ç§‘å¹»å°è¯´']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "conversation = [\n",
    "    HumanMessage(content=\"å—¨ï¼Œæˆ‘æ˜¯ Aliceã€‚\"),\n",
    "    AIMessage(content=\"å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ŒAliceï¼\"),\n",
    "    HumanMessage(content=\"æˆ‘çš„çˆ±å¥½åŒ…æ‹¬è¿œè¶³å’Œé˜…è¯»ç§‘å¹»å°è¯´ã€‚\")\n",
    "]\n",
    "\n",
    "instruction_prompt = \"ä»ä»¥ä¸‹å¯¹è¯ä¸­æå–ç”¨æˆ·èµ„æ–™ã€‚\"\n",
    "\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction_prompt)] + conversation})\n",
    "\n",
    "extracted_profile = result[\"responses\"][0] # è®¿é—®æå–çš„ UserProfile å¯¹è±¡\n",
    "print(extracted_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-5-7",
   "metadata": {},
   "source": [
    "**ğŸ’¡ ç»“æ„åŒ–æå–æ ¸å¿ƒä»·å€¼**ï¼š\n",
    "\n",
    "- **æ¨¡å¼å¼ºåˆ¶æ‰§è¡Œ**ï¼šç¡®ä¿æå–çš„æ•°æ®ä¸¥æ ¼éµå¾ªå®šä¹‰çš„ç»“æ„\n",
    "- **æ™ºèƒ½æå–**ï¼šåˆ©ç”¨æ¨¡å¼åŒ¹é…å’Œè§„åˆ™è¿›è¡Œå¤æ‚çš„ä¿¡æ¯æå–\n",
    "- **å¢é‡æ›´æ–°**ï¼šæ”¯æŒåŸºäºæ–°ä¿¡æ¯æ›´æ–°ç°æœ‰æ•°æ®ç»“æ„\n",
    "- **å¯é æ€§æå‡**ï¼šå‡å°‘æ‰‹å·¥è§£æå¸¦æ¥çš„é”™è¯¯å’Œä¸ä¸€è‡´æ€§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5-4",
   "metadata": {},
   "source": [
    "## 5.4 LangMem\n",
    "\n",
    "åœ¨ç³»ç»Ÿé˜è¿° AI æ™ºèƒ½ä½“è®°å¿†ç†è®ºåŸºç¡€ï¼Œå¹¶å…¨é¢è§£æ LangGraph è®°å¿†å­˜å‚¨æ¶æ„åï¼Œæœ¬èŠ‚å°†è¯¦ç»†ä»‹ç»å¦‚ä½•è¿ç”¨ LangChain å›¢é˜Ÿæœ€æ–°æ¨å‡ºçš„ LangMem å·¥å…·åº“ï¼Œå°†å…ˆè¿›çš„è®°å¿†ç®¡ç†åŠŸèƒ½æ— ç¼é›†æˆè‡³ LangGraph æ™ºèƒ½ä½“ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172afcee",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 5-17ï¼šä½¿ç”¨è®°å¿†å·¥å…·é…ç½® ReAct æ™ºèƒ½ä½“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5749b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ™ºèƒ½ä½“å“åº”: \n",
      "\n",
      "æˆ‘å·²ç»è®°ä½äº†æ‚¨çš„å–œå¥½ï¼Œæ‚¨å–œæ¬¢ç¼–ç¨‹ã€‚å¦‚æœä¹‹åè¿˜æœ‰å…¶ä»–éœ€è¦è®°å½•çš„ä¿¡æ¯ï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼\n",
      "è®°å¿†æ£€ç´¢ç»“æœ: \n",
      "\n",
      "æ ¹æ®ä¹‹å‰çš„è®°å½•ï¼Œæ‚¨æåˆ°è¿‡å–œæ¬¢ç¼–ç¨‹ã€‚éœ€è¦æˆ‘å¸®æ‚¨åšäº›ä»€ä¹ˆä¸ç¼–ç¨‹ç›¸å…³çš„å—ï¼Ÿæˆ–è€…æ‚¨å¸Œæœ›æ›´æ–°/åˆ é™¤è¿™ä¸ªåå¥½ä¿¡æ¯ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
    "\n",
    "# åˆ›å»ºå…·æœ‰è®°å¿†åŠŸèƒ½çš„æ™ºèƒ½ä½“\n",
    "agent = create_react_agent(\n",
    "    \"openai:Qwen/Qwen3-8B\", # é€‰æ‹©æ‚¨çš„ LLM\n",
    "    tools=[\n",
    "        # ä¸ºæ™ºèƒ½ä½“é…å¤‡å·¥å…·ä»¥åœ¨â€œçƒ­è·¯å¾„â€ä¸­ç®¡ç†è‡ªå·±çš„è®°å¿†\n",
    "        create_manage_memory_tool(namespace=(\"memories\",)), # ç”¨äºåˆ›å»ºã€æ›´æ–°ã€åˆ é™¤è®°å¿†çš„å·¥å…·\n",
    "        create_search_memory_tool(namespace=(\"memories\",)), # ç”¨äºæœç´¢ç°æœ‰è®°å¿†çš„å·¥å…·\n",
    "    ],\n",
    "    store=InMemoryStore(), # æä¾›è®°å¿†å­˜å‚¨ä»¥å®ç°æŒä¹…æ€§\n",
    ")\n",
    "\n",
    "# æ‰§è¡Œç¤ºä¾‹ï¼šä½¿ç”¨æ™ºèƒ½ä½“è¿›è¡Œç®€å•å¯¹è¯\n",
    "response = agent.invoke({\"messages\": [HumanMessage(content=\"è¯·è®°ä½æˆ‘å–œæ¬¢ç¼–ç¨‹ã€‚\")]})\n",
    "print(\"æ™ºèƒ½ä½“å“åº”:\", response[\"messages\"][-1].content)\n",
    "\n",
    "# æ£€ç´¢è®°å¿†ä»¥éªŒè¯å­˜å‚¨\n",
    "search_result = agent.invoke({\"messages\": [HumanMessage(content=\"å›å¿†ä¸€ä¸‹æˆ‘å–œæ¬¢ä»€ä¹ˆå—ï¼Ÿ\")]})\n",
    "print(\"è®°å¿†æ£€ç´¢ç»“æœ:\", search_result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99a0642",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 5-18ï¼šå®ç°æç¤ºä¼˜åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2c1fc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‚¨æ˜¯ä¸€ä½ä¹äºåŠ©äººçš„å†™ä½œåŠ©æ‰‹ã€‚è¯·ç¡®ä¿æ‚¨çš„å›ç­”è¯¦ç»†ä¸”åŒ…å«ç”¨æˆ·å¯èƒ½æ„Ÿå…´è¶£çš„ç›¸å…³ä¿¡æ¯ã€‚å¦‚æœå¯èƒ½ï¼Œæä¾›å…·ä½“çš„ä¾‹å­æˆ–åº”ç”¨åœºæ™¯æ¥å¢å¼ºå›ç­”çš„è´¨é‡ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langmem import create_prompt_optimizer\n",
    "\n",
    "optimizer = create_prompt_optimizer(\n",
    "    \"openai:Qwen/Qwen2.5-7B-Instruct\", # é€‰æ‹©æ‚¨çš„ LLM ä»¥è¿›è¡Œä¼˜åŒ–\n",
    "    kind=\"prompt_memory\", # é€‰æ‹©æˆåŠŸæ¡ˆä¾‹ä¼˜åŒ–ç­–ç•¥\n",
    "    config={\"max_reflection_steps\": 5, \"min_reflection_steps\": 1}, # é…ç½®ä¼˜åŒ–è¡Œä¸º\n",
    ")\n",
    "\n",
    "# å¸¦æœ‰åé¦ˆçš„ç¤ºä¾‹å¯¹è¯è½¨è¿¹\n",
    "trajectories = [\n",
    "    # æ²¡æœ‰æ³¨é‡Šçš„å¯¹è¯ï¼ˆä»…å¯¹è¯å†…å®¹ï¼‰\n",
    "    (\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"è¯·å‘Šè¯‰æˆ‘Pythonçš„ä¼˜ç‚¹\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Pythonæ˜¯ä¸€ç§æ˜“äºå­¦ä¹ å’Œä½¿ç”¨çš„ç¼–ç¨‹è¯­è¨€...\"},\n",
    "            {\"role\": \"user\", \"content\": \"èƒ½è¯¦ç»†è¯´è¯´å®ƒçš„åº“æ”¯æŒå—ï¼Ÿ\"},\n",
    "        ],\n",
    "        None,\n",
    "    ),\n",
    "    # å¸¦æœ‰åé¦ˆçš„å¯¹è¯\n",
    "    (\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"Pythonæœ‰å“ªäº›æµè¡Œçš„åº“ï¼Ÿ\"},\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Pythonæœ‰è®¸å¤šæµè¡Œçš„åº“ï¼Œå¦‚NumPyã€Pandasã€TensorFlowç­‰...\",\n",
    "            },\n",
    "        ],\n",
    "        {\n",
    "            \"score\": 0.8,\n",
    "            \"comment\": \"å¯ä»¥å¢åŠ åº“çš„åº”ç”¨åœºæ™¯å’Œæ›´å¤šç»†èŠ‚\",\n",
    "        },\n",
    "    ),\n",
    "    # æ³¨é‡Šå¯ä»¥æ˜¯ä¸åŒç±»å‹çš„ï¼Œä¾‹å¦‚ç¼–è¾‘/ä¿®è®¢ï¼\n",
    "    (\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"Pythonå’ŒJavaç›¸æ¯”å¦‚ä½•ï¼Ÿ\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Pythonå’ŒJavaåœ¨è¯­æ³•å’Œåº”ç”¨é¢†åŸŸä¸Šæœ‰è®¸å¤šä¸åŒ...\"},\n",
    "        ],\n",
    "        {\"revised\": \"Pythonå’ŒJavaåœ¨è¯­æ³•ã€æ€§èƒ½å’Œåº”ç”¨é¢†åŸŸä¸Šå„æœ‰ä¼˜åŠ£...\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "# å®šä¹‰å†™ä½œåŠ©æ‰‹çš„åˆå§‹ç³»ç»Ÿæç¤º\n",
    "initial_prompt = \"æ‚¨æ˜¯ä¸€ä½ä¹äºåŠ©äººçš„å†™ä½œåŠ©æ‰‹\"\n",
    "\n",
    "# è°ƒç”¨ä¼˜åŒ–å™¨ä»¥æ ¹æ®è®­ç»ƒæ•°æ®æ”¹è¿›åˆå§‹æç¤º\n",
    "optimized_prompt = optimizer.invoke(\n",
    "    {\"trajectories\": trajectories, \"prompt\": initial_prompt} # æä¾›è½¨è¿¹å’Œè¦ä¼˜åŒ–çš„åˆå§‹æç¤º\n",
    ")\n",
    "\n",
    "print(optimized_prompt) # è¾“å‡ºä¼˜åŒ–çš„æç¤º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter-conclusion",
   "metadata": {},
   "source": "## ğŸ“š æœ¬ç« æ€»ç»“\n\né€šè¿‡æœ¬ç« çš„å­¦ä¹ ï¼Œæˆ‘ä»¬æ·±å…¥æŒæ¡äº† AI æ™ºèƒ½ä½“è®°å¿†ç³»ç»Ÿçš„æ ¸å¿ƒç†å¿µå’Œå®è·µæŠ€æœ¯ã€‚é¦–å…ˆç³»ç»Ÿé˜è¿°äº†çŸ­æœŸè®°å¿†ä¸é•¿æœŸè®°å¿†çš„åŒºåˆ«ä¸åº”ç”¨ï¼Œç†è§£äº†å¦‚ä½•é€šè¿‡å¯¹è¯å†å²ç®¡ç†ã€æˆªæ–­ç­–ç•¥å’Œæ™ºèƒ½æ‘˜è¦æ¥ä¼˜åŒ–çŸ­æœŸè®°å¿†ï¼ŒåŒæ—¶å­¦ä¼šåˆ©ç”¨ LangGraph è®°å¿†å­˜å‚¨å®ç°è·¨ä¼šè¯çš„é•¿æœŸçŸ¥è¯†ç§¯ç´¯ã€‚æ¥ç€æ·±å…¥æ¢ç´¢äº†è®°å¿†å­˜å‚¨çš„æ ¸å¿ƒæ“ä½œï¼ŒåŒ…æ‹¬å‘½åç©ºé—´è®¾è®¡ã€è¯­ä¹‰æœç´¢å’Œå‘é‡åµŒå…¥æŠ€æœ¯ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤ŸåŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§è¿›è¡Œæ™ºèƒ½æ£€ç´¢ã€‚ç„¶åé€šè¿‡ä¸ªæ€§åŒ–æ¨èã€å¤šæ­¥éª¤ä»»åŠ¡å®Œæˆç­‰å®é™…åº”ç”¨åœºæ™¯ï¼Œå±•ç¤ºäº†è®°å¿†ç³»ç»Ÿå¦‚ä½•æ˜¾è‘—æå‡æ™ºèƒ½ä½“çš„åŠŸèƒ½è¡¨ç°ï¼Œå¹¶å­¦ä¹ äº† TrustCall ç­‰å·¥å…·è¿›è¡Œç»“æ„åŒ–ä¿¡æ¯æå–ã€‚æœ€åä»‹ç»äº† LangMem å·¥å…·åº“çš„ä½¿ç”¨æ–¹æ³•ï¼ŒåŒ…æ‹¬è®°å¿†ç®¡ç†å·¥å…·å’Œæç¤ºä¼˜åŒ–åŠŸèƒ½ã€‚è¿™äº›æŠ€æœ¯çš„ç»“åˆä½¿æˆ‘ä»¬èƒ½å¤Ÿæ„å»ºå…·æœ‰æŒç»­å­¦ä¹ èƒ½åŠ›ã€ä¸ªæ€§åŒ–äº¤äº’å’Œæ™ºèƒ½è¿›åŒ–ç‰¹æ€§çš„ä¸‹ä¸€ä»£ AI æ™ºèƒ½ä½“ç³»ç»Ÿã€‚"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}