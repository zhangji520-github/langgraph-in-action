{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chapter-intro",
   "metadata": {},
   "source": [
    "# ç¬¬ 6 ç« ï¼šæ„å»º AI æ™ºèƒ½ä½“çš„å…¶å®ƒ API é€‰é¡¹\n",
    "\n",
    "> æœ¬ç¬”è®°æ–‡ä»¶éœ€è¦ä¸ã€ŠLangGraphå®æˆ˜ã€‹çš„ç¬¬ 6 ç« çš„å†…å®¹é…å¥—ä½¿ç”¨ã€‚\n",
    "\n",
    "åœ¨æ„å»ºæ™ºèƒ½ä½“çš„é“è·¯ä¸Šï¼Œæ¡†æ¶èµ‹äºˆæˆ‘ä»¬å¤šç§é€”å¾„ï¼Œå¦‚åŒç™¾å·æ±‡æµï¼Œæ®Šé€”åŒå½’ã€‚å…³é”®åœ¨äºæ´æ‚‰æ¯æ¡è·¯å¾„çš„ç‰¹æ€§ï¼Œæƒè¡¡åˆ©å¼Šï¼Œæœ€ç»ˆæ‹©å–é‚£æ¡æœ€èƒ½é‡Šæ”¾åˆ›é€ åŠ›ã€æœ€èƒ½è¾¾æˆç›®æ ‡çš„é€šé€”ã€‚\n",
    "\n",
    "æœ¬ç« å°†æ·±å…¥æ¢ç´¢ LangGraph æ¡†æ¶çš„æ ¸å¿ƒ â€”â€” å…¶ä¸°å¯Œè€Œå¼ºå¤§çš„ API å·¥å…·ç®±ã€‚ä¸ºäº†æ»¡è¶³ä¸åŒå¼€å‘åœºæ™¯å’Œå¼€å‘è€…åå¥½ï¼ŒLangGraph æä¾›äº†å¤šç§ API æ¥å£ï¼š\n",
    "\n",
    "- **`create_react_agent`**: é¢„æ„å»º APIï¼Œå¿«é€Ÿå¯åŠ¨æŒ‰é’®ï¼Œè¿…é€Ÿæ­å»ºåŠŸèƒ½å®Œå¤‡çš„ ReAct æ™ºèƒ½ä½“\n",
    "- **Functional API**: ä»¥å‡½æ•°ä¸ºä¸­å¿ƒçš„ APIï¼Œé€šè¿‡ `@entrypoint` å’Œ `@task` è£…é¥°å™¨ï¼Œå°† LangGraph çš„æ ¸å¿ƒåŠŸèƒ½èå…¥ç†Ÿæ‚‰çš„å‡½æ•°å¼ç¼–ç¨‹èŒƒå¼\n",
    "- **Graph API**: æ ¸å¿ƒ API èŒƒå¼ï¼Œé€šè¿‡æ˜¾å¼å®šä¹‰èŠ‚ç‚¹å’Œè¾¹æ„å»ºä»»æ„å¤æ‚åº¦çš„æ™ºèƒ½ä½“æ¶æ„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environment-setup",
   "metadata": {},
   "source": [
    "### ğŸš€ ç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "é¦–å…ˆåŠ è½½å¿…è¦çš„ç¯å¢ƒå˜é‡é…ç½®ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6-1",
   "metadata": {},
   "source": [
    "## 6.1 create_react_agent \n",
    "\n",
    "LangGraph ä½œä¸º AI æ™ºèƒ½ä½“å¼€å‘æ¡†æ¶ï¼Œåœ¨çµæ´»æ€§å’ŒåŠŸèƒ½æ€§æ–¹é¢å±•ç°å‡ºç‹¬ç‰¹ä¼˜åŠ¿ã€‚è¯¥æ¡†æ¶ä¸ä»…æ”¯æŒé«˜åº¦å®šåˆ¶åŒ–çš„æ™ºèƒ½ä½“æ¶æ„å¼€å‘ï¼ŒåŒæ—¶ä¸ºå¿«é€ŸåŸå‹è®¾è®¡å’Œå¼€å‘è€…å…¥é—¨æä¾›äº†ä¾¿æ·å·¥å…·ã€‚å…¶ä¸­ï¼Œ`create_react_agent` å‡½æ•°ä½œä¸ºé¢„æ„å»ºç»„ä»¶ï¼Œå®ç°äº† ReActï¼ˆæ¨ç†â€”\n",
    "è¡ŒåŠ¨ï¼‰æ¨¡å¼çš„å¿«é€Ÿéƒ¨ç½²ï¼Œæ˜¾è‘—é™ä½äº†å¼€å‘é—¨æ§›ã€‚æœ¬èŠ‚å°†æ¼”ç¤º `create_react_agent` çš„æ ¸å¿ƒåŠŸèƒ½ã€è‡ªå®šä¹‰é€‰é¡¹ï¼Œä»¥åŠå¦‚ä½•åœ¨æ›´å¹¿æ³›çš„ LangChain ç”Ÿæ€ç³»ç»Ÿä¸­æ— ç¼é›†æˆã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-1",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-1ï¼š`create_react_agent` çš„åŸºæœ¬ç”¨æ³•\n",
    "\n",
    "è®©æˆ‘ä»¬ä»æœ€ç®€å•çš„ç¤ºä¾‹å¼€å§‹ï¼Œæ„å»ºä¸€ä¸ªèƒ½å¤ŸæŸ¥è¯¢å¤©æ°”ä¿¡æ¯çš„æ™ºèƒ½ä½“ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The weather in San Francisco is currently sunny! ğŸŒ While the city is known for its foggy days, it's great to hear it's clear up today. Let me know if you'd like more details!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# åˆå§‹åŒ–è¯­è¨€æ¨¡å‹\n",
    "model = ChatOpenAI(model=\"Qwen/Qwen3-8B\", temperature=0)\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªç®€å•çš„å·¥å…·æ¥è·å–å¤©æ°”ä¿¡æ¯\n",
    "@tool\n",
    "def get_weather(city: str):\n",
    "    \"\"\"Use this tool to get the weather information for a city.\"\"\"\n",
    "    if city.lower() in [\"nyc\", \"new york\"]:\n",
    "        return \"It might be cloudy in New York.\"\n",
    "    elif city.lower() in [\"sf\", \"san francisco\"]:\n",
    "        return \"It's always sunny in San Francisco.\"\n",
    "    else:\n",
    "        return \"Unable to get the weather information for this city.\"\n",
    "\n",
    "tools = [get_weather]\n",
    "\n",
    "# åˆ›å»º ReAct æ™ºèƒ½ä½“\n",
    "graph = create_react_agent(model, tools=tools)\n",
    "\n",
    "# è°ƒç”¨æ™ºèƒ½ä½“\n",
    "inputs = {\"messages\": [(\"user\", \"How's the weather in sf?\")]}\n",
    "response = graph.invoke(inputs)\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-1",
   "metadata": {},
   "source": [
    "**ğŸ’¡ æ ¸å¿ƒæ¦‚å¿µè§£æ**ï¼š\n",
    "\n",
    "- **æ¨¡å‹ç»‘å®š**: `create_react_agent` è‡ªåŠ¨å°†å·¥å…·ç»‘å®šåˆ°è¯­è¨€æ¨¡å‹\n",
    "- **å·¥å…·å®šä¹‰**: ä½¿ç”¨ `@tool` è£…é¥°å™¨å°† Python å‡½æ•°è½¬æ¢ä¸º LangChain å·¥å…·\n",
    "- **å›¾æ„å»º**: å†…éƒ¨è‡ªåŠ¨æ„å»º ReAct å·¥ä½œæµç¨‹å›¾ï¼ŒåŒ…å« agent å’Œ tools èŠ‚ç‚¹\n",
    "- **æ¶ˆæ¯å¤„ç†**: æ”¯æŒæ ‡å‡†çš„æ¶ˆæ¯æ ¼å¼è¾“å…¥å’Œè¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-2",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-2ï¼šä½¿ç”¨è‡ªå®šä¹‰ç³»ç»Ÿæç¤º\n",
    "\n",
    "é€šè¿‡ `prompt` å‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥è‡ªå®šä¹‰æ™ºèƒ½ä½“çš„è¡Œä¸ºå’Œå“åº”é£æ ¼ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ç´ç´„ç›®å‰å¯èƒ½æœ‰é›²ï¼Œå¤©æ°£è¼ƒç‚ºé™°æ²‰ã€‚\n"
     ]
    }
   ],
   "source": [
    "# å®šä¹‰ç”¨äºä¸­æ–‡å›å¤çš„è‡ªå®šä¹‰ç³»ç»Ÿæç¤º\n",
    "chinese_prompt = \"è¯·ç”¨ä¸­æ–‡å›å¤æ‰€æœ‰é—®é¢˜\"\n",
    "\n",
    "# ä½¿ç”¨è‡ªå®šä¹‰æç¤ºåˆ›å»º ReAct æ™ºèƒ½ä½“\n",
    "graph_chinese = create_react_agent(model, tools=tools, prompt=chinese_prompt)\n",
    "\n",
    "# ç¤ºä¾‹è°ƒç”¨\n",
    "inputs = {\"messages\": [(\"user\", \"How's the weather in nyc?\")]}\n",
    "response_chinese = graph_chinese.invoke(inputs)\n",
    "print(response_chinese['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-2",
   "metadata": {},
   "source": [
    "**ğŸ’¡ æç¤ºå®šåˆ¶çš„ä»·å€¼**ï¼š\n",
    "\n",
    "- **è¯­è¨€æ§åˆ¶**: æŒ‡å®šå›å¤è¯­è¨€\n",
    "- **è§’è‰²è®¾å®š**: å®šä¹‰æ™ºèƒ½ä½“çš„è§’è‰²å’Œä¸ªæ€§\n",
    "- **è¡Œä¸ºçº¦æŸ**: è®¾ç½®ç‰¹å®šçš„è¡Œä¸ºè§„åˆ™å’Œé™åˆ¶\n",
    "- **é¢†åŸŸé€‚åº”**: ä¸ºç‰¹å®šåº”ç”¨é¢†åŸŸæä¾›ä¸Šä¸‹æ–‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-3",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-3ï¼šæ·»åŠ å¯¹è¯è®°å¿†åŠŸèƒ½\n",
    "\n",
    "é€šè¿‡ `checkpointer` å‚æ•°ï¼Œæ™ºèƒ½ä½“å¯ä»¥è·¨å¤šè½®å¯¹è¯ç»´æŠ¤ä¸Šä¸‹æ–‡ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The current weather in San Francisco is sunny. ğŸŒ San Francisco is known for its mild climate and occasional fog, but today the skies are clear. Hope you enjoy the sunshine!\n",
      "\n",
      "\n",
      "I'm sorry, but I couldn't retrieve the weather information for Chicago. It's possible there was a temporary issue or the city name isn't recognized. Let me know if you'd like to check another city or need further assistance! â˜ï¸â˜€ï¸\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# ... å®šä¹‰æ¨¡å‹å’Œå·¥å…·ï¼ˆä¸ä¹‹å‰ç›¸åŒï¼‰...\n",
    "\n",
    "# åˆå§‹åŒ–å†…å­˜æ£€æŸ¥ç‚¹\n",
    "memory = MemorySaver()\n",
    "\n",
    "# åˆ›å»ºå…·æœ‰è®°å¿†åŠŸèƒ½çš„ ReAct æ™ºèƒ½ä½“\n",
    "graph_with_memory = create_react_agent(model, tools=tools, checkpointer=memory)\n",
    "\n",
    "# é¦–æ¬¡äº¤äº’\n",
    "config = {\"configurable\": {\"thread_id\": \"user_thread_1\"}} # å”¯ä¸€çº¿ç¨‹ ID\n",
    "inputs_1 = {\"messages\": [(\"user\", \"How's the weather in sf?\")]}\n",
    "response_1 = graph_with_memory.invoke(inputs_1, config=config)\n",
    "print(response_1['messages'][-1].content)\n",
    "\n",
    "# åŒä¸€çº¿ç¨‹ä¸­çš„ç¬¬äºŒæ¬¡äº¤äº’ - æ™ºèƒ½ä½“è®°ä½ä¸Šä¸‹æ–‡\n",
    "inputs_2 = {\"messages\": [(\"user\", \"How is chicago?\")]}\n",
    "response_2 = graph_with_memory.invoke(inputs_2, config=config)\n",
    "print(response_2['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-3",
   "metadata": {},
   "source": [
    "**ğŸ’¡ è®°å¿†æœºåˆ¶è§£æ**ï¼š\n",
    "\n",
    "- **çº¿ç¨‹éš”ç¦»**: é€šè¿‡ `thread_id` åŒºåˆ†ä¸åŒçš„å¯¹è¯ä¼šè¯\n",
    "- **çŠ¶æ€æŒä¹…åŒ–**: `MemorySaver` åœ¨å†…å­˜ä¸­ä¿å­˜å¯¹è¯å†å²\n",
    "- **ä¸Šä¸‹æ–‡è¿ç»­æ€§**: æ™ºèƒ½ä½“èƒ½å¤Ÿç†è§£è·¨è½®æ¬¡çš„å¯¹è¯ä¸Šä¸‹æ–‡\n",
    "- **å­˜å‚¨é€‰æ‹©**: ç”Ÿäº§ç¯å¢ƒå¯é€‰æ‹© `RedisSaver` æˆ– `SQLiteSaver`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-4",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-4ï¼šå®ç°äººæœºç¯è·¯å·¥ä½œæµç¨‹\n",
    "\n",
    "é€šè¿‡ `interrupt_before` å‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å…³é”®èŠ‚ç‚¹æš‚åœæ™ºèƒ½ä½“æ‰§è¡Œï¼Œå®ç°äººå·¥ç›‘ç£ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰§è¡Œæ™ºèƒ½ä½“ï¼ˆå°†åœ¨å·¥å…·è°ƒç”¨å‰æš‚åœï¼‰...\n",
      "æ¶ˆæ¯ç±»å‹: HumanMessage\n",
      "å†…å®¹: How's the weather in sf?\n",
      "æ¶ˆæ¯ç±»å‹: AIMessage\n",
      "è®¡åˆ’è°ƒç”¨å·¥å…·: [{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': '0198ebdf1c7d7d658f8d063b41a21d79', 'type': 'tool_call'}]\n",
      ">>> æ™ºèƒ½ä½“å·²æš‚åœï¼Œç­‰å¾…äººå·¥å®¡æ ¸ <<<\n",
      "\n",
      "å½“å‰æ™ºèƒ½ä½“çŠ¶æ€:\n",
      "ä¸‹ä¸€ä¸ªèŠ‚ç‚¹: ('tools',)\n",
      "æ¶ˆæ¯æ•°é‡: 2\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºå¯ç”¨äººæœºç¯è·¯çš„ ReAct æ™ºèƒ½ä½“ - åœ¨å·¥å…·è°ƒç”¨å‰ä¸­æ–­\n",
    "graph_hitl = create_react_agent(model, tools=tools, interrupt_before=[\"tools\"], checkpointer=memory)\n",
    "\n",
    "# é¦–æ¬¡äº¤äº’ - æ™ºèƒ½ä½“å°†åœ¨å·¥å…·è°ƒç”¨ä¹‹å‰æš‚åœ\n",
    "config_hitl = {\"configurable\": {\"thread_id\": \"user_thread_hitl\"}}\n",
    "inputs_hitl = {\"messages\": [(\"user\", \"How's the weather in sf?\")]}\n",
    "\n",
    "print(\"æ‰§è¡Œæ™ºèƒ½ä½“ï¼ˆå°†åœ¨å·¥å…·è°ƒç”¨å‰æš‚åœï¼‰...\")\n",
    "stream = graph_hitl.stream(inputs_hitl, config=config_hitl, stream_mode=\"values\")\n",
    "for output in stream:\n",
    "    if 'messages' in output and output['messages']:\n",
    "        last_message = output['messages'][-1]\n",
    "        print(f\"æ¶ˆæ¯ç±»å‹: {type(last_message).__name__}\")\n",
    "        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "            print(f\"è®¡åˆ’è°ƒç”¨å·¥å…·: {last_message.tool_calls}\")\n",
    "            print(\">>> æ™ºèƒ½ä½“å·²æš‚åœï¼Œç­‰å¾…äººå·¥å®¡æ ¸ <<<\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"å†…å®¹: {last_message.content}\")\n",
    "\n",
    "# æ£€æŸ¥å½“å‰çŠ¶æ€\n",
    "print(\"\\nå½“å‰æ™ºèƒ½ä½“çŠ¶æ€:\")\n",
    "current_state = graph_hitl.get_state(config_hitl)\n",
    "print(f\"ä¸‹ä¸€ä¸ªèŠ‚ç‚¹: {current_state.next}\")\n",
    "print(f\"æ¶ˆæ¯æ•°é‡: {len(current_state.values['messages'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-4",
   "metadata": {},
   "source": [
    "**ğŸ’¡ äººæœºç¯è·¯çš„æ ¸å¿ƒä»·å€¼**ï¼š\n",
    "\n",
    "- **å®‰å…¨æ§åˆ¶**: åœ¨æ‰§è¡Œæ•æ„Ÿæ“ä½œå‰å¼•å…¥äººå·¥å®¡æ ¸\n",
    "- **è´¨é‡ä¿è¯**: ç¡®ä¿å·¥å…·è°ƒç”¨çš„å‡†ç¡®æ€§å’Œåˆç†æ€§\n",
    "- **é£é™©ç®¡ç†**: é˜²æ­¢è‡ªåŠ¨åŒ–ç³»ç»Ÿæ‰§è¡Œä¸å½“æ“ä½œ\n",
    "- **å­¦ä¹ æœºä¼š**: é€šè¿‡äººå·¥åé¦ˆæ”¹è¿›æ™ºèƒ½ä½“å†³ç­–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-5",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-5ï¼šç»“æ„åŒ–è¾“å‡ºå“åº”\n",
    "\n",
    "ä½¿ç”¨ `response_format` å‚æ•°ï¼Œæ™ºèƒ½ä½“å¯ä»¥è¿”å›ç¬¦åˆé¢„å®šä¹‰ç»“æ„çš„å“åº”ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# å®šä¹‰ç»“æ„åŒ–è¾“å‡ºçš„ Pydantic æ¨¡å‹\n",
    "class WeatherResponse(BaseModel):\n",
    "    \"\"\"Respond with a weather description.\"\"\"\n",
    "    city: str = Field(description=\"The city name\")\n",
    "    conditions: str = Field(description=\"Weather conditions description\")\n",
    "    temperature: str = Field(description=\"Temperature information\")\n",
    "    confidence: str = Field(description=\"Confidence level of the weather data\")\n",
    "\n",
    "# æ³¨æ„ï¼šç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½éœ€è¦æ”¯æŒåŸç”Ÿç»“æ„åŒ–è¾“å‡ºçš„æ¨¡å‹\n",
    "# è¿™é‡Œæˆ‘ä»¬æ¼”ç¤ºæ¦‚å¿µï¼Œå®é™…ä½¿ç”¨æ—¶è¯·ç¡®ä¿æ¨¡å‹æ”¯æŒï¼Œå»ºè®®ä½¿ç”¨ OpenAI æ¨¡å‹å®éªŒ\n",
    "try:\n",
    "    # åˆ›å»ºå¯ç”¨ç»“æ„åŒ–è¾“å‡ºçš„ ReAct æ™ºèƒ½ä½“\n",
    "    graph_structured = create_react_agent(model, tools=tools, response_format=WeatherResponse)\n",
    "    \n",
    "    # ç¤ºä¾‹è°ƒç”¨\n",
    "    inputs_structured = {\"messages\": [(\"user\", \"How's the weather in sf?\")]}\n",
    "    response_structured = graph_structured.invoke(inputs_structured)\n",
    "    \n",
    "    # è®¿é—®ç»“æ„åŒ–å“åº”\n",
    "    if \"structured_response\" in response_structured:\n",
    "        structured_data = response_structured[\"structured_response\"]\n",
    "        print(\"ç»“æ„åŒ–å¤©æ°”å“åº”:\")\n",
    "        print(f\"åŸå¸‚: {structured_data.city}\")\n",
    "        print(f\"å¤©æ°”çŠ¶å†µ: {structured_data.conditions}\")\n",
    "        print(f\"æ¸©åº¦: {structured_data.temperature}\")\n",
    "        print(f\"ç½®ä¿¡åº¦: {structured_data.confidence}\")\n",
    "    else:\n",
    "        print(\"å¸¸è§„å“åº”:\", response_structured['messages'][-1].content)\n",
    "except Exception as e:\n",
    "    print(f\"ç»“æ„åŒ–è¾“å‡ºç¤ºä¾‹è·³è¿‡ (éœ€è¦å…¼å®¹æ¨¡å‹): {e}\")\n",
    "    print(\"ä½¿ç”¨å¸¸è§„è¾“å‡ºè¿›è¡Œæ¼”ç¤º...\")\n",
    "    regular_response = graph.invoke({\"messages\": [(\"user\", \"How's the weather in sf?\")]})\n",
    "    print(regular_response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-5",
   "metadata": {},
   "source": [
    "**ğŸ’¡ ç»“æ„åŒ–è¾“å‡ºçš„åº”ç”¨åœºæ™¯**ï¼š\n",
    "\n",
    "- **API é›†æˆ**: ä¸ä¸‹æ¸¸ç³»ç»Ÿçš„æ ‡å‡†åŒ–æ•°æ®äº¤æ¢\n",
    "- **æ•°æ®å¤„ç†**: ä¾¿äºç¨‹åºåŒ–å¤„ç†å’Œåˆ†æ\n",
    "- **ç”¨æˆ·ç•Œé¢**: ä¸ºå‰ç«¯æä¾›ç»“æ„åŒ–çš„å±•ç¤ºæ•°æ®\n",
    "- **è´¨é‡æ§åˆ¶**: ç¡®ä¿è¾“å‡ºæ ¼å¼çš„ä¸€è‡´æ€§å’Œå®Œæ•´æ€§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6-2",
   "metadata": {},
   "source": [
    "## 6.2 Functional APIï¼šæ‹¥æŠ±å·¥ä½œæµè®¾è®¡çš„ç®€æ´æ€§å’Œç†Ÿæ‚‰æ€§\n",
    "\n",
    "Functional API ä½œä¸º Graph API çš„è¡¥å……ï¼Œæ—¨åœ¨æä¾›ä¸€ç§æ›´ç®€æ´ã€æ›´ç›´è§‚ã€æ›´è´´è¿‘ä¼ ç»Ÿç¼–ç¨‹ä¹ æƒ¯çš„å·¥ä½œæµæ„å»ºæ–¹å¼ã€‚å®ƒåœ¨ä¿ç•™ LangGraph æ ¸å¿ƒåŠŸèƒ½çš„åŒæ—¶ï¼Œè®©å¼€å‘è€…èƒ½å¤Ÿä½¿ç”¨ç†Ÿæ‚‰çš„ Python å‡½æ•°å’Œè£…é¥°å™¨æ¥å®šä¹‰å·¥ä½œæµã€‚\n",
    "\n",
    "### è®¾è®¡ç†å¿µ\n",
    "- **é™ä½å­¦ä¹ é—¨æ§›**: å¯¹æ–°æ‰‹å¼€å‘äººå‘˜æ›´åŠ å‹å¥½\n",
    "- **ä»£ç é›†æˆæ€§**: ä¸ç°æœ‰ Python ä»£ç åº“æ— ç¼é›†æˆ\n",
    "- **å¿«é€Ÿå¼€å‘**: å‡å°‘æ ·æ¿ä»£ç ï¼ŒåŠ é€ŸåŸå‹è®¾è®¡\n",
    "- **åŠŸèƒ½å®Œæ•´æ€§**: æ”¯æŒæŒä¹…æ€§ã€å†…å­˜ã€äººæœºç¯è·¯å’Œæµå¼ä¼ è¾“\n",
    "\n",
    "### æ ¸å¿ƒç»„ä»¶ï¼š`@entrypoint` å’Œ `@task`\n",
    "\n",
    "Functional API åŸºäºä¸¤ä¸ªåŸºæœ¬è£…é¥°å™¨æ„å»ºï¼š\n",
    "- **`@entrypoint`**: å®šä¹‰å·¥ä½œæµçš„å…¥å£ç‚¹å’Œè¾¹ç•Œ\n",
    "- **`@task`**: å°è£…ç‹¬ç«‹çš„å·¥ä½œå•å…ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-6",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-6ï¼šå…·æœ‰å‚æ•°ç”¨æ³•çš„å¤æ‚ `@entrypoint` å‡½æ•°\n",
    "\n",
    "å±•ç¤º `@entrypoint` è£…é¥°å™¨çš„é«˜çº§ç”¨æ³•ï¼ŒåŒ…æ‹¬æ‰€æœ‰å¯æ³¨å…¥å‚æ•°ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ä½¿ç”¨ invoke æ‰§è¡Œ ===\n",
      "ç»“æœ: å·¥ä½œæµå¤„ç†çš„è¾“å…¥ï¼š{'message': 'Hello'}, æ‰§è¡Œæ¬¡æ•°: 1\n",
      "\n",
      "=== ä½¿ç”¨ stream æ‰§è¡Œ ===\n",
      "æµå¼æ•°æ®: ('custom', \"å·¥ä½œæµ 'complex_workflow_1' å·²å¯åŠ¨\")\n",
      "æµå¼æ•°æ®: ('custom', \"å‘ç°å…ˆå‰çŠ¶æ€: å·¥ä½œæµå¤„ç†çš„è¾“å…¥ï¼š{'message': 'Hello'}, æ‰§è¡Œæ¬¡æ•°: 1\")\n",
      "æµå¼æ•°æ®: ('custom', 'æ›´æ–°è®¡æ•°å™¨: 2')\n",
      "æµå¼æ•°æ®: ('custom', 'å·¥ä½œæµå¤„ç†å®Œæˆ')\n",
      "æµå¼æ•°æ®: ('updates', {'my_workflow': \"å·¥ä½œæµå¤„ç†çš„è¾“å…¥ï¼š{'message': 'World'}, æ‰§è¡Œæ¬¡æ•°: 2\"})\n"
     ]
    }
   ],
   "source": [
    "from langgraph.func import entrypoint\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.memory import InMemoryStore, BaseStore\n",
    "from langgraph.types import StreamWriter\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing import Any\n",
    "\n",
    "store = InMemoryStore()\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "@entrypoint(checkpointer=checkpointer, store=store)\n",
    "def my_workflow(\n",
    "    user_input: dict, # è¾“å…¥å‚æ•°\n",
    "    *,\n",
    "    previous: Any = None, # ç”¨äºå…ˆå‰çŠ¶æ€çš„å¯æ³¨å…¥å‚æ•°\n",
    "    store: BaseStore,    # ç”¨äºé•¿æœŸå†…å­˜å­˜å‚¨çš„å¯æ³¨å…¥å‚æ•°\n",
    "    writer: StreamWriter, # ç”¨äºè‡ªå®šä¹‰æµå†™å…¥å™¨çš„å¯æ³¨å…¥å‚æ•°\n",
    "    config: RunnableConfig # ç”¨äºè¿è¡Œæ—¶é…ç½®çš„å¯æ³¨å…¥å‚æ•°\n",
    ") -> str:\n",
    "    \"\"\"ä¸€ä¸ªå¤æ‚çš„æ¼”ç¤ºå…¥å£ç‚¹å‚æ•°çš„å·¥ä½œæµã€‚\"\"\"\n",
    "    thread_id = config.get(\"configurable\", {}).get(\"thread_id\", \"unknown\")\n",
    "    \n",
    "    # å‘å®¢æˆ·ç«¯æµå¼ä¼ è¾“è‡ªå®šä¹‰ä¿¡æ¯\n",
    "    writer(f\"å·¥ä½œæµ '{thread_id}' å·²å¯åŠ¨\")\n",
    "    \n",
    "    # æ£€æŸ¥å…ˆå‰çŠ¶æ€\n",
    "    if previous:\n",
    "        writer(f\"å‘ç°å…ˆå‰çŠ¶æ€: {previous}\")\n",
    "    else:\n",
    "        writer(\"è¿™æ˜¯é¦–æ¬¡æ‰§è¡Œ\")\n",
    "    \n",
    "    # è®¿é—®é•¿æœŸå­˜å‚¨\n",
    "    try:\n",
    "        stored_data = store.get((\"demo\", \"counter\"), \"value\")\n",
    "        if stored_data:\n",
    "            counter = stored_data.value + 1\n",
    "        else:\n",
    "            counter = 1\n",
    "        store.put((\"demo\", \"counter\"), \"value\", counter)\n",
    "        writer(f\"æ›´æ–°è®¡æ•°å™¨: {counter}\")\n",
    "    except Exception as e:\n",
    "        writer(f\"å­˜å‚¨æ“ä½œé”™è¯¯: {e}\")\n",
    "        counter = 1\n",
    "    \n",
    "    result = f\"å·¥ä½œæµå¤„ç†çš„è¾“å…¥ï¼š{user_input}, æ‰§è¡Œæ¬¡æ•°: {counter}\"\n",
    "    writer(\"å·¥ä½œæµå¤„ç†å®Œæˆ\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ç¤ºä¾‹è°ƒç”¨\n",
    "config = {\"configurable\": {\"thread_id\": \"complex_workflow_1\"}}\n",
    "print(\"=== ä½¿ç”¨ invoke æ‰§è¡Œ ===\")\n",
    "result = my_workflow.invoke({\"message\": \"Hello\"}, config)\n",
    "print(f\"ç»“æœ: {result}\")\n",
    "print()\n",
    "\n",
    "# ä½¿ç”¨æµå¼æ‰§è¡ŒæŸ¥çœ‹ä¸­é—´è¿‡ç¨‹\n",
    "print(\"=== ä½¿ç”¨ stream æ‰§è¡Œ ===\")\n",
    "for chunk in my_workflow.stream({\"message\": \"World\"}, config, stream_mode=[\"custom\", \"updates\"]):\n",
    "    print(f\"æµå¼æ•°æ®: {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-6",
   "metadata": {},
   "source": [
    "**ğŸ’¡ `@entrypoint` é«˜çº§ç‰¹æ€§è§£æ**ï¼š\n",
    "\n",
    "- **å¯æ³¨å…¥å‚æ•°**: `previous`ã€`store`ã€`writer`ã€`config` ç”±è¿è¡Œæ—¶è‡ªåŠ¨æ³¨å…¥\n",
    "- **çŠ¶æ€æŒä¹…åŒ–**: é€šè¿‡ `checkpointer` å‚æ•°å®ç°è·¨æ‰§è¡ŒçŠ¶æ€ä¿å­˜\n",
    "- **é•¿æœŸå­˜å‚¨**: `store` å‚æ•°æä¾›æŒä¹…åŒ–å­˜å‚¨èƒ½åŠ›\n",
    "- **å®æ—¶æµå¼ä¼ è¾“**: `writer` æ”¯æŒè‡ªå®šä¹‰æ•°æ®æµå¼è¾“å‡º\n",
    "- **è¿è¡Œæ—¶é…ç½®**: `config` æä¾›æ‰§è¡Œæ—¶çš„é…ç½®ä¿¡æ¯è®¿é—®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-7",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-7ï¼šå¸¦æœ‰é‡è¯•ç­–ç•¥çš„ `@task` å‡½æ•°\n",
    "\n",
    "æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ `@task` è£…é¥°å™¨çš„é‡è¯•åŠŸèƒ½æ¥å¤„ç†ä¸å¯é çš„æ“ä½œï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æµ‹è¯•å¸¦é‡è¯•ç­–ç•¥çš„ä»»åŠ¡...\n",
      "å°è¯•ä» https://api.example.com/data è·å–æ•°æ®...\n",
      "API è¯·æ±‚è¶…æ—¶ï¼\n",
      "å°è¯•ä» https://api.example.com/data è·å–æ•°æ®...\n",
      "API è¯·æ±‚è¶…æ—¶ï¼\n",
      "å°è¯•ä» https://api.example.com/data è·å–æ•°æ®...\n",
      "API è¯·æ±‚æˆåŠŸï¼\n",
      "\n",
      "æœ€ç»ˆç»“æœ: {'workflow_result': 'æ•°æ®å·²å¤„ç†', 'api_response': {'status': 'success', 'data': 'æ¥è‡ª https://api.example.com/data çš„æ•°æ®'}}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.func import task\n",
    "from langgraph.types import RetryPolicy\n",
    "import time\n",
    "import random\n",
    "\n",
    "# å®šä¹‰é‡è¯•ç­–ç•¥\n",
    "retry_policy = RetryPolicy(max_attempts=3, retry_on=TimeoutError)\n",
    "\n",
    "@task(name=\"api_data_fetcher\", retry_policy=retry_policy)\n",
    "def fetch_api_data(api_endpoint: str) -> dict:\n",
    "    \"\"\"ä»å¸¦æœ‰é‡è¯•ç­–ç•¥çš„ API ç«¯ç‚¹è·å–æ•°æ®çš„ä»»åŠ¡ã€‚\"\"\"\n",
    "    print(f\"å°è¯•ä» {api_endpoint} è·å–æ•°æ®...\")\n",
    "    time.sleep(random.uniform(0.1, 0.5)) # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ\n",
    "    \n",
    "    if random.random() < 0.8: # æ¨¡æ‹Ÿ 60% çš„è¶…æ—¶æ¦‚ç‡\n",
    "        print(\"API è¯·æ±‚è¶…æ—¶ï¼\")\n",
    "        raise TimeoutError(\"API è¯·æ±‚è¶…æ—¶\")\n",
    "    \n",
    "    print(\"API è¯·æ±‚æˆåŠŸï¼\")\n",
    "    return {\"status\": \"success\", \"data\": f\"æ¥è‡ª {api_endpoint} çš„æ•°æ®\"}\n",
    "\n",
    "# åœ¨å…¥å£ç‚¹å†…è°ƒç”¨ä»»åŠ¡çš„ç¤ºä¾‹\n",
    "@entrypoint(checkpointer=MemorySaver())\n",
    "def data_processing_workflow(endpoint_url: str) -> dict:\n",
    "    \"\"\"è°ƒç”¨ fetch_api_data ä»»åŠ¡çš„å·¥ä½œæµã€‚\"\"\"\n",
    "    try:\n",
    "        api_result = fetch_api_data(api_endpoint=endpoint_url).result()\n",
    "        return {\"workflow_result\": \"æ•°æ®å·²å¤„ç†\", \"api_response\": api_result}\n",
    "    except TimeoutError as e:\n",
    "        return {\"workflow_result\": \"å¤„ç†å¤±è´¥\", \"error\": str(e)}\n",
    "\n",
    "# æµ‹è¯•é‡è¯•æœºåˆ¶\n",
    "config = {\"configurable\": {\"thread_id\": \"task_params_workflow_1\"}}\n",
    "print(\"æµ‹è¯•å¸¦é‡è¯•ç­–ç•¥çš„ä»»åŠ¡...\")\n",
    "result = data_processing_workflow.invoke(\"https://api.example.com/data\", config)\n",
    "print(f\"\\næœ€ç»ˆç»“æœ: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-7",
   "metadata": {},
   "source": [
    "**ğŸ’¡ `@task` é‡è¯•æœºåˆ¶çš„ä¼˜åŠ¿**ï¼š\n",
    "\n",
    "- **å®¹é”™èƒ½åŠ›**: è‡ªåŠ¨å¤„ç†ç¬æ—¶ç½‘ç»œé”™è¯¯å’ŒæœåŠ¡ä¸å¯ç”¨\n",
    "- **æŒ‡å®šå¼‚å¸¸**: `retry_on` å‚æ•°å…è®¸é’ˆå¯¹ç‰¹å®šå¼‚å¸¸ç±»å‹é‡è¯•\n",
    "- **è‡ªå®šä¹‰ç­–ç•¥**: å¯é…ç½®æœ€å¤§é‡è¯•æ¬¡æ•°å’Œé‡è¯•æ¡ä»¶\n",
    "- **ä»»åŠ¡éš”ç¦»**: é‡è¯•é€»è¾‘å°è£…åœ¨ä»»åŠ¡çº§åˆ«ï¼Œä¸å½±å“æ•´ä½“å·¥ä½œæµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-8",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-8ï¼šåŒ…å«æ§åˆ¶æµå’Œä»»åŠ¡è°ƒç”¨çš„å·¥ä½œæµé€»è¾‘\n",
    "\n",
    "å±•ç¤ºåœ¨ `@entrypoint` ä¸­ä½¿ç”¨ Python æ§åˆ¶æµå’Œä»»åŠ¡è°ƒç”¨æ„å»ºæ¡ä»¶é€»è¾‘ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æµ‹è¯•å¶æ•° ===\n",
      "å¤„ç†æ•°å­—: 4\n",
      "æ£€æŸ¥ 4 æ˜¯å¦ä¸ºå¶æ•°...\n",
      "å°† 4 ä¹˜ä»¥ 2...\n",
      "ç»“æœ: {'input': 4, 'is_even': True, 'operation': 'ä¹˜ä»¥2', 'result': 8}\n",
      "\n",
      "=== æµ‹è¯•å¥‡æ•° ===\n",
      "å¤„ç†æ•°å­—: 5\n",
      "æ£€æŸ¥ 5 æ˜¯å¦ä¸ºå¶æ•°...\n",
      "å°† 5 åŠ  10...\n",
      "ç»“æœ: {'input': 5, 'is_even': False, 'operation': 'åŠ 10', 'result': 15}\n"
     ]
    }
   ],
   "source": [
    "@task\n",
    "def is_even(number: int) -> bool:\n",
    "    \"\"\"æ£€æŸ¥æ•°å­—æ˜¯å¦ä¸ºå¶æ•°çš„ä»»åŠ¡ã€‚\"\"\"\n",
    "    print(f\"æ£€æŸ¥ {number} æ˜¯å¦ä¸ºå¶æ•°...\")\n",
    "    return number % 2 == 0\n",
    "\n",
    "@task\n",
    "def multiply_by_two(number: int) -> int:\n",
    "    \"\"\"å°†æ•°å­—ä¹˜ä»¥äºŒçš„ä»»åŠ¡ã€‚\"\"\"\n",
    "    print(f\"å°† {number} ä¹˜ä»¥ 2...\")\n",
    "    return number * 2\n",
    "\n",
    "@task\n",
    "def add_ten(number: int) -> int:\n",
    "    \"\"\"å°†æ•°å­—åŠ åçš„ä»»åŠ¡ã€‚\"\"\"\n",
    "    print(f\"å°† {number} åŠ  10...\")\n",
    "    return number + 10\n",
    "\n",
    "@entrypoint(checkpointer=MemorySaver())\n",
    "def number_workflow(input_number: int) -> dict:\n",
    "    \"\"\"æ ¹æ®æ•°å­—æ˜¯å¥‡æ•°è¿˜æ˜¯å¶æ•°å¤„ç†æ•°å­—çš„å·¥ä½œæµã€‚\"\"\"\n",
    "    print(f\"å¤„ç†æ•°å­—: {input_number}\")\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦ä¸ºå¶æ•°\n",
    "    is_even_result = is_even(input_number).result()\n",
    "    \n",
    "    if is_even_result:\n",
    "        # å¶æ•°ï¼šä¹˜ä»¥2\n",
    "        result = multiply_by_two(input_number).result()\n",
    "        operation = \"ä¹˜ä»¥2\"\n",
    "    else:\n",
    "        # å¥‡æ•°ï¼šåŠ 10\n",
    "        result = add_ten(input_number).result()\n",
    "        operation = \"åŠ 10\"\n",
    "    \n",
    "    return {\n",
    "        \"input\": input_number,\n",
    "        \"is_even\": is_even_result,\n",
    "        \"operation\": operation,\n",
    "        \"result\": result\n",
    "    }\n",
    "\n",
    "# æµ‹è¯•ä¸åŒæ•°å­—\n",
    "config = {\"configurable\": {\"thread_id\": \"number_workflow_1\"}}\n",
    "\n",
    "print(\"=== æµ‹è¯•å¶æ•° ===\")\n",
    "result_even = number_workflow.invoke(4, config)\n",
    "print(f\"ç»“æœ: {result_even}\")\n",
    "print()\n",
    "\n",
    "print(\"=== æµ‹è¯•å¥‡æ•° ===\")\n",
    "result_odd = number_workflow.invoke(5, config)\n",
    "print(f\"ç»“æœ: {result_odd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-8",
   "metadata": {},
   "source": [
    "**ğŸ’¡ æ§åˆ¶æµåœ¨ Functional API ä¸­çš„åº”ç”¨**ï¼š\n",
    "\n",
    "- **æ¡ä»¶åˆ†æ”¯**: ä½¿ç”¨æ ‡å‡† Python `if/else` è¯­å¥å®ç°å·¥ä½œæµåˆ†æ”¯\n",
    "- **ä»»åŠ¡ç¼–æ’**: é€šè¿‡ `.result()` æ–¹æ³•åŒæ­¥è·å–ä»»åŠ¡æ‰§è¡Œç»“æœ\n",
    "- **çŠ¶æ€ä¼ é€’**: ä»»åŠ¡ç»“æœå¯ä½œä¸ºåç»­ä»»åŠ¡çš„è¾“å…¥\n",
    "- **çµæ´»ç»„åˆ**: å¯ä»¥æ ¹æ®ä¸šåŠ¡é€»è¾‘åŠ¨æ€ç»„åˆä¸åŒçš„ä»»åŠ¡æ‰§è¡Œè·¯å¾„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-9",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-9ï¼šä½¿ç”¨ `invoke` åŒæ­¥æ‰§è¡Œå·¥ä½œæµ\n",
    "\n",
    "æ¼”ç¤ºåŒæ­¥å·¥ä½œæµæ‰§è¡Œçš„åŸºæœ¬æ¨¡å¼ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰§è¡ŒåŒæ­¥å·¥ä½œæµ...\n",
      "åŒæ­¥ç»“æœ: å·¥ä½œæµå®Œæˆ: å·²å¤„ç†: HELLO WORLD\n",
      "è°ƒç”¨ 1: å·¥ä½œæµå®Œæˆ: å·²å¤„ç†: APPLE\n",
      "è°ƒç”¨ 2: å·¥ä½œæµå®Œæˆ: å·²å¤„ç†: BANANA\n",
      "è°ƒç”¨ 3: å·¥ä½œæµå®Œæˆ: å·²å¤„ç†: CHERRY\n"
     ]
    }
   ],
   "source": [
    "@task\n",
    "def process_data(data: str) -> str:\n",
    "    \"\"\"å¤„ç†æ•°æ®çš„ç®€å•ä»»åŠ¡ã€‚\"\"\"\n",
    "    time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´\n",
    "    return f\"å·²å¤„ç†: {data.upper()}\"\n",
    "\n",
    "@entrypoint(checkpointer=MemorySaver())\n",
    "def simple_workflow(input_data: str) -> str:\n",
    "    \"\"\"ç®€å•çš„æ•°æ®å¤„ç†å·¥ä½œæµã€‚\"\"\"\n",
    "    processed = process_data(input_data).result()\n",
    "    return f\"å·¥ä½œæµå®Œæˆ: {processed}\"\n",
    "\n",
    "# åŒæ­¥æ‰§è¡Œç¤ºä¾‹\n",
    "config = {\"configurable\": {\"thread_id\": \"sync_workflow_1\"}}\n",
    "print(\"æ‰§è¡ŒåŒæ­¥å·¥ä½œæµ...\")\n",
    "result = simple_workflow.invoke(\"hello world\", config)\n",
    "print(f\"åŒæ­¥ç»“æœ: {result}\")\n",
    "\n",
    "# å¤šæ¬¡è°ƒç”¨åŒä¸€å·¥ä½œæµ\n",
    "inputs = [\"apple\", \"banana\", \"cherry\"]\n",
    "for i, data in enumerate(inputs, 1):\n",
    "    config[\"configurable\"][\"thread_id\"] = f\"sync_workflow_{i}\"\n",
    "    result = simple_workflow.invoke(data, config)\n",
    "    print(f\"è°ƒç”¨ {i}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-9",
   "metadata": {},
   "source": [
    "**ğŸ’¡ åŒæ­¥æ‰§è¡Œçš„ç‰¹ç‚¹**ï¼š\n",
    "\n",
    "- **é˜»å¡æ‰§è¡Œ**: `invoke` æ–¹æ³•ä¼šç­‰å¾…å·¥ä½œæµå®Œå…¨æ‰§è¡Œå®Œæ¯•\n",
    "- **ç®€å•ç›´æ¥**: é€‚åˆä¸éœ€è¦å®æ—¶åé¦ˆçš„åœºæ™¯\n",
    "- **é”™è¯¯å¤„ç†**: æ‰§è¡Œè¿‡ç¨‹ä¸­çš„å¼‚å¸¸ä¼šç›´æ¥æŠ›å‡º\n",
    "- **çº¿ç¨‹éš”ç¦»**: æ¯ä¸ª `thread_id` ç»´æŠ¤ç‹¬ç«‹çš„çŠ¶æ€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-10",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-10ï¼šä½¿ç”¨ `stream` æµå¼æ‰§è¡Œå·¥ä½œæµ\n",
    "\n",
    "æ¼”ç¤ºæµå¼æ‰§è¡Œï¼Œæä¾›å®æ—¶æ‰§è¡Œè¿›åº¦åé¦ˆï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰§è¡Œæµå¼å·¥ä½œæµï¼ˆè§‚å¯Ÿæ‰§è¡Œè¿›åº¦ï¼‰...\n",
      "==================================================\n",
      "æµå¼æ›´æ–° 1: ('updates', {'step_one': 'æ­¥éª¤1å®Œæˆ: æµ‹è¯•æ•°æ®'})\n",
      "æµå¼æ›´æ–° 2: ('updates', {'step_two': 'æ­¥éª¤2å®Œæˆ: æ­¥éª¤1å®Œæˆ: æµ‹è¯•æ•°æ®'})\n",
      "æµå¼æ›´æ–° 3: ('updates', {'step_three': 'æ­¥éª¤3å®Œæˆ: æ­¥éª¤2å®Œæˆ: æ­¥éª¤1å®Œæˆ: æµ‹è¯•æ•°æ®'})\n",
      "æµå¼æ›´æ–° 4: ('updates', {'multi_step_workflow': 'æœ€ç»ˆç»“æœ: æ­¥éª¤3å®Œæˆ: æ­¥éª¤2å®Œæˆ: æ­¥éª¤1å®Œæˆ: æµ‹è¯•æ•°æ®'})\n",
      "==================================================\n",
      "æµå¼æ‰§è¡Œå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "@task\n",
    "def step_one(data: str) -> str:\n",
    "    \"\"\"ç¬¬ä¸€ä¸ªå¤„ç†æ­¥éª¤ã€‚\"\"\"\n",
    "    time.sleep(0.2)\n",
    "    return f\"æ­¥éª¤1å®Œæˆ: {data}\"\n",
    "\n",
    "@task\n",
    "def step_two(data: str) -> str:\n",
    "    \"\"\"ç¬¬äºŒä¸ªå¤„ç†æ­¥éª¤ã€‚\"\"\"\n",
    "    time.sleep(0.2)\n",
    "    return f\"æ­¥éª¤2å®Œæˆ: {data}\"\n",
    "\n",
    "@task\n",
    "def step_three(data: str) -> str:\n",
    "    \"\"\"ç¬¬ä¸‰ä¸ªå¤„ç†æ­¥éª¤ã€‚\"\"\"\n",
    "    time.sleep(0.2)\n",
    "    return f\"æ­¥éª¤3å®Œæˆ: {data}\"\n",
    "\n",
    "@entrypoint(checkpointer=MemorySaver())\n",
    "def multi_step_workflow(input_data: str) -> str:\n",
    "    \"\"\"å¤šæ­¥éª¤å·¥ä½œæµï¼Œå±•ç¤ºæµå¼æ‰§è¡Œã€‚\"\"\"\n",
    "    result1 = step_one(input_data).result()\n",
    "    result2 = step_two(result1).result()\n",
    "    result3 = step_three(result2).result()\n",
    "    \n",
    "    return f\"æœ€ç»ˆç»“æœ: {result3}\"\n",
    "\n",
    "# æµå¼æ‰§è¡Œç¤ºä¾‹\n",
    "config = {\"configurable\": {\"thread_id\": \"stream_workflow_1\"}}\n",
    "print(\"æ‰§è¡Œæµå¼å·¥ä½œæµï¼ˆè§‚å¯Ÿæ‰§è¡Œè¿›åº¦ï¼‰...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, chunk in enumerate(multi_step_workflow.stream(\"æµ‹è¯•æ•°æ®\", config, stream_mode=[\"updates\"]), 1):\n",
    "    print(f\"æµå¼æ›´æ–° {i}: {chunk}\")\n",
    "    time.sleep(0.1)  # ç¨å¾®å»¶è¿Ÿä»¥ä¾¿è§‚å¯Ÿ\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"æµå¼æ‰§è¡Œå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-10",
   "metadata": {},
   "source": [
    "**ğŸ’¡ æµå¼æ‰§è¡Œçš„ä¼˜åŠ¿**ï¼š\n",
    "\n",
    "- **å®æ—¶åé¦ˆ**: ç”¨æˆ·å¯ä»¥çœ‹åˆ°å·¥ä½œæµçš„æ‰§è¡Œè¿›åº¦\n",
    "- **æ”¹å–„ä½“éªŒ**: é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ä¸ä¼šè®©ç”¨æˆ·æ„Ÿåˆ°ç­‰å¾…\n",
    "- **æ—©æœŸå‘ç°**: å¯ä»¥åŠæ—¶å‘ç°æ‰§è¡Œè¿‡ç¨‹ä¸­çš„é—®é¢˜\n",
    "- **çµæ´»ç›‘æ§**: æ”¯æŒå¤šç§æµæ¨¡å¼ï¼ˆupdatesã€messagesã€customï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-11",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-11ï¼šä½¿ç”¨ `Command` å¯¹è±¡æ¢å¤å·¥ä½œæµ\n",
    "\n",
    "æ¼”ç¤ºäººæœºç¯è·¯ä¸­æ–­åçš„å·¥ä½œæµæ¢å¤æœºåˆ¶ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ç¬¬ä¸€é˜¶æ®µï¼šæ‰§è¡Œå·¥ä½œæµç›´åˆ°ä¸­æ–­ ===\n",
      "è¯·æ±‚å®¡æ ¸: åˆ›å»ºæ–°ç”¨æˆ·è´¦æˆ·\n",
      "æ‰§è¡Œæ›´æ–°: ('updates', {'__interrupt__': (Interrupt(value='è¯·å®¡æ ¸ä»¥ä¸‹è¯·æ±‚: åˆ›å»ºæ–°ç”¨æˆ·è´¦æˆ·', id='c6d55bc69a12e9beeb9c2842c724e19c'),)})\n",
      "\n",
      "=== æ£€æŸ¥å·¥ä½œæµçŠ¶æ€ ===\n",
      "å·¥ä½œæµæ˜¯å¦å·²ä¸­æ–­: True\n",
      "ç­‰å¾…ä¸­æ–­çš„ä»»åŠ¡æ•°é‡: 1\n",
      "ä»»åŠ¡ 1: PregelTask(id='3cf1d38b-ce07-0a90-82ad-4d6b4edc4aca', name='approval_workflow', path=('__pregel_pull', 'approval_workflow'), error=None, interrupts=(Interrupt(value='è¯·å®¡æ ¸ä»¥ä¸‹è¯·æ±‚: åˆ›å»ºæ–°ç”¨æˆ·è´¦æˆ·', id='c6d55bc69a12e9beeb9c2842c724e19c'),), state=None, result=None)\n",
      "\n",
      "=== ç¬¬äºŒé˜¶æ®µï¼šæä¾›äººå·¥åé¦ˆå¹¶æ¢å¤ ===\n",
      "æä¾›äººå·¥åé¦ˆå¹¶æ¢å¤å·¥ä½œæµ...\n",
      "è¯·æ±‚å®¡æ ¸: åˆ›å»ºæ–°ç”¨æˆ·è´¦æˆ·\n",
      "æ¢å¤æ‰§è¡Œ: ('updates', {'require_approval': 'è¯·æ±‚å·²æ‰¹å‡†: åˆ›å»ºæ–°ç”¨æˆ·è´¦æˆ·'})\n",
      "æ¢å¤æ‰§è¡Œ: ('updates', {'process_approved_request': 'å¤„ç†å®Œæˆ: è¯·æ±‚å·²æ‰¹å‡†: åˆ›å»ºæ–°ç”¨æˆ·è´¦æˆ·'})\n",
      "æ¢å¤æ‰§è¡Œ: ('updates', {'approval_workflow': 'å¤„ç†å®Œæˆ: è¯·æ±‚å·²æ‰¹å‡†: åˆ›å»ºæ–°ç”¨æˆ·è´¦æˆ·'})\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "@task\n",
    "def require_approval(request: str) -> str:\n",
    "    \"\"\"éœ€è¦äººå·¥å®¡æ ¸çš„ä»»åŠ¡ã€‚\"\"\"\n",
    "    print(f\"è¯·æ±‚å®¡æ ¸: {request}\")\n",
    "    \n",
    "    # ä¸­æ–­å·¥ä½œæµï¼Œç­‰å¾…äººå·¥è¾“å…¥\n",
    "    human_feedback = interrupt(f\"è¯·å®¡æ ¸ä»¥ä¸‹è¯·æ±‚: {request}\")\n",
    "    \n",
    "    if human_feedback and \"æ‰¹å‡†\" in str(human_feedback):\n",
    "        return f\"è¯·æ±‚å·²æ‰¹å‡†: {request}\"\n",
    "    else:\n",
    "        return f\"è¯·æ±‚è¢«æ‹’ç»: {request}\"\n",
    "\n",
    "@task\n",
    "def process_approved_request(approved_request: str) -> str:\n",
    "    \"\"\"å¤„ç†å·²æ‰¹å‡†çš„è¯·æ±‚ã€‚\"\"\"\n",
    "    time.sleep(0.1)\n",
    "    return f\"å¤„ç†å®Œæˆ: {approved_request}\"\n",
    "\n",
    "@entrypoint(checkpointer=MemorySaver())\n",
    "def approval_workflow(request: str) -> str:\n",
    "    \"\"\"éœ€è¦å®¡æ‰¹çš„å·¥ä½œæµã€‚\"\"\"\n",
    "    approval_result = require_approval(request).result()\n",
    "    \n",
    "    if \"å·²æ‰¹å‡†\" in approval_result:\n",
    "        final_result = process_approved_request(approval_result).result()\n",
    "        return final_result\n",
    "    else:\n",
    "        return f\"å·¥ä½œæµç»ˆæ­¢: {approval_result}\"\n",
    "\n",
    "# æ¼”ç¤ºä¸­æ–­å’Œæ¢å¤\n",
    "config = {\"configurable\": {\"thread_id\": \"approval_workflow_1\"}}\n",
    "request_data = \"åˆ›å»ºæ–°ç”¨æˆ·è´¦æˆ·\"\n",
    "\n",
    "print(\"=== ç¬¬ä¸€é˜¶æ®µï¼šæ‰§è¡Œå·¥ä½œæµç›´åˆ°ä¸­æ–­ ===\")\n",
    "try:\n",
    "    # é¦–æ¬¡æ‰§è¡Œï¼Œå°†åœ¨ interrupt å¤„æš‚åœ\n",
    "    for chunk in approval_workflow.stream(request_data, config, stream_mode=[\"updates\"]):\n",
    "        print(f\"æ‰§è¡Œæ›´æ–°: {chunk}\")\n",
    "except Exception as e:\n",
    "    print(f\"å·¥ä½œæµå·²ä¸­æ–­: {e}\")\n",
    "\n",
    "# æ£€æŸ¥å·¥ä½œæµçŠ¶æ€\n",
    "print(\"\\n=== æ£€æŸ¥å·¥ä½œæµçŠ¶æ€ ===\")\n",
    "state = approval_workflow.get_state(config)\n",
    "print(f\"å·¥ä½œæµæ˜¯å¦å·²ä¸­æ–­: {state.next is not None}\")\n",
    "if hasattr(state, 'tasks') and state.tasks:\n",
    "    if isinstance(state.tasks, tuple):\n",
    "        print(f\"ç­‰å¾…ä¸­æ–­çš„ä»»åŠ¡æ•°é‡: {len(state.tasks)}\")\n",
    "        for i, task in enumerate(state.tasks):\n",
    "            print(f\"ä»»åŠ¡ {i+1}: {task}\")\n",
    "    elif hasattr(state.tasks, 'keys'):\n",
    "        print(f\"ç­‰å¾…ä¸­æ–­çš„ä»»åŠ¡: {list(state.tasks.keys())}\")\n",
    "    else:\n",
    "        print(f\"ä¸­æ–­çŠ¶æ€: {state.tasks}\")\n",
    "\n",
    "# æ¨¡æ‹Ÿäººå·¥å®¡æ ¸åæ¢å¤\n",
    "print(\"\\n=== ç¬¬äºŒé˜¶æ®µï¼šæä¾›äººå·¥åé¦ˆå¹¶æ¢å¤ ===\")\n",
    "try:\n",
    "    # ä½¿ç”¨ Command å¯¹è±¡æä¾›äººå·¥åé¦ˆ\n",
    "    resume_command = Command(resume=\"æ‰¹å‡†è¯·æ±‚\")\n",
    "    \n",
    "    print(\"æä¾›äººå·¥åé¦ˆå¹¶æ¢å¤å·¥ä½œæµ...\")\n",
    "    for chunk in approval_workflow.stream(resume_command, config, stream_mode=[\"updates\"]):\n",
    "        print(f\"æ¢å¤æ‰§è¡Œ: {chunk}\")\n",
    "    \n",
    "    # è·å–æœ€ç»ˆç»“æœ\n",
    "    final_state = approval_workflow.get_state(config)\n",
    "    if hasattr(final_state, 'values') and 'return_value' in final_state.values:\n",
    "        print(f\"\\næœ€ç»ˆç»“æœ: {final_state.values['return_value']}\")\n",
    "except Exception as e:\n",
    "    print(f\"æ¢å¤æ‰§è¡Œæ—¶å‡ºé”™: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-11",
   "metadata": {},
   "source": [
    "**ğŸ’¡ Command æ¢å¤æœºåˆ¶è§£æ**ï¼š\n",
    "\n",
    "- **ä¸­æ–­å‡½æ•°**: `interrupt()` å¯åœ¨ä»»åŠ¡ä¸­æš‚åœå·¥ä½œæµæ‰§è¡Œ\n",
    "- **çŠ¶æ€ä¿å­˜**: ä¸­æ–­ç‚¹çš„çŠ¶æ€è¢«è‡ªåŠ¨ä¿å­˜åˆ° checkpointer\n",
    "- **äººå·¥ä»‹å…¥**: å…è®¸äººç±»åœ¨å…³é”®å†³ç­–ç‚¹æä¾›è¾“å…¥\n",
    "- **æ— ç¼æ¢å¤**: ä½¿ç”¨ `Command(resume=...)` ä»ä¸­æ–­ç‚¹ç»§ç»­æ‰§è¡Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-12",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-12ï¼šåœ¨ Functional API å·¥ä½œæµä¸­ä½¿ç”¨ LangChain LLM é›†æˆ\n",
    "\n",
    "å±•ç¤º Functional API ä¸ LangChain ç»„ä»¶çš„æ·±åº¦é›†æˆï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== æµ‹è¯•æŸ¥è¯¢ 1 ===\n",
      "ç”¨æˆ·è¾“å…¥: æˆ‘ä»Šå¤©å¿ƒæƒ…å¾ˆå¥½ï¼ä½ èƒ½å‘Šè¯‰æˆ‘ä¸€ä¸ªç¬‘è¯å—ï¼Ÿ\n",
      "å¤„ç†æŸ¥è¯¢: æˆ‘ä»Šå¤©å¿ƒæƒ…å¾ˆå¥½ï¼ä½ èƒ½å‘Šè¯‰æˆ‘ä¸€ä¸ªç¬‘è¯å—ï¼Ÿ\n",
      "æ£€æµ‹æƒ…æ„Ÿ: ç§¯æ\n",
      "æœ€ç»ˆå›å¤: å¤ªå¥½äº†ï¼ \n",
      "\n",
      "å½“ç„¶å¯ä»¥ï¼è¿™é‡Œæœ‰ä¸€ä¸ªè½»æ¾çš„å°ç¬‘è¯ï¼š\n",
      "\n",
      "**ä¸ºä»€ä¹ˆä¼é¹…ä¸ä¼šè¿·è·¯ï¼Ÿ**  \n",
      "å› ä¸ºå®ƒä»¬æœ‰â€œä¼â€ï¼ˆå¯ï¼‰å’Œâ€œé¹…â€ï¼ˆé¹…ï¼‰ï¼Œç»„åˆèµ·æ¥å°±æ˜¯â€œå¯é¹…â€â€”â€”æ‰€ä»¥å®ƒä»¬æ€»èƒ½æ‰¾åˆ°æ–¹å‘ï¼ ğŸ˜„\n",
      "\n",
      "ï¼ˆè°éŸ³æ¢—+åŠ¨ç‰©æ¢—ï¼Œå¸Œæœ›èƒ½è®©æ‚¨ä¼šå¿ƒä¸€ç¬‘ï½ï¼‰\n",
      "\n",
      "=== æµ‹è¯•æŸ¥è¯¢ 2 ===\n",
      "ç”¨æˆ·è¾“å…¥: æˆ‘å¯¹äº§å“çš„è´¨é‡å¾ˆä¸æ»¡æ„\n",
      "å¤„ç†æŸ¥è¯¢: æˆ‘å¯¹äº§å“çš„è´¨é‡å¾ˆä¸æ»¡æ„\n",
      "æ£€æµ‹æƒ…æ„Ÿ: æ¶ˆæ\n",
      "æœ€ç»ˆå›å¤: æˆ‘ç†è§£æ‚¨çš„æ‹…å¿§ã€‚ \n",
      "\n",
      "å¾ˆæŠ±æ­‰å¬åˆ°æ‚¨å¯¹äº§å“è´¨é‡ä¸æ»¡æ„ï¼Œè¿™ç¡®å®ä¼šè®©äººæ„Ÿåˆ°å›°æ‰°ã€‚ä¸ºäº†æ›´å¥½åœ°å¸®åŠ©æ‚¨è§£å†³é—®é¢˜ï¼Œè¯·æ‚¨æä¾›æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œä¾‹å¦‚ï¼š\n",
      "\n",
      "1. **äº§å“åç§°æˆ–å‹å·**ï¼ˆå¦‚ï¼šæ‰‹æœºã€å®¶ç”µã€ç”µå­äº§å“ç­‰ï¼‰  \n",
      "2. **è´­ä¹°æ¸ é“**ï¼ˆå¦‚ï¼šç”µå•†å¹³å°ã€çº¿ä¸‹é—¨åº—ã€å®˜ç½‘ç­‰ï¼‰  \n",
      "3. **å…·ä½“é—®é¢˜æè¿°**ï¼ˆå¦‚ï¼šåŠŸèƒ½æ•…éšœã€å¤–è§‚ç‘•ç–µã€åŒ…è£…æŸåç­‰ï¼‰  \n",
      "4. **æ˜¯å¦å·²è”ç³»å®¢æœ**ï¼ˆå¦‚ï¼šæ˜¯å¦æœ‰å”®åæ²Ÿé€šè®°å½•ï¼‰  \n",
      "\n",
      "æ ¹æ®æ‚¨æä¾›çš„ä¿¡æ¯ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨æä¾›é’ˆå¯¹æ€§çš„è§£å†³æ–¹æ¡ˆï¼Œä¾‹å¦‚ï¼š  \n",
      "- æ£€æŸ¥äº§å“æ˜¯å¦ç¬¦åˆè´¨é‡æ ‡å‡†  \n",
      "- æŒ‡å¯¼æ‚¨å¦‚ä½•ç”³è¯·é€€æ¢è´§æˆ–ç»´ä¿®  \n",
      "- ååŠ©è”ç³»ç›¸å…³å®¢æœæˆ–æŠ€æœ¯æ”¯æŒå›¢é˜Ÿ  \n",
      "\n",
      "åŒæ—¶ï¼Œè¯·æ‚¨æ³¨æ„ä¿ç•™ä»¥ä¸‹å‡­è¯ï¼š  \n",
      "- äº§å“ç…§ç‰‡/è§†é¢‘ï¼ˆå±•ç¤ºé—®é¢˜ç»†èŠ‚ï¼‰  \n",
      "- å‘ç¥¨æˆ–è®¢å•å·  \n",
      "- ä¸å®¢æœæ²Ÿé€šçš„è®°å½•ï¼ˆå¦‚èŠå¤©æˆªå›¾ã€é‚®ä»¶ç­‰ï¼‰  \n",
      "\n",
      "æˆ‘ä»¬éå¸¸é‡è§†æ‚¨çš„åé¦ˆï¼ŒæœŸå¾…å°½å¿«ä¸ºæ‚¨è§£å†³ï¼ ğŸŒŸ\n",
      "\n",
      "=== æµ‹è¯•æŸ¥è¯¢ 3 ===\n",
      "ç”¨æˆ·è¾“å…¥: è¯·é—®ä½ ä»¬çš„è¥ä¸šæ—¶é—´æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "å¤„ç†æŸ¥è¯¢: è¯·é—®ä½ ä»¬çš„è¥ä¸šæ—¶é—´æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "æ£€æµ‹æƒ…æ„Ÿ: ä¸­æ€§\n",
      "\n",
      "è¿™å¥è¯æ˜¯ä¸€ä¸ªä¸­æ€§çš„é—®é¢˜ï¼Œè¯¢é—®è¥ä¸šæ—¶é—´æœ¬èº«ä¸å¸¦æœ‰ç§¯ææˆ–æ¶ˆæçš„æƒ…æ„Ÿè‰²å½©ã€‚å®ƒå±äºå®¢è§‚ä¿¡æ¯çš„æŸ¥è¯¢ï¼Œæ²¡æœ‰è¡¨è¾¾æ»¡æ„ã€ä¸æ»¡ã€å–œæ‚¦ã€æ„¤æ€’ç­‰æƒ…ç»ªã€‚\n",
      "æœ€ç»ˆå›å¤: å¤ªå¥½äº†ï¼ \n",
      "\n",
      "æ‚¨å¥½ï¼å…³äºè¥ä¸šæ—¶é—´ï¼Œæˆ‘éœ€è¦æ‚¨æä¾›æ›´å…·ä½“çš„ä¿¡æ¯ï¼Œä¾‹å¦‚æ‚¨æƒ³äº†è§£çš„æ˜¯å“ªä¸ªåº—é“ºã€å•†åœºæˆ–æœåŠ¡çš„è¥ä¸šæ—¶é—´ï¼Ÿä¸åŒçš„åœºæ‰€å¯èƒ½æœ‰ä¸åŒçš„è¥ä¸šå®‰æ’ï¼Œæ¯”å¦‚æœ‰çš„å•†åœºæ˜¯æ—©9ç‚¹åˆ°æ™š9ç‚¹ï¼Œæœ‰çš„åº—é“ºå¯èƒ½æœ‰åˆä¼‘æˆ–å‘¨æœ«ä¼‘æ¯æ—¶é—´ã€‚å¦‚æœæ‚¨èƒ½è¯´æ˜å…·ä½“åœ°ç‚¹æˆ–æœåŠ¡ç±»å‹ï¼Œæˆ‘å¯ä»¥æ›´å¥½åœ°ä¸ºæ‚¨è§£ç­”å“¦ï¼ ğŸ˜Š\n",
      "\n",
      "å¦‚æœæ— æ³•æä¾›å…·ä½“ä¿¡æ¯ï¼Œå»ºè®®æ‚¨ç›´æ¥è”ç³»ç›¸å…³å•†å®¶æˆ–æŸ¥çœ‹å…¶å®˜æ–¹å…¬å‘Šï¼Œä»¥è·å–æœ€å‡†ç¡®çš„è¥ä¸šæ—¶é—´ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.func import task, entrypoint\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "llm = ChatOpenAI(model=\"Qwen/Qwen3-8B\", temperature=0.7)\n",
    "\n",
    "@task\n",
    "def generate_response(user_query: str) -> str:\n",
    "    \"\"\"ç”Ÿæˆä½¿ç”¨ LangChain LLM çš„å“åº”çš„ä»»åŠ¡ã€‚\"\"\"\n",
    "    print(f\"å¤„ç†æŸ¥è¯¢: {user_query}\")\n",
    "    response = llm.invoke(user_query)\n",
    "    return response.content\n",
    "\n",
    "@task\n",
    "def analyze_sentiment(text: str) -> str:\n",
    "    \"\"\"åˆ†ææ–‡æœ¬æƒ…æ„Ÿã€‚\"\"\"\n",
    "    sentiment_prompt = f\"åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼Œå›ç­”'ç§¯æ'ã€'æ¶ˆæ'æˆ–'ä¸­æ€§'ï¼š{text}\"\n",
    "    response = llm.invoke(sentiment_prompt)\n",
    "    return response.content.strip()\n",
    "\n",
    "@task\n",
    "def enhance_response(original_response: str, sentiment: str) -> str:\n",
    "    \"\"\"æ ¹æ®æƒ…æ„Ÿåˆ†æå¢å¼ºå“åº”ã€‚\"\"\"\n",
    "    if \"ç§¯æ\" in sentiment:\n",
    "        enhancement = \"å¤ªå¥½äº†ï¼\"\n",
    "    elif \"æ¶ˆæ\" in sentiment:\n",
    "        enhancement = \"æˆ‘ç†è§£æ‚¨çš„æ‹…å¿§ã€‚\"\n",
    "    else:\n",
    "        enhancement = \"è°¢è°¢æ‚¨çš„é—®é¢˜ã€‚\"\n",
    "    \n",
    "    return f\"{enhancement} {original_response}\"\n",
    "\n",
    "@entrypoint(checkpointer=MemorySaver())\n",
    "def smart_chatbot_workflow(query: str) -> dict:\n",
    "    \"\"\"æ™ºèƒ½èŠå¤©æœºå™¨äººå·¥ä½œæµï¼Œå…·å¤‡æƒ…æ„Ÿåˆ†æèƒ½åŠ›ã€‚\"\"\"\n",
    "    # ç”Ÿæˆåˆå§‹å“åº”\n",
    "    initial_response = generate_response(query).result()\n",
    "    \n",
    "    # åˆ†æç”¨æˆ·æŸ¥è¯¢çš„æƒ…æ„Ÿ\n",
    "    user_sentiment = analyze_sentiment(query).result()\n",
    "    \n",
    "    # æ ¹æ®æƒ…æ„Ÿå¢å¼ºå“åº”\n",
    "    enhanced_response = enhance_response(initial_response, user_sentiment).result()\n",
    "    \n",
    "    return {\n",
    "        \"user_query\": query,\n",
    "        \"initial_response\": initial_response,\n",
    "        \"detected_sentiment\": user_sentiment,\n",
    "        \"final_response\": enhanced_response\n",
    "    }\n",
    "\n",
    "# æµ‹è¯•æ™ºèƒ½èŠå¤©æœºå™¨äºº\n",
    "config = {\"configurable\": {\"thread_id\": \"chatbot_1\"}}\n",
    "\n",
    "# æµ‹è¯•ä¸åŒæƒ…æ„Ÿçš„æŸ¥è¯¢\n",
    "test_queries = [\n",
    "    \"æˆ‘ä»Šå¤©å¿ƒæƒ…å¾ˆå¥½ï¼ä½ èƒ½å‘Šè¯‰æˆ‘ä¸€ä¸ªç¬‘è¯å—ï¼Ÿ\",\n",
    "    \"æˆ‘å¯¹äº§å“çš„è´¨é‡å¾ˆä¸æ»¡æ„\",\n",
    "    \"è¯·é—®ä½ ä»¬çš„è¥ä¸šæ—¶é—´æ˜¯ä»€ä¹ˆï¼Ÿ\"\n",
    "]\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n=== æµ‹è¯•æŸ¥è¯¢ {i} ===\")\n",
    "    print(f\"ç”¨æˆ·è¾“å…¥: {query}\")\n",
    "    \n",
    "    config[\"configurable\"][\"thread_id\"] = f\"chatbot_{i}\"\n",
    "    result = smart_chatbot_workflow.invoke(query, config)\n",
    "    \n",
    "    print(f\"æ£€æµ‹æƒ…æ„Ÿ: {result['detected_sentiment']}\")\n",
    "    print(f\"æœ€ç»ˆå›å¤: {result['final_response']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-12",
   "metadata": {},
   "source": [
    "**ğŸ’¡ LangChain é›†æˆçš„ä»·å€¼**ï¼š\n",
    "\n",
    "- **ç»„ä»¶å¤ç”¨**: å……åˆ†åˆ©ç”¨ LangChain ç”Ÿæ€ç³»ç»Ÿçš„ç°æœ‰ç»„ä»¶\n",
    "- **æ¨¡å‹æŠ½è±¡**: é€šè¿‡ç»Ÿä¸€æ¥å£ä½¿ç”¨ä¸åŒçš„è¯­è¨€æ¨¡å‹\n",
    "- **åŠŸèƒ½å¢å¼º**: LangGraph çš„çŠ¶æ€ç®¡ç†å¢å¼ºäº† LangChain çš„èƒ½åŠ›\n",
    "- **ç”Ÿæ€ååŒ**: ä¸¤ä¸ªæ¡†æ¶çš„ä¼˜åŠ¿ç›¸äº’è¡¥å……"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-13",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-13ï¼šåœ¨ Functional API å·¥ä½œæµä¸­å®ç°ä»»åŠ¡çš„å¹¶è¡Œæ‰§è¡Œ\n",
    "\n",
    "å±•ç¤ºå¦‚ä½•å¹¶è¡Œæ‰§è¡Œå¤šä¸ªç‹¬ç«‹ä»»åŠ¡ä»¥æé«˜æ€§èƒ½ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== å¹¶è¡Œæ‰§è¡Œå·¥ä½œæµ ===\n",
      "å¼€å§‹å¹¶è¡Œè·å–ç”¨æˆ· 12345 çš„æ•°æ®...\n",
      "æ‰€æœ‰æ•°æ®è·å–ä»»åŠ¡å·²å¯åŠ¨ï¼Œç­‰å¾…ç»“æœ...\n",
      "æ‰€æœ‰æ•°æ®å·²è·å–ï¼Œå¼€å§‹èšåˆ...\n",
      "\n",
      "æ‰§è¡Œè€—æ—¶: 0.41 ç§’\n",
      "ç”¨æˆ·æ¡£æ¡ˆ: {'user_id': '12345', 'name': 'User-12345', 'email': '12345@example.com'}\n",
      "è®¢å•æ€»æ•°: 2\n",
      "æ€»æ¶ˆè´¹: $249.98\n",
      "ç”¨æˆ·åå¥½: {'theme': 'dark', 'language': 'zh-CN', 'notifications': True}\n"
     ]
    }
   ],
   "source": [
    "@task\n",
    "def fetch_user_info(user_id: str) -> dict:\n",
    "    \"\"\"è·å–ç”¨æˆ·ä¿¡æ¯çš„ä»»åŠ¡ã€‚\"\"\"\n",
    "    time.sleep(0.3)  # æ¨¡æ‹Ÿ API è°ƒç”¨å»¶è¿Ÿ\n",
    "    return {\n",
    "        \"user_id\": user_id,\n",
    "        \"name\": f\"User-{user_id}\",\n",
    "        \"email\": f\"{user_id}@example.com\"\n",
    "    }\n",
    "\n",
    "@task\n",
    "def fetch_user_orders(user_id: str) -> list:\n",
    "    \"\"\"è·å–ç”¨æˆ·è®¢å•çš„ä»»åŠ¡ã€‚\"\"\"\n",
    "    time.sleep(0.4)  # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢å»¶è¿Ÿ\n",
    "    return [\n",
    "        {\"order_id\": f\"ord-{user_id}-001\", \"amount\": 99.99},\n",
    "        {\"order_id\": f\"ord-{user_id}-002\", \"amount\": 149.99}\n",
    "    ]\n",
    "\n",
    "@task\n",
    "def fetch_user_preferences(user_id: str) -> dict:\n",
    "    \"\"\"è·å–ç”¨æˆ·åå¥½çš„ä»»åŠ¡ã€‚\"\"\"\n",
    "    time.sleep(0.2)  # æ¨¡æ‹Ÿç¼“å­˜æŸ¥è¯¢å»¶è¿Ÿ\n",
    "    return {\n",
    "        \"theme\": \"dark\",\n",
    "        \"language\": \"zh-CN\",\n",
    "        \"notifications\": True\n",
    "    }\n",
    "\n",
    "@task\n",
    "def aggregate_user_data(user_info: dict, orders: list, preferences: dict) -> dict:\n",
    "    \"\"\"èšåˆç”¨æˆ·æ•°æ®çš„ä»»åŠ¡ã€‚\"\"\"\n",
    "    return {\n",
    "        \"user_profile\": user_info,\n",
    "        \"order_history\": orders,\n",
    "        \"user_preferences\": preferences,\n",
    "        \"total_orders\": len(orders),\n",
    "        \"total_spent\": sum(order[\"amount\"] for order in orders)\n",
    "    }\n",
    "\n",
    "@entrypoint(checkpointer=MemorySaver())\n",
    "def parallel_user_data_workflow(user_id: str) -> dict:\n",
    "    \"\"\"å¹¶è¡Œè·å–ç”¨æˆ·æ•°æ®çš„å·¥ä½œæµã€‚\"\"\"\n",
    "    print(f\"å¼€å§‹å¹¶è¡Œè·å–ç”¨æˆ· {user_id} çš„æ•°æ®...\")\n",
    "    \n",
    "    # å¹¶è¡Œå¯åŠ¨æ‰€æœ‰æ•°æ®è·å–ä»»åŠ¡\n",
    "    user_info_future = fetch_user_info(user_id)\n",
    "    orders_future = fetch_user_orders(user_id)\n",
    "    preferences_future = fetch_user_preferences(user_id)\n",
    "    \n",
    "    print(\"æ‰€æœ‰æ•°æ®è·å–ä»»åŠ¡å·²å¯åŠ¨ï¼Œç­‰å¾…ç»“æœ...\")\n",
    "    \n",
    "    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆå¹¶è·å–ç»“æœ\n",
    "    user_info = user_info_future.result()\n",
    "    orders = orders_future.result()\n",
    "    preferences = preferences_future.result()\n",
    "    \n",
    "    print(\"æ‰€æœ‰æ•°æ®å·²è·å–ï¼Œå¼€å§‹èšåˆ...\")\n",
    "    \n",
    "    # èšåˆæ•°æ®\n",
    "    aggregated_data = aggregate_user_data(user_info, orders, preferences).result()\n",
    "    \n",
    "    return aggregated_data\n",
    "\n",
    "# æµ‹è¯•å¹¶è¡Œæ‰§è¡Œ\n",
    "import time\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"parallel_workflow_1\"}}\n",
    "user_id = \"12345\"\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"=== å¹¶è¡Œæ‰§è¡Œå·¥ä½œæµ ===\")\n",
    "result = parallel_user_data_workflow.invoke(user_id, config)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"\\næ‰§è¡Œè€—æ—¶: {end_time - start_time:.2f} ç§’\")\n",
    "print(f\"ç”¨æˆ·æ¡£æ¡ˆ: {result['user_profile']}\")\n",
    "print(f\"è®¢å•æ€»æ•°: {result['total_orders']}\")\n",
    "print(f\"æ€»æ¶ˆè´¹: ${result['total_spent']:.2f}\")\n",
    "print(f\"ç”¨æˆ·åå¥½: {result['user_preferences']}\")\n",
    "\n",
    "# å¯¹æ¯”ï¼šå¦‚æœæ˜¯ä¸²è¡Œæ‰§è¡Œä¼šèŠ±è´¹æ›´é•¿æ—¶é—´\n",
    "# (0.3 + 0.4 + 0.2 = 0.9ç§’ vs å¹¶è¡Œæ‰§è¡Œçº¦0.4ç§’)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-13",
   "metadata": {},
   "source": [
    "**ğŸ’¡ å¹¶è¡Œæ‰§è¡Œçš„æ€§èƒ½ä¼˜åŠ¿**ï¼š\n",
    "\n",
    "- **æ—¶é—´æ•ˆç‡**: å¤šä¸ªç‹¬ç«‹ä»»åŠ¡å¯åŒæ—¶æ‰§è¡Œï¼Œæ˜¾è‘—å‡å°‘æ€»è€—æ—¶\n",
    "- **èµ„æºåˆ©ç”¨**: å……åˆ†åˆ©ç”¨ç³»ç»Ÿçš„å¹¶å‘å¤„ç†èƒ½åŠ›\n",
    "- **I/O ä¼˜åŒ–**: ç‰¹åˆ«é€‚ç”¨äºç½‘ç»œè¯·æ±‚ã€æ•°æ®åº“æŸ¥è¯¢ç­‰ I/O å¯†é›†å‹ä»»åŠ¡\n",
    "- **ç®€å•å®ç°**: æ— éœ€å¤æ‚çš„å¹¶å‘ç¼–ç¨‹ï¼Œæ¡†æ¶è‡ªåŠ¨å¤„ç†å¹¶è¡Œæ‰§è¡Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-14",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-14ï¼šåœ¨ Functional API ä¸­è°ƒç”¨å­å›¾\n",
    "\n",
    "å±•ç¤ºå¦‚ä½•ç»„åˆå’ŒåµŒå¥—å·¥ä½œæµï¼Œå®ç°æ¨¡å—åŒ–è®¾è®¡ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æµ‹è¯•æœ‰æ•ˆæ•°æ® ===\n",
      "=== å¼€å§‹ä¸»æ•°æ®å·¥ä½œæµ ===\n",
      "æ­¥éª¤ 1: æ•°æ®éªŒè¯\n",
      "éªŒè¯æ•°æ®: ['name', 'email', 'age']\n",
      "æ­¥éª¤ 2: æ•°æ®å¤„ç†\n",
      "å¤„ç†æ•°æ®: {'name': 'john doe', 'email': 'John.Doe@Example.COM', 'age': 30}\n",
      "å¤„ç†ç»“æœ: success\n",
      "å¤„ç†åæ•°æ®: {'name': 'John Doe', 'email': 'john.doe@example.com', 'age': 30, 'processed_at': '2024-01-01 12:00:00'}\n",
      "\n",
      "=== æµ‹è¯•æ— æ•ˆæ•°æ® ===\n",
      "=== å¼€å§‹ä¸»æ•°æ®å·¥ä½œæµ ===\n",
      "æ­¥éª¤ 1: æ•°æ®éªŒè¯\n",
      "éªŒè¯æ•°æ®: ['email', 'age']\n",
      "å¤„ç†ç»“æœ: failed\n",
      "å¤±è´¥åŸå› : æ•°æ®éªŒè¯å¤±è´¥\n",
      "é”™è¯¯ä¿¡æ¯: ['ç¼ºå°‘ name å­—æ®µ', 'é‚®ç®±æ ¼å¼æ— æ•ˆ']\n"
     ]
    }
   ],
   "source": [
    "# å®šä¹‰å­å·¥ä½œæµ\n",
    "@entrypoint(checkpointer=MemorySaver())\n",
    "def data_validation_workflow(data: dict) -> dict:\n",
    "    \"\"\"æ•°æ®éªŒè¯å­å·¥ä½œæµã€‚\"\"\"\n",
    "    print(f\"éªŒè¯æ•°æ®: {list(data.keys())}\")\n",
    "    \n",
    "    validation_results = {\n",
    "        \"is_valid\": True,\n",
    "        \"errors\": [],\n",
    "        \"warnings\": []\n",
    "    }\n",
    "    \n",
    "    # æ¨¡æ‹Ÿæ•°æ®éªŒè¯é€»è¾‘\n",
    "    if \"name\" not in data:\n",
    "        validation_results[\"errors\"].append(\"ç¼ºå°‘ name å­—æ®µ\")\n",
    "        validation_results[\"is_valid\"] = False\n",
    "    \n",
    "    if \"email\" in data and \"@\" not in data[\"email\"]:\n",
    "        validation_results[\"errors\"].append(\"é‚®ç®±æ ¼å¼æ— æ•ˆ\")\n",
    "        validation_results[\"is_valid\"] = False\n",
    "    \n",
    "    if \"age\" in data and data[\"age\"] < 0:\n",
    "        validation_results[\"warnings\"].append(\"å¹´é¾„ä¸ºè´Ÿæ•°\")\n",
    "    \n",
    "    return {\n",
    "        \"original_data\": data,\n",
    "        \"validation\": validation_results\n",
    "    }\n",
    "\n",
    "@entrypoint(checkpointer=MemorySaver())\n",
    "def data_processing_workflow(data: dict) -> dict:\n",
    "    \"\"\"æ•°æ®å¤„ç†å­å·¥ä½œæµã€‚\"\"\"\n",
    "    print(f\"å¤„ç†æ•°æ®: {data}\")\n",
    "    \n",
    "    processed_data = data.copy()\n",
    "    \n",
    "    # æ¨¡æ‹Ÿæ•°æ®å¤„ç†é€»è¾‘\n",
    "    if \"name\" in processed_data:\n",
    "        processed_data[\"name\"] = processed_data[\"name\"].title()\n",
    "    \n",
    "    if \"email\" in processed_data:\n",
    "        processed_data[\"email\"] = processed_data[\"email\"].lower()\n",
    "    \n",
    "    processed_data[\"processed_at\"] = \"2024-01-01 12:00:00\"\n",
    "    \n",
    "    return {\n",
    "        \"original_data\": data,\n",
    "        \"processed_data\": processed_data\n",
    "    }\n",
    "\n",
    "# ä¸»å·¥ä½œæµè°ƒç”¨å­å·¥ä½œæµ\n",
    "@entrypoint(checkpointer=MemorySaver())\n",
    "def master_data_workflow(raw_data: dict) -> dict:\n",
    "    \"\"\"ä¸»æ•°æ®å·¥ä½œæµï¼Œåè°ƒå¤šä¸ªå­å·¥ä½œæµã€‚\"\"\"\n",
    "    print(\"=== å¼€å§‹ä¸»æ•°æ®å·¥ä½œæµ ===\")\n",
    "    \n",
    "    # ç¬¬ä¸€æ­¥ï¼šæ•°æ®éªŒè¯\n",
    "    print(\"æ­¥éª¤ 1: æ•°æ®éªŒè¯\")\n",
    "    validation_result = data_validation_workflow.invoke(raw_data)\n",
    "    \n",
    "    if not validation_result[\"validation\"][\"is_valid\"]:\n",
    "        return {\n",
    "            \"status\": \"failed\",\n",
    "            \"reason\": \"æ•°æ®éªŒè¯å¤±è´¥\",\n",
    "            \"errors\": validation_result[\"validation\"][\"errors\"],\n",
    "            \"raw_data\": raw_data\n",
    "        }\n",
    "    \n",
    "    # ç¬¬äºŒæ­¥ï¼šæ•°æ®å¤„ç†ï¼ˆä»…åœ¨éªŒè¯é€šè¿‡æ—¶æ‰§è¡Œï¼‰\n",
    "    print(\"æ­¥éª¤ 2: æ•°æ®å¤„ç†\")\n",
    "    processing_result = data_processing_workflow.invoke(raw_data)\n",
    "    \n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"validation_result\": validation_result[\"validation\"],\n",
    "        \"processed_data\": processing_result[\"processed_data\"],\n",
    "        \"original_data\": raw_data\n",
    "    }\n",
    "\n",
    "# æµ‹è¯•å­å·¥ä½œæµç»„åˆ\n",
    "config = {\"configurable\": {\"thread_id\": \"master_workflow_1\"}}\n",
    "\n",
    "# æµ‹è¯•æœ‰æ•ˆæ•°æ®\n",
    "print(\"=== æµ‹è¯•æœ‰æ•ˆæ•°æ® ===\")\n",
    "valid_data = {\n",
    "    \"name\": \"john doe\",\n",
    "    \"email\": \"John.Doe@Example.COM\",\n",
    "    \"age\": 30\n",
    "}\n",
    "\n",
    "result_valid = master_data_workflow.invoke(valid_data, config)\n",
    "print(f\"å¤„ç†ç»“æœ: {result_valid['status']}\")\n",
    "if result_valid['status'] == 'success':\n",
    "    print(f\"å¤„ç†åæ•°æ®: {result_valid['processed_data']}\")\n",
    "print()\n",
    "\n",
    "# æµ‹è¯•æ— æ•ˆæ•°æ®\n",
    "print(\"=== æµ‹è¯•æ— æ•ˆæ•°æ® ===\")\n",
    "invalid_data = {\n",
    "    \"email\": \"invalid-email\",  # æ— æ•ˆé‚®ç®±\n",
    "    \"age\": -5  # è´Ÿæ•°å¹´é¾„\n",
    "}\n",
    "\n",
    "config[\"configurable\"][\"thread_id\"] = \"master_workflow_2\"\n",
    "result_invalid = master_data_workflow.invoke(invalid_data, config)\n",
    "print(f\"å¤„ç†ç»“æœ: {result_invalid['status']}\")\n",
    "if result_invalid['status'] == 'failed':\n",
    "    print(f\"å¤±è´¥åŸå› : {result_invalid['reason']}\")\n",
    "    print(f\"é”™è¯¯ä¿¡æ¯: {result_invalid['errors']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-14",
   "metadata": {},
   "source": [
    "**ğŸ’¡ å­å·¥ä½œæµç»„åˆçš„ä¼˜åŠ¿**ï¼š\n",
    "\n",
    "- **æ¨¡å—åŒ–è®¾è®¡**: å°†å¤æ‚å·¥ä½œæµåˆ†è§£ä¸ºå¯é‡ç”¨çš„å­å·¥ä½œæµ\n",
    "- **èŒè´£åˆ†ç¦»**: æ¯ä¸ªå­å·¥ä½œæµä¸“æ³¨äºç‰¹å®šåŠŸèƒ½\n",
    "- **æ˜“äºæµ‹è¯•**: å¯ä»¥ç‹¬ç«‹æµ‹è¯•æ¯ä¸ªå­å·¥ä½œæµ\n",
    "- **ä»£ç å¤ç”¨**: å­å·¥ä½œæµå¯åœ¨å¤šä¸ªä¸»å·¥ä½œæµä¸­é‡å¤ä½¿ç”¨\n",
    "- **çŠ¶æ€éš”ç¦»**: æ¯ä¸ªå·¥ä½œæµå¯ä»¥æœ‰ç‹¬ç«‹çš„çŠ¶æ€ç®¡ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-15",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-15ï¼šåœ¨ Functional API ä¸­æ¼”ç¤ºè‡ªå®šä¹‰æ•°æ®æµå¼ä¼ è¾“\n",
    "\n",
    "å±•ç¤ºå¦‚ä½•ä½¿ç”¨ `writer` å‚æ•°å®ç°è‡ªå®šä¹‰æ•°æ®çš„å®æ—¶æµå¼ä¼ è¾“ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æµå¼æ‰§è¡Œæ–‡æœ¬åˆ†æå·¥ä½œæµ ===\n",
      "ç›‘å¬è‡ªå®šä¹‰æµå’Œæ›´æ–°æµ...\n",
      "--------------------------------------------------\n",
      "ğŸ“¢ è¿›åº¦æ›´æ–°: å¼€å§‹æ–‡æœ¬åˆ†æå·¥ä½œæµ\n",
      "ğŸ“¢ è¿›åº¦æ›´æ–°: è¾“å…¥æ–‡æœ¬é•¿åº¦: 98 å­—ç¬¦\n",
      "ğŸ“¢ è¿›åº¦æ›´æ–°: é˜¶æ®µ 1: æ­£åœ¨åˆ†ææ–‡æœ¬ç»“æ„...\n",
      "ğŸ”„ å·¥ä½œæµæ›´æ–°: ['analyze_text']\n",
      "ğŸ“¢ è¿›åº¦æ›´æ–°: åˆ†æå®Œæˆ: å‘ç° 5 ä¸ªå•è¯\n",
      "ğŸ“¢ è¿›åº¦æ›´æ–°: é˜¶æ®µ 2: æ­£åœ¨ç”Ÿæˆæ‘˜è¦...\n",
      "ğŸ”„ å·¥ä½œæµæ›´æ–°: ['generate_summary']\n",
      "ğŸ“¢ è¿›åº¦æ›´æ–°: æ‘˜è¦ç”Ÿæˆå®Œæˆ\n",
      "ğŸ“¢ è¿›åº¦æ›´æ–°: æ–‡æœ¬åˆ†æå·¥ä½œæµå·²å®Œæˆ\n",
      "ğŸ”„ å·¥ä½œæµæ›´æ–°: ['text_analysis_workflow']\n",
      "--------------------------------------------------\n",
      "æµå¼æ‰§è¡Œå®Œæˆï¼\n",
      "\n",
      "=== æœ€ç»ˆç»“æœ ===\n",
      "å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼ŒæŸ¥çœ‹æµå¼è¾“å‡ºäº†è§£è¯¦ç»†è¿‡ç¨‹ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import StreamWriter\n",
    "\n",
    "@task\n",
    "def analyze_text(text: str) -> dict:\n",
    "    \"\"\"åˆ†ææ–‡æœ¬çš„ä»»åŠ¡ã€‚\"\"\"\n",
    "    time.sleep(0.5)  # æ¨¡æ‹Ÿåˆ†ææ—¶é—´\n",
    "    \n",
    "    return {\n",
    "        \"length\": len(text),\n",
    "        \"words\": len(text.split()),\n",
    "        \"sentences\": text.count('.') + text.count('!') + text.count('?'),\n",
    "        \"paragraphs\": text.count('\\n\\n') + 1\n",
    "    }\n",
    "\n",
    "@task\n",
    "def generate_summary(analysis: dict) -> str:\n",
    "    \"\"\"ç”Ÿæˆæ‘˜è¦çš„ä»»åŠ¡ã€‚\"\"\"\n",
    "    time.sleep(0.3)  # æ¨¡æ‹Ÿç”Ÿæˆæ—¶é—´\n",
    "    \n",
    "    return f\"æ–‡æœ¬åŒ…å« {analysis['words']} ä¸ªå•è¯ï¼Œ{analysis['sentences']} ä¸ªå¥å­ï¼Œ{analysis['paragraphs']} ä¸ªæ®µè½ã€‚\"\n",
    "\n",
    "@entrypoint(checkpointer=MemorySaver())\n",
    "def text_analysis_workflow(\n",
    "    text: str, \n",
    "    *,\n",
    "    writer: StreamWriter\n",
    ") -> dict:\n",
    "    \"\"\"æ–‡æœ¬åˆ†æå·¥ä½œæµï¼Œå¸¦æœ‰å®æ—¶è¿›åº¦åé¦ˆã€‚\"\"\"\n",
    "    writer(\"å¼€å§‹æ–‡æœ¬åˆ†æå·¥ä½œæµ\")\n",
    "    writer(f\"è¾“å…¥æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦\")\n",
    "    \n",
    "    # ç¬¬ä¸€é˜¶æ®µï¼šæ–‡æœ¬åˆ†æ\n",
    "    writer(\"é˜¶æ®µ 1: æ­£åœ¨åˆ†ææ–‡æœ¬ç»“æ„...\")\n",
    "    analysis = analyze_text(text).result()\n",
    "    writer(f\"åˆ†æå®Œæˆ: å‘ç° {analysis['words']} ä¸ªå•è¯\")\n",
    "    \n",
    "    # ç¬¬äºŒé˜¶æ®µï¼šç”Ÿæˆæ‘˜è¦\n",
    "    writer(\"é˜¶æ®µ 2: æ­£åœ¨ç”Ÿæˆæ‘˜è¦...\")\n",
    "    summary = generate_summary(analysis).result()\n",
    "    writer(\"æ‘˜è¦ç”Ÿæˆå®Œæˆ\")\n",
    "    \n",
    "    # æœ€ç»ˆç»“æœ\n",
    "    result = {\n",
    "        \"text_analysis\": analysis,\n",
    "        \"summary\": summary,\n",
    "        \"processing_status\": \"completed\"\n",
    "    }\n",
    "    \n",
    "    writer(\"æ–‡æœ¬åˆ†æå·¥ä½œæµå·²å®Œæˆ\")\n",
    "    return result\n",
    "\n",
    "# æµ‹è¯•è‡ªå®šä¹‰æ•°æ®æµå¼ä¼ è¾“\n",
    "config = {\"configurable\": {\"thread_id\": \"streaming_workflow_1\"}}\n",
    "sample_text = \"\"\"\n",
    "äººå·¥æ™ºèƒ½æ˜¯ä¸€ä¸ªå¿«é€Ÿå‘å±•çš„é¢†åŸŸã€‚å®ƒåŒ…å«æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰å¤šä¸ªåˆ†æ”¯ã€‚\n",
    "AI æŠ€æœ¯æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼ã€‚ä»æ™ºèƒ½åŠ©æ‰‹åˆ°è‡ªåŠ¨é©¾é©¶ï¼ŒAI æ— å¤„ä¸åœ¨ã€‚\n",
    "æˆ‘ä»¬éœ€è¦è´Ÿè´£ä»»åœ°å¼€å‘å’Œä½¿ç”¨è¿™äº›æŠ€æœ¯ã€‚\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== æµå¼æ‰§è¡Œæ–‡æœ¬åˆ†æå·¥ä½œæµ ===\")\n",
    "print(\"ç›‘å¬è‡ªå®šä¹‰æµå’Œæ›´æ–°æµ...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for chunk in text_analysis_workflow.stream(\n",
    "    sample_text, \n",
    "    config, \n",
    "    stream_mode=[\"custom\", \"updates\"]\n",
    "):\n",
    "    if chunk[0] == \"custom\":\n",
    "        print(f\"ğŸ“¢ è¿›åº¦æ›´æ–°: {chunk[1]}\")\n",
    "    elif chunk[0] == \"updates\":\n",
    "        print(f\"ğŸ”„ å·¥ä½œæµæ›´æ–°: {list(chunk[1].keys())}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"æµå¼æ‰§è¡Œå®Œæˆï¼\")\n",
    "\n",
    "# è·å–æœ€ç»ˆç»“æœ\n",
    "final_state = text_analysis_workflow.get_state(config)\n",
    "if hasattr(final_state, 'values') and final_state.values:\n",
    "    print(\"\\n=== æœ€ç»ˆç»“æœ ===\")\n",
    "    # æ³¨æ„ï¼šå®é™…çš„ç»“æœè®¿é—®æ–¹å¼å¯èƒ½å› ç‰ˆæœ¬è€Œå¼‚\n",
    "    print(\"å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼ŒæŸ¥çœ‹æµå¼è¾“å‡ºäº†è§£è¯¦ç»†è¿‡ç¨‹ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-15",
   "metadata": {},
   "source": [
    "**ğŸ’¡ è‡ªå®šä¹‰æµå¼ä¼ è¾“çš„åº”ç”¨ä»·å€¼**ï¼š\n",
    "\n",
    "- **è¿›åº¦è¿½è¸ª**: ä¸ºç”¨æˆ·æä¾›è¯¦ç»†çš„æ‰§è¡Œè¿›åº¦ä¿¡æ¯\n",
    "- **å®æ—¶åé¦ˆ**: é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ä¸å†æ˜¯é»‘ç›’æ“ä½œ\n",
    "- **è°ƒè¯•æ”¯æŒ**: é€šè¿‡æµå¼è¾“å‡ºæ›´å®¹æ˜“å®šä½é—®é¢˜\n",
    "- **ç”¨æˆ·ä½“éªŒ**: æ˜¾è‘—æ”¹å–„ç”¨æˆ·å¯¹ç³»ç»Ÿå“åº”æ€§çš„æ„ŸçŸ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-16",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-16ï¼šåœ¨ Functional API ä¸­å®ç°é‡è¯•ç­–ç•¥\n",
    "\n",
    "æ¼”ç¤ºæ›´å¤æ‚çš„é‡è¯•ç­–ç•¥é…ç½®å’Œé”™è¯¯å¤„ç†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "æµ‹è¯• 1: https://api.example.com/data\n",
      "============================================================\n",
      "=== å¼€å§‹å¤„ç† API è¯·æ±‚: https://api.example.com/data ===\n",
      "æ­¥éª¤ 1: å‘èµ·ç½‘ç»œè¯·æ±‚\n",
      "å°è¯•è®¿é—®: https://api.example.com/data\n",
      "âŒ ç½‘ç»œè¿æ¥å¤±è´¥\n",
      "å°è¯•è®¿é—®: https://api.example.com/data\n",
      "âŒ ç½‘ç»œè¿æ¥å¤±è´¥\n",
      "å°è¯•è®¿é—®: https://api.example.com/data\n",
      "âŒ ç½‘ç»œè¿æ¥å¤±è´¥\n",
      "\n",
      "ğŸ’¥ ç½‘ç»œé”™è¯¯ï¼ˆé‡è¯•åä»å¤±è´¥ï¼‰: æ— æ³•è¿æ¥åˆ° https://api.example.com/data\n",
      "\n",
      "ğŸ“Š æœ€ç»ˆç»“æœ:\n",
      "çŠ¶æ€: network_error\n",
      "é”™è¯¯ä¿¡æ¯: æ— æ³•è¿æ¥åˆ° https://api.example.com/data\n",
      "\n",
      "============================================================\n",
      "æµ‹è¯• 2: https://api.service.com/info\n",
      "============================================================\n",
      "=== å¼€å§‹å¤„ç† API è¯·æ±‚: https://api.service.com/info ===\n",
      "æ­¥éª¤ 1: å‘èµ·ç½‘ç»œè¯·æ±‚\n",
      "å°è¯•è®¿é—®: https://api.service.com/info\n",
      "âŒ ç½‘ç»œè¿æ¥å¤±è´¥\n",
      "å°è¯•è®¿é—®: https://api.service.com/info\n",
      "âŒ ç½‘ç»œè¿æ¥å¤±è´¥\n",
      "å°è¯•è®¿é—®: https://api.service.com/info\n",
      "âŒ ç½‘ç»œè¿æ¥å¤±è´¥\n",
      "\n",
      "ğŸ’¥ ç½‘ç»œé”™è¯¯ï¼ˆé‡è¯•åä»å¤±è´¥ï¼‰: æ— æ³•è¿æ¥åˆ° https://api.service.com/info\n",
      "\n",
      "ğŸ“Š æœ€ç»ˆç»“æœ:\n",
      "çŠ¶æ€: network_error\n",
      "é”™è¯¯ä¿¡æ¯: æ— æ³•è¿æ¥åˆ° https://api.service.com/info\n",
      "\n",
      "============================================================\n",
      "æµ‹è¯• 3: https://api.test.com/status\n",
      "============================================================\n",
      "=== å¼€å§‹å¤„ç† API è¯·æ±‚: https://api.test.com/status ===\n",
      "æ­¥éª¤ 1: å‘èµ·ç½‘ç»œè¯·æ±‚\n",
      "å°è¯•è®¿é—®: https://api.test.com/status\n",
      "âŒ ç½‘ç»œè¿æ¥å¤±è´¥\n",
      "å°è¯•è®¿é—®: https://api.test.com/status\n",
      "âŒ ç½‘ç»œè¿æ¥å¤±è´¥\n",
      "å°è¯•è®¿é—®: https://api.test.com/status\n",
      "âœ… ç½‘ç»œè¯·æ±‚æˆåŠŸ\n",
      "\n",
      "æ­¥éª¤ 2: éªŒè¯å“åº”æ•°æ®\n",
      "éªŒè¯æ•°æ®: ['url', 'status', 'data']\n",
      "âœ… æ•°æ®éªŒè¯é€šè¿‡\n",
      "\n",
      "æ­¥éª¤ 3: å¤„ç†éªŒè¯æ•°æ®\n",
      "\n",
      "ğŸ“Š æœ€ç»ˆç»“æœ:\n",
      "çŠ¶æ€: success\n",
      "å¤„ç†ç»“æœ: å¤„ç†å®Œæˆ: æ¥è‡ª https://api.test.com/status çš„æ•°æ®\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import RetryPolicy\n",
    "import random\n",
    "\n",
    "# å®šä¹‰ä¸åŒçš„é‡è¯•ç­–ç•¥\n",
    "network_retry_policy = RetryPolicy(max_attempts=3, retry_on=ConnectionError)\n",
    "validation_retry_policy = RetryPolicy(max_attempts=2, retry_on=ValueError)\n",
    "\n",
    "@task(name=\"network_request\", retry_policy=network_retry_policy)\n",
    "def make_network_request(url: str) -> dict:\n",
    "    \"\"\"æ¨¡æ‹Ÿç½‘ç»œè¯·æ±‚ï¼Œå¯èƒ½å¤±è´¥çš„ä»»åŠ¡ã€‚\"\"\"\n",
    "    print(f\"å°è¯•è®¿é—®: {url}\")\n",
    "    \n",
    "    # æ¨¡æ‹Ÿç½‘ç»œä¸ç¨³å®š\n",
    "    if random.random() < 0.7:  # 70% å¤±è´¥ç‡\n",
    "        print(\"âŒ ç½‘ç»œè¿æ¥å¤±è´¥\")\n",
    "        raise ConnectionError(f\"æ— æ³•è¿æ¥åˆ° {url}\")\n",
    "    \n",
    "    print(\"âœ… ç½‘ç»œè¯·æ±‚æˆåŠŸ\")\n",
    "    return {\n",
    "        \"url\": url,\n",
    "        \"status\": \"success\",\n",
    "        \"data\": f\"æ¥è‡ª {url} çš„æ•°æ®\"\n",
    "    }\n",
    "\n",
    "@task(name=\"data_validator\", retry_policy=validation_retry_policy)\n",
    "def validate_response_data(data: dict) -> dict:\n",
    "    \"\"\"éªŒè¯å“åº”æ•°æ®ï¼Œå¯èƒ½éœ€è¦é‡è¯•çš„ä»»åŠ¡ã€‚\"\"\"\n",
    "    print(f\"éªŒè¯æ•°æ®: {list(data.keys())}\")\n",
    "    \n",
    "    # æ¨¡æ‹ŸéªŒè¯é€»è¾‘\n",
    "    if \"status\" not in data:\n",
    "        print(\"âŒ æ•°æ®éªŒè¯å¤±è´¥ï¼šç¼ºå°‘ status å­—æ®µ\")\n",
    "        raise ValueError(\"å“åº”æ•°æ®æ ¼å¼ä¸æ­£ç¡®\")\n",
    "    \n",
    "    if data.get(\"status\") != \"success\":\n",
    "        print(\"âŒ æ•°æ®éªŒè¯å¤±è´¥ï¼šçŠ¶æ€ä¸æ˜¯ success\")\n",
    "        raise ValueError(\"å“åº”çŠ¶æ€å¼‚å¸¸\")\n",
    "    \n",
    "    print(\"âœ… æ•°æ®éªŒè¯é€šè¿‡\")\n",
    "    return {\n",
    "        \"validated\": True,\n",
    "        \"original_data\": data\n",
    "    }\n",
    "\n",
    "@task\n",
    "def process_validated_data(validated_data: dict) -> str:\n",
    "    \"\"\"å¤„ç†å·²éªŒè¯çš„æ•°æ®ã€‚\"\"\"\n",
    "    original = validated_data[\"original_data\"]\n",
    "    return f\"å¤„ç†å®Œæˆ: {original['data']}\"\n",
    "\n",
    "@entrypoint(checkpointer=MemorySaver())\n",
    "def robust_api_workflow(api_url: str) -> dict:\n",
    "    \"\"\"å…·æœ‰é‡è¯•æœºåˆ¶çš„å¥å£® API å·¥ä½œæµã€‚\"\"\"\n",
    "    try:\n",
    "        print(f\"=== å¼€å§‹å¤„ç† API è¯·æ±‚: {api_url} ===\")\n",
    "        \n",
    "        # æ­¥éª¤ 1: ç½‘ç»œè¯·æ±‚ï¼ˆå¸¦é‡è¯•ï¼‰\n",
    "        print(\"æ­¥éª¤ 1: å‘èµ·ç½‘ç»œè¯·æ±‚\")\n",
    "        response_data = make_network_request(api_url).result()\n",
    "        \n",
    "        # æ­¥éª¤ 2: æ•°æ®éªŒè¯ï¼ˆå¸¦é‡è¯•ï¼‰\n",
    "        print(\"\\næ­¥éª¤ 2: éªŒè¯å“åº”æ•°æ®\")\n",
    "        validated_data = validate_response_data(response_data).result()\n",
    "        \n",
    "        # æ­¥éª¤ 3: å¤„ç†æ•°æ®ï¼ˆæ— é‡è¯•ï¼‰\n",
    "        print(\"\\næ­¥éª¤ 3: å¤„ç†éªŒè¯æ•°æ®\")\n",
    "        processed_result = process_validated_data(validated_data).result()\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"result\": processed_result,\n",
    "            \"api_url\": api_url\n",
    "        }\n",
    "        \n",
    "    except ConnectionError as e:\n",
    "        print(f\"\\nğŸ’¥ ç½‘ç»œé”™è¯¯ï¼ˆé‡è¯•åä»å¤±è´¥ï¼‰: {e}\")\n",
    "        return {\n",
    "            \"status\": \"network_error\",\n",
    "            \"error\": str(e),\n",
    "            \"api_url\": api_url\n",
    "        }\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"\\nğŸ’¥ æ•°æ®éªŒè¯é”™è¯¯ï¼ˆé‡è¯•åä»å¤±è´¥ï¼‰: {e}\")\n",
    "        return {\n",
    "            \"status\": \"validation_error\",\n",
    "            \"error\": str(e),\n",
    "            \"api_url\": api_url\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nğŸ’¥ æœªé¢„æœŸé”™è¯¯: {e}\")\n",
    "        return {\n",
    "            \"status\": \"unexpected_error\",\n",
    "            \"error\": str(e),\n",
    "            \"api_url\": api_url\n",
    "        }\n",
    "\n",
    "# æµ‹è¯•é‡è¯•æœºåˆ¶\n",
    "api_endpoints = [\n",
    "    \"https://api.example.com/data\",\n",
    "    \"https://api.service.com/info\",\n",
    "    \"https://api.test.com/status\"\n",
    "]\n",
    "\n",
    "for i, endpoint in enumerate(api_endpoints, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"æµ‹è¯• {i}: {endpoint}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": f\"robust_api_workflow_{i}\"}}\n",
    "    result = robust_api_workflow.invoke(endpoint, config)\n",
    "    \n",
    "    print(\"\\nğŸ“Š æœ€ç»ˆç»“æœ:\")\n",
    "    print(f\"çŠ¶æ€: {result['status']}\")\n",
    "    if result['status'] == 'success':\n",
    "        print(f\"å¤„ç†ç»“æœ: {result['result']}\")\n",
    "    else:\n",
    "        print(f\"é”™è¯¯ä¿¡æ¯: {result['error']}\")\n",
    "    \n",
    "    time.sleep(0.5)  # ç»™ç”¨æˆ·æ—¶é—´è§‚å¯Ÿè¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-16",
   "metadata": {},
   "source": [
    "**ğŸ’¡ é‡è¯•ç­–ç•¥çš„é‡è¦æ€§**ï¼š\n",
    "\n",
    "- **æé«˜å¯é æ€§**: è‡ªåŠ¨å¤„ç†ä¸´æ—¶æ€§é”™è¯¯ï¼Œå‡å°‘ç³»ç»Ÿæ•…éšœ\n",
    "- **åŒºåˆ†å¼‚å¸¸ç±»å‹**: ä¸åŒç±»å‹çš„é”™è¯¯é‡‡ç”¨ä¸åŒçš„é‡è¯•ç­–ç•¥\n",
    "- **ä¼˜é›…é™çº§**: é‡è¯•å¤±è´¥åæä¾›æœ‰æ„ä¹‰çš„é”™è¯¯ä¿¡æ¯\n",
    "- **ç”Ÿäº§å°±ç»ª**: æ˜¯æ„å»ºå¥å£®ç”Ÿäº§ç³»ç»Ÿçš„å¿…è¦åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-6-17",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-17ï¼šåœ¨ Functional API ä¸­å®ç°çŸ­æœŸè®°å¿†\n",
    "\n",
    "å±•ç¤ºå¦‚ä½•ä½¿ç”¨ `previous` å‚æ•°å’Œ `entrypoint.final()` ç®¡ç†å·¥ä½œæµçŠ¶æ€ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æµ‹è¯•è®¡æ•°å™¨å·¥ä½œæµ ===\n",
      "å½“å‰è®¡æ•°: 0, å¢é‡: 1, æ–°è®¡æ•°: 1\n",
      "è°ƒç”¨ 1: å¢é‡ 1 -> è¿”å›å€¼ 0\n",
      "å½“å‰è®¡æ•°: 1, å¢é‡: 2, æ–°è®¡æ•°: 3\n",
      "è°ƒç”¨ 2: å¢é‡ 2 -> è¿”å›å€¼ 1\n",
      "å½“å‰è®¡æ•°: 3, å¢é‡: 3, æ–°è®¡æ•°: 6\n",
      "è°ƒç”¨ 3: å¢é‡ 3 -> è¿”å›å€¼ 3\n",
      "å½“å‰è®¡æ•°: 6, å¢é‡: 5, æ–°è®¡æ•°: 11\n",
      "è°ƒç”¨ 4: å¢é‡ 5 -> è¿”å›å€¼ 6\n",
      "\n",
      "=== æµ‹è¯•ä¼šè¯èŠå¤©å·¥ä½œæµ ===\n",
      "\n",
      "--- å¯¹è¯è½®æ¬¡ 1 ---\n",
      "ğŸ‘¤ ç”¨æˆ·: ä½ å¥½ï¼\n",
      "ğŸ†• å¼€å§‹æ–°çš„å¯¹è¯ä¼šè¯\n",
      "ğŸ¤– åŠ©æ‰‹: è¿™æ˜¯æˆ‘ä»¬çš„ç¬¬ 1 æ¬¡äº¤æµã€‚ä½ å¥½ï¼\n",
      "\n",
      "--- å¯¹è¯è½®æ¬¡ 2 ---\n",
      "ğŸ‘¤ ç”¨æˆ·: æˆ‘å«å°æ˜\n",
      "ğŸ”„ æ¢å¤å¯¹è¯ä¼šè¯ (å·²æœ‰ 2 æ¡æ¶ˆæ¯)\n",
      "ğŸ¤– åŠ©æ‰‹: å¾ˆé«˜å…´è®¤è¯†ä½ ï¼Œå°æ˜ï¼\n",
      "\n",
      "--- å¯¹è¯è½®æ¬¡ 3 ---\n",
      "ğŸ‘¤ ç”¨æˆ·: ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\n",
      "ğŸ”„ æ¢å¤å¯¹è¯ä¼šè¯ (å·²æœ‰ 4 æ¡æ¶ˆæ¯)\n",
      "ğŸ¤– åŠ©æ‰‹: å°æ˜ï¼Œè¿™æ˜¯æˆ‘ä»¬çš„ç¬¬ 3 æ¬¡äº¤æµã€‚ä½ è¯´ï¼šä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\n",
      "\n",
      "--- å¯¹è¯è½®æ¬¡ 4 ---\n",
      "ğŸ‘¤ ç”¨æˆ·: æˆ‘å–œæ¬¢ç¼–ç¨‹\n",
      "ğŸ”„ æ¢å¤å¯¹è¯ä¼šè¯ (å·²æœ‰ 6 æ¡æ¶ˆæ¯)\n",
      "ğŸ¤– åŠ©æ‰‹: å°æ˜ï¼Œè¿™æ˜¯æˆ‘ä»¬çš„ç¬¬ 4 æ¬¡äº¤æµã€‚ä½ è¯´ï¼šæˆ‘å–œæ¬¢ç¼–ç¨‹\n",
      "\n",
      "--- å¯¹è¯è½®æ¬¡ 5 ---\n",
      "ğŸ‘¤ ç”¨æˆ·: å†è§ï¼\n",
      "ğŸ”„ æ¢å¤å¯¹è¯ä¼šè¯ (å·²æœ‰ 8 æ¡æ¶ˆæ¯)\n",
      "ğŸ¤– åŠ©æ‰‹: å°æ˜ï¼Œè¿™æ˜¯æˆ‘ä»¬çš„ç¬¬ 5 æ¬¡äº¤æµã€‚ä½ è¯´ï¼šå†è§ï¼\n",
      "\n",
      "=== æŸ¥çœ‹æœ€ç»ˆä¼šè¯çŠ¶æ€ ===\n",
      "ä¼šè¯å·²ä¿å­˜ï¼ŒåŒ…å«è¯¦ç»†çš„å¯¹è¯å†å²\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "@entrypoint(checkpointer=MemorySaver())\n",
    "def counter_workflow(increment: int, *, previous: Any = None) -> 'entrypoint.final[int, int]':\n",
    "    \"\"\"ä½¿ç”¨å…ˆå‰çŠ¶æ€ç»´æŠ¤è®¡æ•°å™¨çš„å·¥ä½œæµã€‚\"\"\"\n",
    "    current_count = previous if previous is not None else 0\n",
    "    new_count = current_count + increment\n",
    "    \n",
    "    print(f\"å½“å‰è®¡æ•°: {current_count}, å¢é‡: {increment}, æ–°è®¡æ•°: {new_count}\")\n",
    "    \n",
    "    # è¿”å›å½“å‰å€¼ç»™è°ƒç”¨è€…ï¼Œä¿å­˜æ–°å€¼åˆ°çŠ¶æ€\n",
    "    return entrypoint.final(value=current_count, save=new_count)\n",
    "\n",
    "@entrypoint(checkpointer=MemorySaver())\n",
    "def session_chat_workflow(\n",
    "    user_message: str, \n",
    "    *, \n",
    "    previous: Any = None\n",
    ") -> 'entrypoint.final[str, dict]':\n",
    "    \"\"\"å¸¦æœ‰ä¼šè¯è®°å¿†çš„èŠå¤©å·¥ä½œæµã€‚\"\"\"\n",
    "    # åˆå§‹åŒ–æˆ–æ¢å¤ä¼šè¯çŠ¶æ€\n",
    "    if previous is None:\n",
    "        session_state = {\n",
    "            \"messages\": [],\n",
    "            \"user_name\": None,\n",
    "            \"conversation_count\": 0\n",
    "        }\n",
    "        print(\"ğŸ†• å¼€å§‹æ–°çš„å¯¹è¯ä¼šè¯\")\n",
    "    else:\n",
    "        session_state = previous.copy()\n",
    "        print(f\"ğŸ”„ æ¢å¤å¯¹è¯ä¼šè¯ (å·²æœ‰ {len(session_state['messages'])} æ¡æ¶ˆæ¯)\")\n",
    "    \n",
    "    # æ›´æ–°ä¼šè¯çŠ¶æ€\n",
    "    session_state[\"conversation_count\"] += 1\n",
    "    session_state[\"messages\"].append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    # ç®€å•çš„èŠå¤©é€»è¾‘\n",
    "    if \"æˆ‘å«\" in user_message or \"æˆ‘æ˜¯\" in user_message:\n",
    "        # å°è¯•æå–ç”¨æˆ·å\n",
    "        parts = user_message.replace(\"æˆ‘å«\", \"\").replace(\"æˆ‘æ˜¯\", \"\").strip()\n",
    "        if parts:\n",
    "            session_state[\"user_name\"] = parts\n",
    "            response = f\"å¾ˆé«˜å…´è®¤è¯†ä½ ï¼Œ{parts}ï¼\"\n",
    "        else:\n",
    "            response = \"å¾ˆé«˜å…´è®¤è¯†ä½ ï¼\"\n",
    "    elif session_state[\"user_name\"]:\n",
    "        response = f\"{session_state['user_name']}ï¼Œè¿™æ˜¯æˆ‘ä»¬çš„ç¬¬ {session_state['conversation_count']} æ¬¡äº¤æµã€‚ä½ è¯´ï¼š{user_message}\"\n",
    "    else:\n",
    "        response = f\"è¿™æ˜¯æˆ‘ä»¬çš„ç¬¬ {session_state['conversation_count']} æ¬¡äº¤æµã€‚ä½ å¥½ï¼\"\n",
    "    \n",
    "    # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°ä¼šè¯å†å²\n",
    "    session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})\n",
    "    \n",
    "    return entrypoint.final(value=response, save=session_state)\n",
    "\n",
    "# æµ‹è¯•è®¡æ•°å™¨å·¥ä½œæµ\n",
    "print(\"=== æµ‹è¯•è®¡æ•°å™¨å·¥ä½œæµ ===\")\n",
    "config_counter = {\"configurable\": {\"thread_id\": \"counter_workflow_1\"}}\n",
    "\n",
    "for i, increment in enumerate([1, 2, 3, 5], 1):\n",
    "    result = counter_workflow.invoke(increment, config_counter)\n",
    "    print(f\"è°ƒç”¨ {i}: å¢é‡ {increment} -> è¿”å›å€¼ {result}\")\n",
    "print()\n",
    "\n",
    "# æµ‹è¯•ä¼šè¯èŠå¤©å·¥ä½œæµ\n",
    "print(\"=== æµ‹è¯•ä¼šè¯èŠå¤©å·¥ä½œæµ ===\")\n",
    "config_chat = {\"configurable\": {\"thread_id\": \"chat_workflow_1\"}}\n",
    "\n",
    "conversation = [\n",
    "    \"ä½ å¥½ï¼\",\n",
    "    \"æˆ‘å«å°æ˜\",\n",
    "    \"ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\",\n",
    "    \"æˆ‘å–œæ¬¢ç¼–ç¨‹\",\n",
    "    \"å†è§ï¼\"\n",
    "]\n",
    "\n",
    "for i, message in enumerate(conversation, 1):\n",
    "    print(f\"\\n--- å¯¹è¯è½®æ¬¡ {i} ---\")\n",
    "    print(f\"ğŸ‘¤ ç”¨æˆ·: {message}\")\n",
    "    response = session_chat_workflow.invoke(message, config_chat)\n",
    "    print(f\"ğŸ¤– åŠ©æ‰‹: {response}\")\n",
    "\n",
    "# æŸ¥çœ‹æœ€ç»ˆä¼šè¯çŠ¶æ€\n",
    "print(\"\\n=== æŸ¥çœ‹æœ€ç»ˆä¼šè¯çŠ¶æ€ ===\")\n",
    "final_state = session_chat_workflow.get_state(config_chat)\n",
    "if hasattr(final_state, 'values'):\n",
    "    print(\"ä¼šè¯å·²ä¿å­˜ï¼ŒåŒ…å«è¯¦ç»†çš„å¯¹è¯å†å²\")\n",
    "else:\n",
    "    print(\"çŠ¶æ€ç®¡ç†æ­£å¸¸å·¥ä½œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-6-17",
   "metadata": {},
   "source": [
    "**ğŸ’¡ çŸ­æœŸè®°å¿†æœºåˆ¶è§£æ**ï¼š\n",
    "\n",
    "- **`previous` å‚æ•°**: è‡ªåŠ¨æ³¨å…¥ä¸Šæ¬¡æ‰§è¡Œä¿å­˜çš„çŠ¶æ€\n",
    "- **`entrypoint.final()`**: åˆ†ç¦»è¿”å›å€¼å’Œä¿å­˜çŠ¶æ€ï¼Œæä¾›çµæ´»çš„çŠ¶æ€ç®¡ç†\n",
    "- **çŠ¶æ€æŒç»­æ€§**: åŒä¸€ `thread_id` ä¸‹çš„çŠ¶æ€åœ¨è°ƒç”¨é—´ä¿æŒè¿ç»­\n",
    "- **åº”ç”¨åœºæ™¯**: é€‚ç”¨äºéœ€è¦è·¨è°ƒç”¨ç»´æŠ¤ä¸Šä¸‹æ–‡çš„å¯¹è¯ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c578f05",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 6-18ï¼šåœ¨ Functional API ä¸­å®ç°é•¿æœŸè®°å¿†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "664d6d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ä½¿ç”¨ invoke åŒæ­¥æ‰§è¡Œ ===\n",
      "ç»“æœ: æ‚¨å¥½ï¼æ ¹æ®æ‚¨çš„æŸ¥è¯¢ 'ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ' å’Œåå¥½è®¾ç½®ï¼Œä¸ºæ‚¨æä¾›ä¸­æ–‡æœåŠ¡ã€‚\n",
      "\n",
      "=== ä½¿ç”¨ stream æµå¼æ‰§è¡Œ ===\n",
      "ğŸ“¢ è¿›åº¦: å¼€å§‹ä¸ªæ€§åŒ–å·¥ä½œæµï¼Œçº¿ç¨‹: personalized_workflow_2\n",
      "ğŸ“¢ è¿›åº¦: è·å–ç”¨æˆ· user_456 çš„åå¥½...\n",
      "ğŸ”„ æ›´æ–°: ['retrieve_user_preferences']\n",
      "ğŸ“¢ è¿›åº¦: ç”¨æˆ·åå¥½: {'theme': 'light', 'language': 'zh-CN', 'notifications': True}\n",
      "ğŸ”„ æ›´æ–°: ['store_user_preferences']\n",
      "ğŸ“¢ è¿›åº¦: åå¥½æ›´æ–°ç»“æœ: å·²ä¿å­˜ç”¨æˆ· user_456 çš„åå¥½è®¾ç½®\n",
      "ğŸ“¢ è¿›åº¦: ä¸ªæ€§åŒ–å·¥ä½œæµå®Œæˆ\n",
      "ğŸ”„ æ›´æ–°: ['personalized_workflow']\n",
      "\n",
      "=== æµ‹è¯•å­˜å‚¨æŒä¹…æ€§ ===\n",
      "ç¬¬äºŒæ¬¡è°ƒç”¨ç»“æœ: æ‚¨å¥½ï¼æ ¹æ®æ‚¨çš„æŸ¥è¯¢ 'æ˜å¤©ä¼šä¸‹é›¨å—ï¼Ÿ' å’Œåå¥½è®¾ç½®ï¼Œä¸ºæ‚¨æä¾›ä¸­æ–‡æœåŠ¡ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langgraph.func import entrypoint, task\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.types import StreamWriter\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing import Any\n",
    "\n",
    "# åˆå§‹åŒ–é•¿æœŸå†…å­˜å­˜å‚¨\n",
    "store = InMemoryStore()\n",
    "\n",
    "@task\n",
    "def retrieve_user_preferences(user_id: str, *, store: BaseStore):\n",
    "    \"\"\"ä»é•¿æœŸå†…å­˜ä¸­æ£€ç´¢ç”¨æˆ·åå¥½çš„ä»»åŠ¡\"\"\"\n",
    "    try:\n",
    "        preferences_data = store.get((\"user_preferences\", user_id), \"preferences\")\n",
    "        if preferences_data:\n",
    "            return preferences_data.value\n",
    "        else:\n",
    "            return {\"theme\": \"light\", \"language\": \"zh-CN\", \"notifications\": True}  # é»˜è®¤åå¥½\n",
    "    except Exception as e:\n",
    "        print(f\"è·å–ç”¨æˆ·åå¥½æ—¶å‡ºé”™: {e}\")\n",
    "        return {\"theme\": \"light\", \"language\": \"zh-CN\", \"notifications\": True}\n",
    "\n",
    "@task  \n",
    "def store_user_preferences(user_id: str, preferences: dict, *, store: BaseStore):\n",
    "    \"\"\"å­˜å‚¨ç”¨æˆ·åå¥½åˆ°é•¿æœŸå†…å­˜çš„ä»»åŠ¡\"\"\"\n",
    "    try:\n",
    "        store.put((\"user_preferences\", user_id), \"preferences\", preferences)\n",
    "        return f\"å·²ä¿å­˜ç”¨æˆ· {user_id} çš„åå¥½è®¾ç½®\"\n",
    "    except Exception as e:\n",
    "        print(f\"å­˜å‚¨ç”¨æˆ·åå¥½æ—¶å‡ºé”™: {e}\")\n",
    "        return f\"ä¿å­˜å¤±è´¥: {e}\"\n",
    "\n",
    "@entrypoint(checkpointer=MemorySaver(), store=store)\n",
    "def personalized_workflow(\n",
    "    input_data: dict,  \n",
    "    *,\n",
    "    store: BaseStore,\n",
    "    writer: StreamWriter,\n",
    "    config: RunnableConfig\n",
    ") -> str:\n",
    "    \"\"\"è®¿é—®é•¿æœŸè®°å¿†çš„ä¸ªæ€§åŒ–å·¥ä½œæµ\"\"\"\n",
    "    # ä»è¾“å…¥æ•°æ®ä¸­æå–å‚æ•°\n",
    "    user_id = input_data[\"user_id\"]\n",
    "    query = input_data[\"query\"]\n",
    "\n",
    "    thread_id = config.get(\"configurable\", {}).get(\"thread_id\", \"unknown\")\n",
    "    writer(f\"å¼€å§‹ä¸ªæ€§åŒ–å·¥ä½œæµï¼Œçº¿ç¨‹: {thread_id}\")\n",
    "\n",
    "    # è·å–ç”¨æˆ·åå¥½\n",
    "    writer(f\"è·å–ç”¨æˆ· {user_id} çš„åå¥½...\")\n",
    "    user_prefs = retrieve_user_preferences(user_id, store=store).result()\n",
    "    writer(f\"ç”¨æˆ·åå¥½: {user_prefs}\")\n",
    "\n",
    "    # æ ¹æ®åå¥½å¤„ç†æŸ¥è¯¢\n",
    "    if user_prefs.get(\"language\") == \"zh-CN\":\n",
    "        response = f\"æ‚¨å¥½ï¼æ ¹æ®æ‚¨çš„æŸ¥è¯¢ '{query}' å’Œåå¥½è®¾ç½®ï¼Œä¸ºæ‚¨æä¾›ä¸­æ–‡æœåŠ¡ã€‚\"\n",
    "    else:\n",
    "        response = f\"Hello! Based on your query '{query}' and preferences, providing service in English.\"\n",
    "\n",
    "    # å¯é€‰ï¼šæ›´æ–°åå¥½ï¼ˆä¾‹å¦‚è®°å½•æœ€è¿‘æŸ¥è¯¢ï¼‰\n",
    "    updated_prefs = user_prefs.copy()\n",
    "    updated_prefs[\"last_query\"] = query\n",
    "    store_result = store_user_preferences(user_id, updated_prefs, store=store).result()\n",
    "    writer(f\"åå¥½æ›´æ–°ç»“æœ: {store_result}\")\n",
    "\n",
    "    writer(\"ä¸ªæ€§åŒ–å·¥ä½œæµå®Œæˆ\")\n",
    "    return response\n",
    "\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"personalized_workflow_1\"}}\n",
    "\n",
    "# æ–¹å¼1: ä½¿ç”¨ invoke åŒæ­¥æ‰§è¡Œ\n",
    "print(\"=== ä½¿ç”¨ invoke åŒæ­¥æ‰§è¡Œ ===\")\n",
    "input_data = {\n",
    "    \"user_id\": \"user_123\",\n",
    "    \"query\": \"ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"\n",
    "}\n",
    "result = personalized_workflow.invoke(input_data, config=config)\n",
    "print(f\"ç»“æœ: {result}\")\n",
    "print()\n",
    "\n",
    "# æ–¹å¼2: ä½¿ç”¨ stream æµå¼æ‰§è¡Œï¼ˆå¯ä»¥çœ‹åˆ°ä¸­é—´è¿‡ç¨‹ï¼‰\n",
    "print(\"=== ä½¿ç”¨ stream æµå¼æ‰§è¡Œ ===\")\n",
    "input_data2 = {\n",
    "    \"user_id\": \"user_456\",\n",
    "    \"query\": \"What's the weather like today?\"\n",
    "}\n",
    "for chunk in personalized_workflow.stream(\n",
    "    input_data2,\n",
    "    config={\"configurable\": {\"thread_id\": \"personalized_workflow_2\"}},\n",
    "    stream_mode=[\"custom\", \"updates\"]\n",
    "):\n",
    "    if chunk[0] == \"custom\":\n",
    "        print(f\"ğŸ“¢ è¿›åº¦: {chunk[1]}\")\n",
    "    elif chunk[0] == \"updates\":\n",
    "        print(f\"ğŸ”„ æ›´æ–°: {list(chunk[1].keys())}\")\n",
    "print()\n",
    "\n",
    "# æ–¹å¼3: æµ‹è¯•å­˜å‚¨æŒä¹…æ€§ - å†æ¬¡è°ƒç”¨åŒä¸€ç”¨æˆ·\n",
    "print(\"=== æµ‹è¯•å­˜å‚¨æŒä¹…æ€§ ===\")\n",
    "input_data3 = {\n",
    "    \"user_id\": \"user_123\",  # åŒä¸€ç”¨æˆ·\n",
    "    \"query\": \"æ˜å¤©ä¼šä¸‹é›¨å—ï¼Ÿ\"\n",
    "}\n",
    "result2 = personalized_workflow.invoke(input_data3, config={\"configurable\": {\"thread_id\": \"personalized_workflow_3\"}})\n",
    "print(f\"ç¬¬äºŒæ¬¡è°ƒç”¨ç»“æœ: {result2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api-comparison",
   "metadata": {},
   "source": [
    "### API ç‰¹æ€§å¯¹æ¯”æ€»ç»“\n",
    "\n",
    "| ç‰¹æ€§ | `create_react_agent` | Functional API | Graph API |\n",
    "|------|---------------------|----------------|----------|\n",
    "| **å­¦ä¹ æ›²çº¿** | æœ€ä½ | ä¸­ç­‰ | è¾ƒé«˜ |\n",
    "| **å¼€å‘é€Ÿåº¦** | æœ€å¿« | å¿«é€Ÿ | ä¸­ç­‰ |\n",
    "| **çµæ´»æ€§** | æœ‰é™ | é«˜ | æœ€é«˜ |\n",
    "| **å¯æ‰©å±•æ€§** | ä½ | ä¸­ç­‰ | é«˜ |\n",
    "| **é€‚ç”¨åœºæ™¯** | ReAct æ¨¡å¼ | ä¸­ç­‰å¤æ‚åº¦ | å¤æ‚ç³»ç»Ÿ |\n",
    "| **ä»£ç é£æ ¼** | é…ç½®å¼ | å‡½æ•°å¼ | å£°æ˜å¼ |\n",
    "| **è°ƒè¯•æ”¯æŒ** | LangSmith è‡ªåŠ¨ | ä»»åŠ¡çº§è·Ÿè¸ª | èŠ‚ç‚¹çº§å¯è§†åŒ– |\n",
    "| **çŠ¶æ€ç®¡ç†** | è‡ªåŠ¨ | çµæ´» | å®Œå…¨æ§åˆ¶ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter-conclusion",
   "metadata": {},
   "source": [
    "## ğŸ“š æœ¬ç« æ€»ç»“\n",
    "\n",
    "é€šè¿‡æœ¬ç« çš„å­¦ä¹ ï¼Œæˆ‘ä»¬å…¨é¢æ¢ç´¢äº† LangGraph æ¡†æ¶æä¾›çš„ä¸‰ç§ä¸»è¦ API é€‰é¡¹ï¼Œæ·±å…¥ç†è§£äº†å®ƒä»¬å„è‡ªçš„ç‰¹ç‚¹ã€ä¼˜åŠ¿å’Œé€‚ç”¨åœºæ™¯ã€‚é¦–å…ˆå­¦ä¹ äº† `create_react_agent` é¢„æ„å»º APIï¼ŒæŒæ¡äº†å¿«é€Ÿæ„å»º ReAct æ™ºèƒ½ä½“çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬è‡ªå®šä¹‰æç¤ºã€è®°å¿†é›†æˆã€äººæœºç¯è·¯å’Œç»“æ„åŒ–è¾“å‡ºç­‰é«˜çº§åŠŸèƒ½ã€‚æ¥ç€æ·±å…¥ç ”ç©¶äº† Functional APIï¼Œå­¦ä¼šä½¿ç”¨ `@entrypoint` å’Œ `@task` è£…é¥°å™¨æ„å»ºå‡½æ•°å¼å·¥ä½œæµï¼ŒæŒæ¡äº†å¹¶è¡Œæ‰§è¡Œã€å­å·¥ä½œæµç»„åˆã€è‡ªå®šä¹‰æµå¼ä¼ è¾“ã€é‡è¯•ç­–ç•¥å’ŒçŠ¶æ€ç®¡ç†ç­‰æ ¸å¿ƒæŠ€æœ¯ã€‚ç„¶åå›é¡¾äº† Graph API çš„æ ¸å¿ƒä»·å€¼ï¼Œç†è§£äº†å…¶åœ¨å¤„ç†å¤æ‚æ™ºèƒ½ä½“æ¶æ„ä¸­çš„ä¸å¯æ›¿ä»£æ€§ã€‚æœ€åå»ºç«‹äº† API é€‰æ‹©å†³ç­–æ¡†æ¶ï¼Œå­¦ä¼šæ ¹æ®é¡¹ç›®å¤æ‚åº¦ã€å›¢é˜Ÿç»éªŒã€æ—¶é—´è¦æ±‚å’Œå¯æ‰©å±•æ€§éœ€æ±‚é€‰æ‹©æœ€é€‚åˆçš„ APIã€‚è¿™äº›å¤šæ ·åŒ–çš„ API é€‰é¡¹ç¡®ä¿äº† LangGraph èƒ½å¤Ÿæ»¡è¶³ä»å¿«é€ŸåŸå‹åˆ°å¤æ‚ç”Ÿäº§ç³»ç»Ÿçš„å„ç§å¼€å‘éœ€æ±‚ï¼Œä¸ºæ„å»ºä¸‹ä¸€ä»£ AI æ™ºèƒ½ä½“åº”ç”¨æä¾›äº†å¼ºæœ‰åŠ›çš„å·¥å…·æ”¯æŒã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
