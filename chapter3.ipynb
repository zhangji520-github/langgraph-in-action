{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7434284",
   "metadata": {},
   "source": [
    "# 第 3 章：图驱动的 AI 智能体系统\n",
    "\n",
    "> 本笔记文件需要与《LangGraph实战》的第 3 章的内容配套使用。\n",
    "\n",
    "我们习惯于用线性的、因果的视角去理解世界，如同手持一张粗略的地图，在一条条既定的道路上按部就班地前行。然而，真实的疆域远比地图复杂，它充满了未知的岔路、突发的状况，以及无数交织的可能性。当我们试图构建能够理解、适应并驾驭这个复杂世界的 AI 智能体时，线性的思维模式便显得捉襟见肘。**图**，正是这样一种活地图，它超越了线性结构的局限，以节点和边构建起一个充满可能性的网络，让我们得以描绘智能体系统中那些非线性的、动态的、错综复杂的行为路径。\n",
    "\n",
    "本章将深入探讨 LangGraph 的图计算模型，学习如何利用状态、节点、边、命令这四个核心原语构建复杂的智能体系统，掌握并行处理、MapReduce模式、子图机制等高级技术，最终构建出能够应对真实世界复杂挑战的智能体应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environment-setup",
   "metadata": {},
   "source": [
    "### 🚀 环境准备\n",
    "\n",
    "首先加载必要的环境变量配置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-1",
   "metadata": {},
   "source": [
    "## 3.1 核心原语：状态、节点、边和命令\n",
    "\n",
    "LangGraph 的核心在于其简洁而强大的图计算模型，这一模型的基石由四个核心原语构成：**状态（State）**、**节点（Node）**、**边（Edge）**，以及**命令（Command）**。\n",
    "\n",
    "理解这四个原语的概念及其相互作用方式，是掌握 LangGraph 并构建复杂智能体系统的重中之重。可以将这四个原语比作乐高积木最基本的、也是最核心的模块，理解了它们，就如同掌握了乐高搭建的\"语言\"，后续才能使用更高级的技巧，搭建出各种各样精巧、复杂、功能强大的智能体系统。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-1-1",
   "metadata": {},
   "source": [
    "### 3.1.1 状态（State）\n",
    "\n",
    "在 LangGraph 中，状态是贯穿智能体系统运行始终的核心概念。我们可以将其理解为智能体的\"短期记忆\"、\"工作记忆\"或者\"临时共享数据空间\"，它承载着智能体在执行过程中产生的各种信息，例如用户的输入、中间计算结果、工具的输出、对话历史等等。\n",
    "\n",
    "LangGraph 在状态定义上提供了极大的灵活性，允许开发者根据实际应用的需求，选择最合适的数据结构来表示状态。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-3-1",
   "metadata": {},
   "source": [
    "##### 示例 3-1：使用 TypedDict 和 Pydantic 定义状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, field_validator\n",
    "\n",
    "# 使用 TypedDict 定义状态\n",
    "class TypedDictState(TypedDict):\n",
    "    user_input: str\n",
    "    agent_response: str\n",
    "    tool_output: str\n",
    "\n",
    "# 使用 Pydantic 定义状态，并进行数据验证\n",
    "class PydanticState(BaseModel):\n",
    "    user_input: str\n",
    "    agent_response: str\n",
    "    tool_output: str\n",
    "    mood: str = \"neutral\"  # 默认情绪状态为 neutral\n",
    "\n",
    "    @field_validator('mood')\n",
    "    @classmethod\n",
    "    def validate_mood(cls, value):\n",
    "        if value not in [\"happy\", \"sad\", \"neutral\"]:\n",
    "            raise ValueError(\"情绪状态必须是 'happy', 'sad' 或 'neutral'\")\n",
    "        return value\n",
    "\n",
    "# 测试状态定义\n",
    "print(\"TypedDict 状态示例:\")\n",
    "typed_state = {\"user_input\": \"Hello\", \"agent_response\": \"Hi there!\", \"tool_output\": \"weather data\"}\n",
    "print(typed_state)\n",
    "\n",
    "print(\"\\nPydantic 状态示例:\")\n",
    "pydantic_state = PydanticState(\n",
    "    user_input=\"Hello\", \n",
    "    agent_response=\"Hi there!\", \n",
    "    tool_output=\"weather data\",\n",
    "    mood=\"happy\"\n",
    ")\n",
    "print(pydantic_state.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-3-1",
   "metadata": {},
   "source": [
    "**💡 核心概念解析**：\n",
    "\n",
    "- **TypedDict**：可以快速定义简单的状态结构，提供类型提示但不进行运行时验证\n",
    "- **Pydantic**：提供更强大的数据建模和验证能力，能够在运行时进行数据验证，确保状态的类型和取值符合预期\n",
    "- **状态的作用**：作为各节点间信息传递的桥梁，也是智能体进行决策和行为调整的重要依据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab12b8c",
   "metadata": {},
   "source": [
    "##### 示例 3-2：使用多结构体实现私有状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c172e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import json\n",
    "\n",
    "# 定义全局的公共状态 Schema\n",
    "class OverallState(TypedDict):\n",
    "    user_input: str\n",
    "    agent_response: str\n",
    "\n",
    "# 定义节点的私有状态 Schema\n",
    "class ToolState(TypedDict):\n",
    "    api_key: str\n",
    "    tool_config: dict\n",
    "    user_input: str  # 需要包含从公共状态传递的数据\n",
    "\n",
    "# 模拟 API 客户端类\n",
    "class MockAPIClient:\n",
    "    def __init__(self, api_key: str, config: dict):\n",
    "        self.api_key = api_key\n",
    "        self.config = config\n",
    "        print(f\"初始化 API 客户端，API Key: {api_key[:8]}..., 配置: {config}\")\n",
    "\n",
    "    def call_api(self, user_input: str) -> str:\n",
    "        # 模拟 API 调用\n",
    "        response = f\"基于输入 '{user_input}' 和配置 {self.config}，API 返回处理结果\"\n",
    "        print(f\"调用 API，输入: {user_input}\")\n",
    "        return response\n",
    "\n",
    "def create_api_client(api_key: str, tool_config: dict) -> MockAPIClient:\n",
    "    \"\"\"创建 API 客户端的工厂函数\"\"\"\n",
    "    return MockAPIClient(api_key, tool_config)\n",
    "\n",
    "# 定义一个使用私有状态的节点\n",
    "def tool_node(state: ToolState) -> OverallState:\n",
    "    \"\"\"使用私有状态的工具节点\"\"\"\n",
    "    print(f\"工具节点接收到私有状态: {state}\")\n",
    "\n",
    "    # 节点逻辑，例如调用工具 API 并根据 ToolState 中的配置进行操作\n",
    "    api_client = create_api_client(state['api_key'], state['tool_config'])\n",
    "    response = api_client.call_api(state['user_input'])\n",
    "\n",
    "    return {\"agent_response\": response}  # 返回更新后的公共状态\n",
    "\n",
    "# 定义一个输入处理节点\n",
    "def input_processor(state: OverallState) -> OverallState:\n",
    "    \"\"\"处理用户输入的节点\"\"\"\n",
    "    print(f\"输入处理节点接收到: {state['user_input']}\")\n",
    "    processed_input = f\"已处理: {state['user_input']}\"\n",
    "    return {\"user_input\": processed_input}\n",
    "\n",
    "# 定义状态适配节点，将公共状态转换为私有状态\n",
    "def state_adapter(state: OverallState) -> dict:\n",
    "    \"\"\"适配器节点：将公共状态转换为私有状态\"\"\"\n",
    "    from langgraph.constants import Send\n",
    "\n",
    "    # 创建私有状态数据\n",
    "    private_state = {\n",
    "        \"api_key\": \"secret_api_key_12345\",\n",
    "        \"tool_config\": {\n",
    "            \"timeout\": 30,\n",
    "            \"retry_count\": 3,\n",
    "            \"endpoint\": \"https://api.example.com\"\n",
    "        },\n",
    "        \"user_input\": state[\"user_input\"]\n",
    "    }\n",
    "\n",
    "    # 使用 Send 将私有状态发送给工具节点\n",
    "    return Send(\"tool_node\", private_state)\n",
    "\n",
    "# 构建图\n",
    "builder = StateGraph(OverallState)\n",
    "\n",
    "# 添加节点\n",
    "builder.add_node(\"input_processor\", input_processor)\n",
    "builder.add_node(\"state_adapter\", state_adapter)\n",
    "builder.add_node(\"tool_node\", tool_node)\n",
    "\n",
    "# 定义边\n",
    "builder.add_edge(START, \"input_processor\")\n",
    "builder.add_conditional_edges(\"input_processor\", state_adapter, [\"tool_node\"])\n",
    "builder.add_edge(\"tool_node\", END)\n",
    "\n",
    "# 编译图\n",
    "graph = builder.compile()\n",
    "\n",
    "# 测试运行\n",
    "print(\"=== 多结构体状态管理示例 ===\\n\")\n",
    "\n",
    "# 初始状态\n",
    "initial_state = {\n",
    "    \"user_input\": \"查询天气信息\",\n",
    "    \"agent_response\": \"\"\n",
    "}\n",
    "\n",
    "print(f\"初始状态: {initial_state}\\n\")\n",
    "\n",
    "# 运行图\n",
    "try:\n",
    "    final_state = graph.invoke(initial_state)\n",
    "    print(f\"\\n最终状态: {final_state}\")\n",
    "\n",
    "    print(f\"\\n=== 执行结果 ===\")\n",
    "    print(f\"用户输入: {final_state['user_input']}\")\n",
    "    print(f\"智能体响应: {final_state['agent_response']}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"执行出错: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9df6d",
   "metadata": {},
   "source": [
    "这个完整的示例展示了：\n",
    "\n",
    "1. 多结构体定义：\n",
    "  - `OverallState`：全局公共状态，包含用户输入和智能体响应\n",
    "  - `ToolState`：私有状态，包含 API 密钥、工具配置和用户输入\n",
    "2. 状态转换机制：\n",
    "  - `state_adapter` 节点负责将公共状态转换为私有状态\n",
    "  - 使用 Send API 将私有状态发送给特定节点\n",
    "3. 私有状态的使用：\n",
    "  - `tool_node` 接收私有状态，包含敏感信息（API 密钥、配置）\n",
    "  - 节点处理完成后返回公共状态格式的更新\n",
    "4. 完整的工作流：\n",
    "  - 输入处理 → 状态适配 → 工具调用 → 结果返回"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740f1a88",
   "metadata": {},
   "source": [
    "##### 示例 3-3：定义输入/输出结构体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196d3c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏗️ 构建 LangGraph（带输入输出结构体约束）...\n",
      "✅ 图构建完成！\n",
      "\n",
      "=== 🚀 输入输出结构体约束示例 ===\n",
      "📥 输入数据 (InputSchema): {'user_query': '什么是人工智能'}\n",
      "🔍 搜索节点: 处理查询 '什么是人工智能'\n",
      "📊 搜索完成，找到 3 条结果\n",
      "🤖 LLM 节点: 基于 3 条搜索结果生成回复\n",
      "💭 LLM 处理完成，生成 80 字符的回复\n",
      "📝 生成回复: 基于您的查询 '什么是人工智能'，我找到了以下信息：搜索结果1: 关于 '什么是人工智能' 的信息 ...\n",
      "\n",
      "📤 输出数据 (OutputSchema): {'llm_response': \"基于您的查询 '什么是人工智能'，我找到了以下信息：搜索结果1: 关于 '什么是人工智能' 的信息 | 搜索结果2: 什么是人工智能 相关数据。希望这能帮到您！\"}\n",
      "📊 输出类型: <class 'dict'>\n",
      "📋 输出键: ['llm_response']\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# 定义内部的、全面的状态结构体\n",
    "class InternalState(TypedDict):\n",
    "    user_query: str\n",
    "    search_results: list[str]\n",
    "    llm_response: str\n",
    "    debug_info: str  # 内部调试信息，不需要对外暴露\n",
    "\n",
    "# 定义输入结构体 (只包含 user_query)\n",
    "class InputSchema(TypedDict):\n",
    "    user_query: str\n",
    "\n",
    "# 定义输出结构体 (只包含 llm_response)\n",
    "class OutputSchema(TypedDict):\n",
    "    llm_response: str\n",
    "\n",
    "# 模拟搜索节点\n",
    "def search_node(state: InternalState) -> InternalState:\n",
    "    query = state[\"user_query\"]\n",
    "    print(f\"🔍 搜索节点: 处理查询 '{query}'\")\n",
    "\n",
    "    # 模拟搜索结果\n",
    "    mock_results = [\n",
    "        f\"搜索结果1: 关于 '{query}' 的信息\",\n",
    "        f\"搜索结果2: {query} 相关数据\",\n",
    "        f\"搜索结果3: {query} 详细说明\"\n",
    "    ]\n",
    "\n",
    "    debug = f\"搜索完成，找到 {len(mock_results)} 条结果\"\n",
    "    print(f\"📊 {debug}\")\n",
    "\n",
    "    return {\n",
    "        \"search_results\": mock_results,\n",
    "        \"debug_info\": debug\n",
    "    }\n",
    "\n",
    "# LLM 处理节点\n",
    "def llm_node(state: InternalState) -> InternalState:\n",
    "    query = state[\"user_query\"]\n",
    "    results = state[\"search_results\"]\n",
    "\n",
    "    print(f\"🤖 LLM 节点: 基于 {len(results)} 条搜索结果生成回复\")\n",
    "\n",
    "    # 模拟 LLM 生成响应\n",
    "    combined_info = \" | \".join(results[:2])  # 使用前两条结果\n",
    "    response = f\"基于您的查询 '{query}'，我找到了以下信息：{combined_info}。希望这能帮到您！\"\n",
    "\n",
    "    debug = f\"LLM 处理完成，生成 {len(response)} 字符的回复\"\n",
    "    print(f\"💭 {debug}\")\n",
    "    print(f\"📝 生成回复: {response[:50]}...\")\n",
    "\n",
    "    return {\n",
    "        \"llm_response\": response,\n",
    "        \"debug_info\": state.get(\"debug_info\", \"\") + f\" | {debug}\"\n",
    "    }\n",
    "\n",
    "# 创建图并指定输入输出结构体\n",
    "print(\"🏗️ 构建 LangGraph（带输入输出结构体约束）...\")\n",
    "builder = StateGraph(\n",
    "    state_schema=InternalState,\n",
    "    input_schema=InputSchema,\n",
    "    output_schema=OutputSchema\n",
    ")\n",
    "\n",
    "# 添加节点\n",
    "builder.add_node(\"search\", search_node)\n",
    "builder.add_node(\"llm\", llm_node)\n",
    "\n",
    "# 定义边\n",
    "builder.add_edge(START, \"search\")\n",
    "builder.add_edge(\"search\", \"llm\")\n",
    "builder.add_edge(\"llm\", END)\n",
    "\n",
    "# 编译图\n",
    "graph = builder.compile()\n",
    "print(\"✅ 图构建完成！\")\n",
    "\n",
    "# 测试运行\n",
    "print(\"\\n=== 🚀 输入输出结构体约束示例 ===\")\n",
    "\n",
    "# 创建符合 InputSchema 的输入\n",
    "input_data = {\"user_query\": \"什么是人工智能\"}\n",
    "print(f\"📥 输入数据 (InputSchema): {input_data}\")\n",
    "\n",
    "# 运行图\n",
    "result = graph.invoke(input_data)\n",
    "# 保存图\n",
    "from draw import save_graph_as_png\n",
    "save_graph_as_png(graph, \"./graphs/c3/input_output_state.png\")\n",
    "\n",
    "# 结果自动符合 OutputSchema 格式\n",
    "print(f\"\\n📤 输出数据 (OutputSchema): {result}\")\n",
    "print(f\"📊 输出类型: {type(result)}\")\n",
    "print(f\"📋 输出键: {list(result.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0df85",
   "metadata": {},
   "source": [
    "1. 三层状态结构体：\n",
    "  - `InternalState`：内部完整状态，包含所有中间数据\n",
    "  - `InputSchema`：外部输入接口，只需要用户查询\n",
    "  - `OutputSchema`：外部输出接口，只返回最终回复\n",
    "2. 状态封装：\n",
    "  - 内部节点可以访问和修改完整的内部状态\n",
    "  - 外部只能看到定义的输入输出格式\n",
    "  - 调试信息、搜索结果等中间数据被隐藏\n",
    "3. 实际工作流程：\n",
    "  - 搜索节点模拟信息检索\n",
    "  - LLM 节点基于搜索结果生成回复\n",
    "  - 完整的状态管理和数据流\n",
    "4. 输入输出约束验证：\n",
    "  - 输入只需要符合 `InputSchema`\n",
    "  - 输出自动符合 `OutputSchema`\n",
    "  - 内部复杂性被完全封装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-1-1-3",
   "metadata": {},
   "source": [
    "#### 3.1.1.3 状态 Reducer \n",
    "\n",
    "状态 Reducer 是 LangGraph 提供的用于自定义状态更新逻辑的核心机制。它允许我们精细地控制状态在节点执行过程中的演变方式，尤其是在处理并发状态更新、复杂数据结构以及需要特定合并策略的场景下。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-3-4",
   "metadata": {},
   "source": [
    "##### 示例 3-4：使用状态 Reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "# 定义状态 Schema，并为 'message_history' 键指定 add_messages Reducer\n",
    "class ChatState(TypedDict):\n",
    "    message_history: Annotated[list[BaseMessage], add_messages]\n",
    "    user_intent: str\n",
    "    tool_output: str\n",
    "\n",
    "# 演示 add_messages Reducer 的工作方式\n",
    "print(\"演示 add_messages Reducer：\")\n",
    "\n",
    "# 初始状态\n",
    "initial_state = {\n",
    "    \"message_history\": [HumanMessage(content=\"Hello\")],\n",
    "    \"user_intent\": \"greeting\",\n",
    "    \"tool_output\": \"\"\n",
    "}\n",
    "\n",
    "print(\"初始状态:\")\n",
    "for msg in initial_state[\"message_history\"]:\n",
    "    print(f\"  {type(msg).__name__}: {msg.content}\")\n",
    "\n",
    "# 新的消息更新\n",
    "new_messages = [AIMessage(content=\"Hi there! How can I help you?\")]\n",
    "print(\"\\n添加新消息:\")\n",
    "for msg in new_messages:\n",
    "    print(f\"  {type(msg).__name__}: {msg.content}\")\n",
    "\n",
    "# add_messages Reducer 会自动合并消息\n",
    "updated_messages = add_messages(initial_state[\"message_history\"], new_messages)\n",
    "print(\"\\n合并后的消息历史:\")\n",
    "for msg in updated_messages:\n",
    "    print(f\"  {type(msg).__name__}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-3-5",
   "metadata": {},
   "source": [
    "##### 示例 3-5 & 3-6：自定义 Reducer 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer_extend_unique(left: list[str] | None, right: list[str] | None) -> list[str]:\n",
    "    \"\"\"\n",
    "    自定义 Reducer 函数，用于合并两个字符串列表，并进行去重\n",
    "    \"\"\"\n",
    "    existing_items = left if left else []  # 如果 left 为 None，则初始化为空列表\n",
    "    new_items = right if right else []     # 如果 right 为 None，则初始化为空列表\n",
    "    combined_items = existing_items + new_items\n",
    "    return list(set(combined_items))       # 使用 set 去重并转换为 list 返回\n",
    "\n",
    "# 测试自定义 Reducer\n",
    "print(\"测试自定义 Reducer：\")\n",
    "\n",
    "existing_list = [\"apple\", \"banana\", \"orange\"]\n",
    "new_list = [\"banana\", \"grape\", \"apple\", \"mango\"]\n",
    "\n",
    "print(f\"已有列表: {existing_list}\")\n",
    "print(f\"新增列表: {new_list}\")\n",
    "\n",
    "result = reducer_extend_unique(existing_list, new_list)\n",
    "print(f\"合并去重结果: {result}\")\n",
    "\n",
    "# 在状态结构体中应用自定义 Reducer\n",
    "class ChatStateWithCustomReducer(TypedDict):\n",
    "    message_history: Annotated[list[BaseMessage], add_messages]\n",
    "    user_intent: str\n",
    "    tool_output: str\n",
    "    item_list: Annotated[list[str], reducer_extend_unique]  # 应用自定义 Reducer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-1-1-4",
   "metadata": {},
   "source": [
    "#### 3.1.1.4 Message 与 MessagesState\n",
    "\n",
    "在构建对话型 AI 智能体时，对话历史至关重要。LangGraph 引入了消息（Message）和 MessagesState 的概念，专门优化对话场景的状态管理。\n",
    "\n",
    "LangChain 定义了多种消息类型：\n",
    "- `HumanMessage`：代表人类用户的消息\n",
    "- `AIMessage`：代表 AI 模型生成的消息\n",
    "- `ToolMessage`：代表工具执行后的输出结果消息\n",
    "- `SystemMessage`：代表系统发出的消息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-3-7",
   "metadata": {},
   "source": [
    "##### 示例 3-7：使用 MessagesState 定义状态结构体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "演示不同类型的消息：\n",
      "1. SystemMessage: 你是一个专业的天气助手，请友好地回复用户\n",
      "2. HumanMessage: 你好，我想查询今天的天气\n",
      "3. AIMessage: 好的，我来帮你查询天气信息\n",
      "4. ToolMessage: 北京今天晴转多云，温度 20-28°C\n",
      "\n",
      "演示 MessagesState 的状态管理：\n",
      "messages:[SystemMessage(content='你是一个专业的天气助手，请友好地回复用户', additional_kwargs={}, response_metadata={}), HumanMessage(content='你好，我想查询今天的天气', additional_kwargs={}, response_metadata={}), AIMessage(content='好的，我来帮你查询天气信息', additional_kwargs={}, response_metadata={}), ToolMessage(content='北京今天晴转多云，温度 20-28°C', tool_call_id='weather_001')]\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, SystemMessage\n",
    "\n",
    "class MyChatState(MessagesState):\n",
    "    \"\"\"\n",
    "    自定义的 ChatState, 继承自 MessagesState, \n",
    "    自动包含 messages 状态键和 add_messages Reducer\n",
    "    \"\"\"\n",
    "    user_intent: str\n",
    "    tool_output: str\n",
    "    # ... 可以添加其他自定义的状态键 ...\n",
    "\n",
    "# 演示不同类型的消息\n",
    "print(\"演示不同类型的消息：\")\n",
    "\n",
    "# 创建不同类型的消息\n",
    "human_msg = HumanMessage(content=\"你好，我想查询今天的天气\")\n",
    "system_msg = SystemMessage(content=\"你是一个专业的天气助手，请友好地回复用户\")\n",
    "ai_msg = AIMessage(content=\"好的，我来帮你查询天气信息\")\n",
    "tool_msg = ToolMessage(content=\"北京今天晴转多云，温度 20-28°C\", tool_call_id=\"weather_001\")\n",
    "\n",
    "messages = [system_msg, human_msg, ai_msg, tool_msg]\n",
    "\n",
    "for i, msg in enumerate(messages, 1):\n",
    "    print(f\"{i}. {type(msg).__name__}: {msg.content}\")\n",
    "\n",
    "# 演示 MessagesState 的使用\n",
    "print(\"\\n演示 MessagesState 的状态管理：\")\n",
    "chat_state = {\n",
    "    \"messages\": messages,\n",
    "    \"user_intent\": \"weather_query\",\n",
    "    \"tool_output\": \"weather_data_retrieved\"\n",
    "}\n",
    "\n",
    "# print(f\"对话轮次: {len(chat_state['messages'])}\")\n",
    "# print(f\"用户意图: {chat_state['user_intent']}\")\n",
    "# print(f\"工具输出: {chat_state['tool_output']}\")\n",
    "print(f'messages:{chat_state['messages']}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-3-7",
   "metadata": {},
   "source": [
    "**💡 MessagesState 核心特性**：\n",
    "\n",
    "- **内置 `messages` 状态键**：自动提供消息列表管理\n",
    "- **默认 `add_messages` Reducer**：自动处理消息追加、更新和去重\n",
    "- **消息序列化与反序列化**：支持 JSON 兼容的字典格式传递消息数据\n",
    "- **可扩展性**：可以自由添加其他自定义状态键"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d350119",
   "metadata": {},
   "source": [
    "##### 示例 3-8 & 3-9：在使用 MessagesState 的节点中使用 trim_messages 和 RemoveMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e673c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, trim_messages, RemoveMessage\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages.utils import count_tokens_approximately\n",
    "\n",
    "llm = ChatOpenAI(model=\"Qwen/Qwen3-8B\")\n",
    "\n",
    "# 使用 trim_messages 的节点\n",
    "def llm_node_with_trim(state: MessagesState):\n",
    "    print(\"🤖 LLM节点 (使用 trim_messages)\")\n",
    "    message_history = state['messages']\n",
    "    print(f\"📥 接收到 {len(message_history)} 条消息\")\n",
    "\n",
    "    # 显示原始消息\n",
    "    for i, msg in enumerate(message_history):\n",
    "        content_preview = msg.content[:50] + \"...\" if len(msg.content) > 50 else msg.content\n",
    "        print(f\"  {i+1}. [{msg.__class__.__name__}] {content_preview}\")\n",
    "\n",
    "    # 使用 trim_messages 修剪消息历史\n",
    "    trimmed_messages = trim_messages(\n",
    "        message_history,\n",
    "        max_tokens=200,  # 降低限制以便看到修剪效果\n",
    "        strategy=\"last\",\n",
    "        token_counter=count_tokens_approximately,\n",
    "        allow_partial=False\n",
    "    )\n",
    "\n",
    "    print(f\"✂️ 修剪后保留 {len(trimmed_messages)} 条消息 (token限制: 200)\")\n",
    "\n",
    "    # 生成回复\n",
    "    llm_response = llm.invoke(trimmed_messages)\n",
    "    print(f\"💭 生成回复: {llm_response.content}\")\n",
    "\n",
    "    return {\"messages\": [llm_response]}\n",
    "\n",
    "# 使用 filter_messages 的节点 (基于 RemoveMessage)\n",
    "def filter_node(state: MessagesState):\n",
    "    print(\"\\n🔧 过滤节点 (使用 RemoveMessage)\")\n",
    "    message_history = state['messages']\n",
    "    print(f\"📥 接收到 {len(message_history)} 条消息\")\n",
    "\n",
    "    remove_messages = []\n",
    "\n",
    "    # 过滤策略：移除包含\"你好\"或\"再见\"的寒暄消息\n",
    "    for msg in message_history:\n",
    "        if any(greeting in msg.content.lower() for greeting in [\"你好\",\n",
    "\"再见\", \"hello\", \"bye\"]):\n",
    "            print(f\"🗑️ 标记移除寒暄消息: {msg.content[:30]}...\")\n",
    "            remove_messages.append(RemoveMessage(id=msg.id))\n",
    "        # 移除过长的消息\n",
    "        elif len(msg.content) > 100:\n",
    "            print(f\"🗑️ 标记移除过长消息: {msg.content[:30]}...\")\n",
    "            remove_messages.append(RemoveMessage(id=msg.id))\n",
    "\n",
    "    if remove_messages:\n",
    "        print(f\"📊 将移除 {len(remove_messages)} 条消息\")\n",
    "        return {\"messages\": remove_messages}\n",
    "    else:\n",
    "        print(\"✅ 没有需要移除的消息\")\n",
    "        return {}\n",
    "\n",
    "# 添加用户消息的节点\n",
    "def add_user_message(state: MessagesState):\n",
    "    print(\"\\n👤 添加用户消息节点\")\n",
    "    new_message = HumanMessage(content=\"我想了解人工智能的最新发展，特别是在自然语言处理方面的突破。\")\n",
    "    print(f\"➕ 添加消息: {new_message.content}\")\n",
    "    return {\"messages\": [new_message]}\n",
    "\n",
    "# 创建图\n",
    "print(\"🏗️ 构建消息管理示例图...\")\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# 添加节点\n",
    "builder.add_node(\"add_message\", add_user_message)\n",
    "builder.add_node(\"filter\", filter_node)\n",
    "builder.add_node(\"llm_trim\", llm_node_with_trim)\n",
    "\n",
    "# 定义边\n",
    "builder.add_edge(START, \"add_message\")\n",
    "builder.add_edge(\"add_message\", \"filter\")\n",
    "builder.add_edge(\"filter\", \"llm_trim\")\n",
    "builder.add_edge(\"llm_trim\", END)\n",
    "\n",
    "# 编译图\n",
    "graph = builder.compile()\n",
    "print(\"✅ 图构建完成！\")\n",
    "\n",
    "# 准备初始消息历史\n",
    "print(\"\\n=== 🚀 消息状态管理示例 ===\")\n",
    "\n",
    "initial_messages = [\n",
    "    SystemMessage(content=\"你是一个专业的AI助手，擅长回答各种问题。\"),\n",
    "    HumanMessage(content=\"你好！很高兴见到你。\"),\n",
    "    AIMessage(content=\"你好！我也很高兴为您服务。有什么可以帮助您的吗？\"),\n",
    "    HumanMessage(content=\"这是一条很长很长很长很长很长很长很长很长很长很长很长很长很长很长很长很长很长很长的测试消息，用来测试过滤功能。\"),\n",
    "    AIMessage(content=\"我明白了您的测试消息。\"),\n",
    "    HumanMessage(content=\"再见！\"),\n",
    "]\n",
    "\n",
    "print(\"📋 初始消息历史:\")\n",
    "for i, msg in enumerate(initial_messages):\n",
    "    content_preview = msg.content[:40] + \"...\" if len(msg.content) > 40 else msg.content\n",
    "    print(f\"  {i+1}. [{msg.__class__.__name__}] {content_preview}\")\n",
    "\n",
    "# 运行图\n",
    "result = graph.invoke({\"messages\": initial_messages})\n",
    "\n",
    "print(f\"\\n=== ✨ 最终结果 ===\")\n",
    "print(f\"📊 最终消息历史包含 {len(result['messages'])} 条消息:\")\n",
    "for i, msg in enumerate(result['messages']):\n",
    "    content_preview = msg.content[:50] + \"...\" if len(msg.content) > 50 else msg.content\n",
    "    print(f\"  {i+1}. [{msg.__class__.__name__}] {content_preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e029ef6",
   "metadata": {},
   "source": [
    "1. `trim_messages` 功能：\n",
    "- 根据 Token 限制自动修剪消息历史\n",
    "- 使用 `\"last\"` 策略保留最近的消息\n",
    "- 模拟 Token 计数器进行 Token 估算\n",
    "2. `filter_messages` (`RemoveMessage`) 功能：\n",
    "- 根据内容规则过滤消息（移除寒暄语）\n",
    "- 根据长度规则过滤消息（移除过长消息）\n",
    "- 使用 `RemoveMessage` 标记要删除的消息\n",
    "3. `MessagesState` 自动管理：\n",
    "- 自动使用 `add_messages` Reducer\n",
    "- 支持消息的添加和移除操作\n",
    "- 维护完整的消息历史\n",
    "4. 实际工作流程：\n",
    "- 添加新的用户消息\n",
    "- 过滤不需要的消息\n",
    "- 使用修剪后的消息生成 LLM 回复\n",
    "- 展示完整的消息管理流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-1-2",
   "metadata": {},
   "source": [
    "### 3.1.2 节点（Node）\n",
    "\n",
    "节点是 LangGraph 图结构中的基本计算单元。每一个节点都封装了一个独立的计算逻辑，例如调用语言模型、执行工具、进行条件判断、或者仅仅是一个简单的数据处理函数。\n",
    "\n",
    "在 LangGraph 中，节点本质上就是一个 Python 函数。这个函数接收当前的状态作为输入，并返回一个新的状态（或者状态的更新部分）作为输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-3-10",
   "metadata": {},
   "source": [
    "##### 示例 3-10：节点函数的基本结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_node(state):\n",
    "    \"\"\"\n",
    "    节点函数示例\n",
    "    \"\"\"\n",
    "    # 从状态中读取数据\n",
    "    input_data = state.get(\"some_key\", \"default_value\")\n",
    "    \n",
    "    # 执行节点计算逻辑\n",
    "    def process_data(data):\n",
    "        return f\"处理后的数据: {data.upper()}\"\n",
    "    \n",
    "    output_data = process_data(input_data)\n",
    "    \n",
    "    # 返回新的状态（或状态的更新部分）\n",
    "    return {\"some_key\": output_data, \"another_key\": \"new_value\"}\n",
    "\n",
    "# 测试节点函数\n",
    "print(\"测试节点函数：\")\n",
    "test_state = {\"some_key\": \"hello world\", \"existing_key\": \"existing_value\"}\n",
    "print(f\"输入状态: {test_state}\")\n",
    "\n",
    "result = my_node(test_state)\n",
    "print(f\"节点输出: {result}\")\n",
    "\n",
    "# 模拟状态更新（LangGraph会自动处理状态合并）\n",
    "updated_state = {**test_state, **result}\n",
    "print(f\"更新后状态: {updated_state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-3-11",
   "metadata": {},
   "source": [
    "##### 示例 3-11：一个包含 LLM 节点的 LangGraph 图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 定义状态结构体 \n",
    "class ChatState(MessagesState):\n",
    "    user_question: str  # 用户问题\n",
    "    llm_response: str   # LLM回复\n",
    "\n",
    "# 定义 LLM 节点 \n",
    "def llm_node(state):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "    model = ChatOpenAI(model=\"Qwen/Qwen3-8B\")\n",
    "    chain = prompt | model\n",
    "    \n",
    "    response = chain.invoke({\"question\": state['user_question']}).content\n",
    "    return {\"llm_response\": response}\n",
    "\n",
    "# 构建图 \n",
    "builder = StateGraph(ChatState)\n",
    "builder.add_node(\"llm_node\", llm_node)\n",
    "builder.add_edge(START, \"llm_node\")\n",
    "builder.add_edge(\"llm_node\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "print(\"LangGraph 图构建完成\")\n",
    "print(\"节点: llm_node\")\n",
    "print(\"边: START -> llm_node -> END\")\n",
    "\n",
    "# 测试图的执行\n",
    "print(\"\\n测试图执行：\")\n",
    "try:\n",
    "    result = graph.invoke({\"user_question\": \"你好，LangGraph！\"})\n",
    "    print(f\"执行结果: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"需要配置API密钥才能实际运行LLM: {e}\")\n",
    "    print(\"图结构已成功创建，可以在配置API后运行\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e7a7e5",
   "metadata": {},
   "source": [
    "##### 示例 3-12：为 LangGraph 节点配置重试策略的代码示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a1f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import sqlite3\n",
    "import random\n",
    "import time\n",
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.pregel import RetryPolicy\n",
    "\n",
    "# 模拟数据库类\n",
    "class MockSQLDatabase:\n",
    "    def __init__(self):\n",
    "        self.connection_stable = False\n",
    "        self.call_count = 0\n",
    "\n",
    "    def run(self, query):\n",
    "        self.call_count += 1\n",
    "        print(f\"🗄️ 数据库查询 (第{self.call_count}次): {query}\")\n",
    "\n",
    "        # 模拟不稳定的数据库连接 - 前2次调用会失败\n",
    "        if self.call_count <= 2:\n",
    "            print(f\"❌ 数据库连接失败 (模拟错误)\")\n",
    "            raise sqlite3.OperationalError(\"数据库连接超时\")\n",
    "\n",
    "        print(f\"✅ 数据库查询成功\")\n",
    "        return \"艺术家数据: Van Gogh, Picasso, Da Vinci, Monet, Renoir\"\n",
    "\n",
    "# 模拟 LLM 类\n",
    "class MockChatOpenAI:\n",
    "    def __init__(self, model=\"mock-model\"):\n",
    "        self.model = model\n",
    "        self.call_count = 0\n",
    "\n",
    "    def invoke(self, messages):\n",
    "        self.call_count += 1\n",
    "        print(f\"🤖 LLM调用 (第{self.call_count}次)\")\n",
    "\n",
    "        # 模拟 LLM 偶尔失败 - 30% 概率失败\n",
    "        if random.random() < 0.3:\n",
    "            print(f\"❌ LLM服务暂时不可用 (模拟错误)\")\n",
    "            raise ConnectionError(\"LLM服务连接失败\")\n",
    "\n",
    "        last_message = messages[-1] if messages else None\n",
    "        content = f\"基于查询结果，我为您找到了相关的艺术家信息。这是第{self.call_count}次成功调用的响应。\"\n",
    "        print(f\"✅ LLM响应生成成功\")\n",
    "        return AIMessage(content=content)\n",
    "\n",
    "# 初始化模拟组件\n",
    "db = MockSQLDatabase()\n",
    "model = MockChatOpenAI(model=\"Mock-GPT-4\")\n",
    "\n",
    "# 定义图的状态\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "def query_database(state):\n",
    "    \"\"\"查询数据库节点 - 配置了特定异常重试\"\"\"\n",
    "    print(f\"\\n📊 执行数据库查询节点...\")\n",
    "    query_result = db.run(\"SELECT * FROM Artist LIMIT 10;\")\n",
    "    return {\"messages\": [AIMessage(content=f\"数据库查询结果: {query_result}\")]}\n",
    "\n",
    "def call_model(state):\n",
    "    \"\"\"调用模型节点 - 配置了最大重试次数\"\"\"\n",
    "    print(f\"\\n🧠 执行模型调用节点...\")\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def user_input_node(state):\n",
    "    \"\"\"用户输入节点\"\"\"\n",
    "    print(f\"\\n👤 添加用户输入...\")\n",
    "    user_message = HumanMessage(content=\"请帮我查询一些著名艺术家的信息\")\n",
    "    print(f\"📝 用户问题: {user_message.content}\")\n",
    "    return {\"messages\": [user_message]}\n",
    "\n",
    "# 定义图 builder\n",
    "print(\"🏗️ 构建带重试策略的 LangGraph...\")\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "# 添加用户输入节点\n",
    "builder.add_node(\"user_input\", user_input_node)\n",
    "\n",
    "# 为 call_model 节点配置重试策略: 最大重试 5 次，包含退避策略\n",
    "builder.add_node(\n",
    "    \"model\",\n",
    "    call_model,\n",
    "    retry=RetryPolicy(\n",
    "        max_attempts=5,           # 最大重试5次\n",
    "        initial_interval=0.5,     # 初始重试间隔0.5秒\n",
    "        backoff_factor=2.0,       # 退避因子2.0 (指数退避)\n",
    "        max_interval=8.0,         # 最大重试间隔8秒\n",
    "        jitter=True              # 添加随机抖动\n",
    "    )\n",
    ")\n",
    "\n",
    "# 为 query_database 节点配置重试策略: 针对 sqlite3.OperationalError 异常进行重试\n",
    "builder.add_node(\n",
    "    \"query_database\",\n",
    "    query_database,\n",
    "    retry=RetryPolicy(\n",
    "        retry_on=sqlite3.OperationalError,  # 只对数据库操作错误重试\n",
    "        max_attempts=4,                     # 最大重试4次\n",
    "        initial_interval=1.0,               # 初始间隔1秒\n",
    "        backoff_factor=1.5                  # 较小的退避因子\n",
    "    )\n",
    ")\n",
    "\n",
    "# 定义边\n",
    "builder.add_edge(START, \"user_input\")\n",
    "builder.add_edge(\"user_input\", \"model\")\n",
    "builder.add_edge(\"model\", \"query_database\")\n",
    "builder.add_edge(\"query_database\", END)\n",
    "\n",
    "# 编译图\n",
    "graph = builder.compile()\n",
    "print(\"✅ 图构建完成！\")\n",
    "\n",
    "# 测试运行\n",
    "print(\"\\n=== 🚀 重试策略演示 ===\")\n",
    "print(\"📋 测试场景:\")\n",
    "print(\"  - 数据库节点: 前2次调用会失败，第3次成功\")\n",
    "print(\"  - 模型节点: 30% 概率失败，会自动重试\")\n",
    "print(\"  - 两个节点都配置了不同的重试策略\\n\")\n",
    "\n",
    "try:\n",
    "    # 运行图\n",
    "    result = graph.invoke({\"messages\": []})\n",
    "\n",
    "    print(f\"\\n=== ✨ 执行完成 ===\")\n",
    "    print(f\"📊 最终消息数量: {len(result['messages'])}\")\n",
    "    for i, msg in enumerate(result['messages']):\n",
    "        print(f\"  {i+1}. [{msg.__class__.__name__}] {msg.content[:60]}...\")\n",
    "\n",
    "    print(f\"\\n=== 📈 重试统计 ===\")\n",
    "    print(f\"🗄️ 数据库调用次数: {db.call_count}\")\n",
    "    print(f\"🤖 模型调用次数: {model.call_count}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ 执行失败: {e}\")\n",
    "    print(f\"🗄️ 数据库调用次数: {db.call_count}\")\n",
    "    print(f\"🤖 模型调用次数: {model.call_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b4744",
   "metadata": {},
   "source": [
    "1. `RetryPolicy` 配置：\n",
    "- `model` 节点：通用重试策略，处理各种异常\n",
    "- `query_database` 节点：针对特定数据库异常的重试策略\n",
    "2. 不同的重试参数：\n",
    "- 最大重试次数、初始间隔、退避因子等\n",
    "- 展示指数退避和抖动机制\n",
    "3. 模拟失败场景：\n",
    "- 数据库连接不稳定（前几次必然失败）\n",
    "- LLM 服务偶尔不可用（随机失败）\n",
    "4. 重试效果演示：\n",
    "- 显示每次重试的过程\n",
    "- 统计实际调用次数\n",
    "- 展示重试策略的实际效果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-1-3",
   "metadata": {},
   "source": [
    "### 3.1.3 边（Edge）\n",
    "\n",
    "边在 LangGraph 中负责连接不同的节点，定义智能体系统的执行流程。边决定了在执行完一个节点之后，下一步应该执行哪个节点。\n",
    "\n",
    "LangGraph 主要支持两种类型的边：\n",
    "- **普通边**：定义节点间固定的、无条件的连接关系\n",
    "- **条件边**：提供基于状态动态路由的能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-3-13",
   "metadata": {},
   "source": [
    "##### 示例 3-13：意图识别与技能路由流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# 定义状态\n",
    "class IntentState(TypedDict):\n",
    "    user_input: str\n",
    "    user_intent: str\n",
    "    response: str\n",
    "\n",
    "# 意图识别节点\n",
    "def intent_recognition_node(state):\n",
    "    user_input = state['user_input'].lower()\n",
    "    \n",
    "    # 简单的意图识别逻辑\n",
    "    if '天气' in user_input or 'weather' in user_input:\n",
    "        intent = \"查询天气\"\n",
    "    elif '机票' in user_input or 'flight' in user_input:\n",
    "        intent = \"预订机票\"\n",
    "    elif '投诉' in user_input or 'complaint' in user_input:\n",
    "        intent = \"投诉建议\"\n",
    "    else:\n",
    "        intent = \"未知\"\n",
    "    \n",
    "    return {\"user_intent\": intent}\n",
    "\n",
    "# 技能节点\n",
    "def weather_query_node(state):\n",
    "    return {\"response\": \"今天天气晴朗，温度 22-28°C\"}\n",
    "\n",
    "def flight_booking_node(state):\n",
    "    return {\"response\": \"为您查找合适的机票选项...\"}\n",
    "\n",
    "def complaint_suggestion_node(state):\n",
    "    return {\"response\": \"感谢您的反馈，我们会认真处理您的建议\"}\n",
    "\n",
    "# 条件路由函数\n",
    "def route_to_skill(state):\n",
    "    \"\"\"条件函数，根据用户意图路由到不同的技能节点\"\"\"\n",
    "    user_intent = state['user_intent']\n",
    "    if user_intent == \"查询天气\":\n",
    "        return \"weather_query_node\"  # 跳转到查询天气节点\n",
    "    elif user_intent == \"预订机票\":\n",
    "        return \"flight_booking_node\"  # 跳转到预订机票节点\n",
    "    elif user_intent == \"投诉建议\":\n",
    "        return \"complaint_suggestion_node\"  # 跳转到投诉建议处理节点\n",
    "    else:\n",
    "        return END  # 无法识别意图，结束流程\n",
    "\n",
    "# 构建图\n",
    "builder = StateGraph(IntentState)\n",
    "\n",
    "# 添加节点\n",
    "builder.add_node(\"intent_recognition_node\", intent_recognition_node)\n",
    "builder.add_node(\"weather_query_node\", weather_query_node)\n",
    "builder.add_node(\"flight_booking_node\", flight_booking_node)\n",
    "builder.add_node(\"complaint_suggestion_node\", complaint_suggestion_node)\n",
    "\n",
    "# 添加边\n",
    "builder.add_edge(START, \"intent_recognition_node\")\n",
    "builder.add_conditional_edges(\n",
    "    \"intent_recognition_node\", \n",
    "    route_to_skill,\n",
    "    [\"weather_query_node\", \"flight_booking_node\", \"complaint_suggestion_node\", END]\n",
    ")\n",
    "builder.add_edge(\"weather_query_node\", END)\n",
    "builder.add_edge(\"flight_booking_node\", END)\n",
    "builder.add_edge(\"complaint_suggestion_node\", END)\n",
    "\n",
    "# 编译图\n",
    "intent_graph = builder.compile()\n",
    "\n",
    "print(\"意图识别与技能路由图构建完成\")\n",
    "\n",
    "# 测试不同的用户输入\n",
    "test_inputs = [\n",
    "    \"今天天气怎么样？\",\n",
    "    \"我要预订明天到北京的机票\",\n",
    "    \"我要投诉你们的服务\",\n",
    "    \"你好\"\n",
    "]\n",
    "\n",
    "for user_input in test_inputs:\n",
    "    print(f\"\\n用户输入: {user_input}\")\n",
    "    result = intent_graph.invoke({\"user_input\": user_input})\n",
    "    print(f\"识别意图: {result.get('user_intent', '未识别')}\")\n",
    "    print(f\"系统回复: {result.get('response', '无回复')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-3-13",
   "metadata": {},
   "source": [
    "**💡 边的类型和应用场景**：\n",
    "\n",
    "- **条件边**：`add_conditional_edges()` 实现动态路由，根据运行时状态选择路径\n",
    "- **普通边**：`add_edge()` 创建固定连接，适用于确定的流程序列\n",
    "- **应用场景**：意图识别、工具选择、错误处理、流程分支等"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-1-4",
   "metadata": {},
   "source": [
    "### 3.1.4 命令（Command）\n",
    "\n",
    "命令（Command）是 LangGraph 新推出的强大工具，它允许我们将状态更新和流程控制逻辑整合到同一个节点中。Command 打破了节点和边功能上的传统分工，赋予了节点更强大的流程控制能力。\n",
    "\n",
    "一个 `Command` 对象主要包含以下两个部分：\n",
    "- `update`（状态更新）：指定需要更新的状态键值对\n",
    "- `goto`（流程跳转）：指定下一步要执行的节点名称"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-3-15",
   "metadata": {},
   "source": [
    "##### 示例 3-15：使用 Command 的节点函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "from typing import Literal\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# 定义状态\n",
    "class CommandState(TypedDict):\n",
    "    input_data: str\n",
    "    processed_data: str\n",
    "    decision_result: str\n",
    "\n",
    "def decide_next_node(state):\n",
    "    \"\"\"根据状态决定下一个节点\"\"\"\n",
    "    input_data = state['input_data'].lower()\n",
    "    if 'process_a' in input_data:\n",
    "        return 'node_a'\n",
    "    elif 'process_b' in input_data:\n",
    "        return 'node_b'\n",
    "    else:\n",
    "        return 'node_c'\n",
    "\n",
    "def decision_node(state) -> Command[Literal[\"node_a\", \"node_b\", \"node_c\"]]:\n",
    "    \"\"\"\n",
    "    使用 Command 的节点函数示例\n",
    "    \"\"\"\n",
    "    # 处理输入数据\n",
    "    input_data = state['input_data']\n",
    "    processed_result = f\"已处理: {input_data}\"\n",
    "    \n",
    "    # 决定下一个节点\n",
    "    next_node_name = decide_next_node(state)\n",
    "    \n",
    "    return Command(\n",
    "        update={\"processed_data\": processed_result, \"decision_result\": f\"决定跳转到: {next_node_name}\"},  # 状态更新\n",
    "        goto=next_node_name  # 流程跳转指令\n",
    "    )\n",
    "\n",
    "# 目标节点\n",
    "def node_a(state):\n",
    "    return {\"processed_data\": state['processed_data'] + \" -> 经过节点A处理\"}\n",
    "\n",
    "def node_b(state):\n",
    "    return {\"processed_data\": state['processed_data'] + \" -> 经过节点B处理\"}\n",
    "\n",
    "def node_c(state):\n",
    "    return {\"processed_data\": state['processed_data'] + \" -> 经过节点C处理\"}\n",
    "\n",
    "# 构建使用 Command 的图\n",
    "builder = StateGraph(CommandState)\n",
    "\n",
    "# 添加节点\n",
    "builder.add_node(\"decision_node\", decision_node)\n",
    "builder.add_node(\"node_a\", node_a)\n",
    "builder.add_node(\"node_b\", node_b)\n",
    "builder.add_node(\"node_c\", node_c)\n",
    "\n",
    "# 添加边\n",
    "builder.add_edge(START, \"decision_node\")\n",
    "builder.add_edge(\"node_a\", END)\n",
    "builder.add_edge(\"node_b\", END)\n",
    "builder.add_edge(\"node_c\", END)\n",
    "\n",
    "# 编译图\n",
    "command_graph = builder.compile()\n",
    "\n",
    "print(\"Command 示例图构建完成\")\n",
    "\n",
    "# 测试不同的输入\n",
    "test_inputs = [\n",
    "    \"请执行 process_a 操作\",\n",
    "    \"需要 process_b 处理\",\n",
    "    \"其他类型的操作\"\n",
    "]\n",
    "\n",
    "for input_data in test_inputs:\n",
    "    print(f\"\\n输入数据: {input_data}\")\n",
    "    result = command_graph.invoke({\"input_data\": input_data})\n",
    "    print(f\"决策结果: {result.get('decision_result', '无')}\")\n",
    "    print(f\"处理结果: {result.get('processed_data', '无')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-3-15",
   "metadata": {},
   "source": [
    "**💡 Command 的核心价值**：\n",
    "\n",
    "- **内聚性**：将状态更新和流程控制逻辑封装在同一个节点中\n",
    "- **类型安全**：通过 `Literal` 类型提示确保跳转目标的正确性\n",
    "- **可视化支持**：LangGraph 可以静态分析 Command 的类型提示生成准确的流程图\n",
    "- **灵活性**：特别适合多智能体协作中的\"交接\"场景"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4rtx30sakwu",
   "metadata": {},
   "source": [
    "## 3.2 流程控制：分支与并发\n",
    "\n",
    "在上一节中，我们了解了 LangGraph 的核心原语：状态、节点、边和命令。有了这些原语，我们就可以构建简单的线性流程。但在实际的智能体系统中，流程往往不是简单的线性执行，而是会根据不同的情况和条件，出现分支、并行、循环等复杂的控制流。\n",
    "\n",
    "本节我们将重点探讨 LangGraph 中的流程控制机制，特别是如何利用 LangGraph 实现并行分支 (Parallel Branching)，构建能够并发执行多个任务、提高系统效率的智能体系统。\n",
    "\n",
    "在最简单的 LangGraph 流程中，我们使用普通边将节点串联起来，形成一条线性的执行路径。但线性流程有其局限性：\n",
    "\n",
    "- **无法处理条件判断**：线性流程无法根据状态或外部条件，动态地选择不同的执行路径\n",
    "- **无法实现并行执行**：线性流程只能串行地执行节点，无法同时执行多个独立的任务\n",
    "- **效率较低**：对于一些可以并行处理的任务，线性流程的串行执行方式会浪费计算资源\n",
    "\n",
    "为了克服这些局限性，LangGraph 提供了强大的流程控制机制，其中分支 (Branching) 和 并发 (Concurrency) 是核心要素。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w6cgoebnpwf",
   "metadata": {},
   "source": [
    "### 3.2.1 并行分支：扇出 (Fan-out) 与扇入 (Fan-in)\n",
    "\n",
    "LangGraph 实现并行分支的核心机制是扇出 (Fan-out) 和 扇入 (Fan-in)。\n",
    "\n",
    "- **扇出 (Fan-out)**：从一个节点出发，同时触发多个下游节点，使得流程并行地向多个方向分支\n",
    "- **扇入 (Fan-in)**：将多个并行分支的流程汇聚到一个共同的下游节点，实现并行流程的同步和汇合\n",
    "\n",
    "要实现扇出，最简单的方式是为一个节点添加多个出边，将该节点同时连接到多个下游节点。当 LangGraph 执行到该节点时，会同时、并发地触发所有出边指向的下游节点。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3jfe3zy3a42",
   "metadata": {},
   "source": [
    "##### 示例 3-16：扇出和扇入的完整并行分支流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x5qfd76xu6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Any\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# 定义状态，使用 operator.add Reducer 处理并行分支的状态更新\n",
    "class ParallelState(TypedDict):\n",
    "    aggregate: Annotated[list, operator.add]\n",
    "\n",
    "def node_a(state: ParallelState):\n",
    "    print(f'Adding \"A\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"A\"]}\n",
    "\n",
    "def node_b(state: ParallelState):\n",
    "    print(f'Adding \"B\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"B\"]}\n",
    "\n",
    "def node_c(state: ParallelState):\n",
    "    print(f'Adding \"C\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"C\"]}\n",
    "\n",
    "def node_d(state: ParallelState):\n",
    "    print(f'Adding \"D\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"D\"]}\n",
    "\n",
    "# 构建并行分支图\n",
    "builder = StateGraph(ParallelState)\n",
    "\n",
    "# 添加节点\n",
    "builder.add_node(\"node_a\", node_a)\n",
    "builder.add_node(\"node_b\", node_b)\n",
    "builder.add_node(\"node_c\", node_c)\n",
    "builder.add_node(\"node_d\", node_d)\n",
    "\n",
    "# 添加边：实现扇出和扇入\n",
    "builder.add_edge(START, \"node_a\")  # 从 START 到 node_a\n",
    "builder.add_edge(\"node_a\", \"node_b\")  # node_a 扇出到 node_b\n",
    "builder.add_edge(\"node_a\", \"node_c\")  # node_a 扇出到 node_c (实现扇出)\n",
    "builder.add_edge(\"node_b\", \"node_d\")  # node_b 扇入到 node_d\n",
    "builder.add_edge(\"node_c\", \"node_d\")  # node_c 扇入到 node_d (实现扇入)\n",
    "builder.add_edge(\"node_d\", END)  # node_d 到 END\n",
    "\n",
    "# 编译图\n",
    "parallel_graph = builder.compile()\n",
    "\n",
    "print(\"并行分支图构建完成\")\n",
    "print(\"流程: START -> node_a -> (node_b, node_c 并行) -> node_d -> END\")\n",
    "\n",
    "# 执行并行分支流程\n",
    "print(\"\\n执行并行分支流程:\")\n",
    "result = parallel_graph.invoke({\"aggregate\": []})\n",
    "print(f\"\\n最终结果: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kbidijuub19",
   "metadata": {},
   "source": [
    "**💡 并行分支核心概念解析**：\n",
    "\n",
    "- **扇出效果**：节点 A 执行完后，同时触发节点 B 和 C，两个节点并发执行\n",
    "- **扇入同步**：节点 D 必须等待节点 B 和 C 都执行完成后才开始执行，起到同步点作用\n",
    "- **状态 Reducer**：使用 `operator.add` Reducer 确保并行分支的状态更新能正确合并\n",
    "- **执行效率**：并行执行比串行执行节省时间，如果 B 需要 3 秒，C 需要 5 秒，并行执行总共只需 5 秒\n",
    "\n",
    "可以看到执行结果中，节点 B 和 C 是并发执行的，然后节点 D 汇聚了两个分支的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ew455k5fbao",
   "metadata": {},
   "source": [
    "### 3.2.2 并发 (Concurrency) 而非并行 (Parallelism)\n",
    "\n",
    "需要明确的是，LangGraph 实现的并非真正的并行 (Parallelism)，而是并发 (Concurrency)。理解这个区别对于正确使用 LangGraph 非常重要：\n",
    "\n",
    "#### 并发 vs 并行的本质区别\n",
    "\n",
    "- **并行 (Parallelism)**：同时执行多个独立的任务，需要多个物理计算资源（多核 CPU、多台机器）真正地同时运行不同的代码\n",
    "- **并发 (Concurrency)**：在单计算资源上，\"看似同时\"执行多个任务，通过时间片轮转或异步 IO，CPU 在多个任务之间快速切换\n",
    "\n",
    "#### LangGraph 的 Superstep 执行模型\n",
    "\n",
    "LangGraph 借鉴了 Apache Pregel 分布式图计算框架的 Superstep (超步) 概念：\n",
    "\n",
    "- **Superstep**：图执行的基本迭代单元，代表 LangGraph 图执行过程中的一个\"步骤\"\n",
    "- **并发执行**：在每个 Superstep 中，LangGraph 会尽可能地并发执行所有\"就绪\"的节点\n",
    "- **同步屏障**：当 Superstep 内的所有节点都执行完成后，进行全局同步，应用状态更新，进入下一个 Superstep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cre0fjl04um",
   "metadata": {},
   "source": [
    "##### 示例 3-17 & 3-18：Superstep 执行模式演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495pf8a7d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import operator\n",
    "\n",
    "class SuperstepState(TypedDict):\n",
    "    superstep_log: Annotated[list, operator.add]\n",
    "    timestamp: str\n",
    "\n",
    "def superstep_node_a(state: SuperstepState):\n",
    "    print(f\"Superstep 1: 执行节点 A\")\n",
    "    time.sleep(0.1)  # 模拟处理时间\n",
    "    return {\"superstep_log\": [\"Superstep 1: Node A executed\"]}\n",
    "\n",
    "def superstep_node_b(state: SuperstepState):\n",
    "    print(f\"Superstep 2: 执行节点 B (并发)\")\n",
    "    time.sleep(0.2)  # 模拟处理时间\n",
    "    return {\"superstep_log\": [\"Superstep 2: Node B executed\"]}\n",
    "\n",
    "def superstep_node_c(state: SuperstepState):\n",
    "    print(f\"Superstep 2: 执行节点 C (并发)\")\n",
    "    time.sleep(0.15)  # 模拟处理时间\n",
    "    return {\"superstep_log\": [\"Superstep 2: Node C executed\"]}\n",
    "\n",
    "def superstep_node_d(state: SuperstepState):\n",
    "    print(f\"Superstep 3: 执行节点 D (同步后)\")\n",
    "    time.sleep(0.1)  # 模拟处理时间\n",
    "    return {\"superstep_log\": [\"Superstep 3: Node D executed\"]}\n",
    "\n",
    "# 构建 Superstep 演示图\n",
    "builder = StateGraph(SuperstepState)\n",
    "\n",
    "# 添加节点\n",
    "builder.add_node(\"superstep_a\", superstep_node_a)\n",
    "builder.add_node(\"superstep_b\", superstep_node_b) \n",
    "builder.add_node(\"superstep_c\", superstep_node_c)\n",
    "builder.add_node(\"superstep_d\", superstep_node_d)\n",
    "\n",
    "# 添加边：演示 Superstep 执行\n",
    "builder.add_edge(START, \"superstep_a\")          # Superstep 1: A 执行\n",
    "builder.add_edge(\"superstep_a\", \"superstep_b\")  # Superstep 2: A -> B (并发)\n",
    "builder.add_edge(\"superstep_a\", \"superstep_c\")  # Superstep 2: A -> C (并发) \n",
    "builder.add_edge(\"superstep_b\", \"superstep_d\")  # Superstep 3: B -> D (同步)\n",
    "builder.add_edge(\"superstep_c\", \"superstep_d\")  # Superstep 3: C -> D (同步)\n",
    "builder.add_edge(\"superstep_d\", END)\n",
    "\n",
    "superstep_graph = builder.compile()\n",
    "\n",
    "print(\"Superstep 执行模式演示:\")\n",
    "print(\"Superstep 1: 执行 A\")\n",
    "print(\"Superstep 2: 并发执行 B 和 C (等待同步)\")  \n",
    "print(\"Superstep 3: 同步后执行 D\")\n",
    "print()\n",
    "\n",
    "# 执行并记录时间\n",
    "start_time = time.time()\n",
    "result = superstep_graph.invoke({\"superstep_log\": []})\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"\\\\n执行完成，总时间: {end_time - start_time:.3f} 秒\")\n",
    "print(\"执行日志:\")\n",
    "for log in result[\"superstep_log\"]:\n",
    "    print(f\"  - {log}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7jzjr48b5r7",
   "metadata": {},
   "source": [
    "**💡 Superstep 核心特性**：\n",
    "\n",
    "- **并发性**：同一个 Superstep 内的多个节点可以并发执行，提高执行效率\n",
    "- **同步性**：每个 Superstep 结束时有全局同步点，保证状态更新的原子性和一致性  \n",
    "- **迭代性**：图执行是 Superstep 的迭代过程，每个 Superstep 在前一个基础上计算\n",
    "\n",
    "从上面的例子可以看到：\n",
    "- Superstep 1: 只有节点 A 执行\n",
    "- Superstep 2: 节点 B 和 C 并发执行（等待较慢的任务完成）\n",
    "- Superstep 3: 同步后节点 D 执行\n",
    "\n",
    "总执行时间约等于每个 Superstep 中最慢节点的时间之和，而非所有节点时间的总和。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j51m8zyo5u",
   "metadata": {},
   "source": [
    "### 3.2.3 递归限制与并行分支\n",
    "\n",
    "递归限制（Recursion Limit）用于限制 LangGraph 图执行过程中的最大 Superstep 迭代次数，防止图无限循环执行。\n",
    "\n",
    "#### 重要特性\n",
    "\n",
    "- **计数单位**：递归限制的计数单位是 Superstep，而不是节点\n",
    "- **并行不影响计数**：无论一个 Superstep 内部并发执行了多少个节点，都只计为一次 Superstep 迭代\n",
    "- **防止无限循环**：有效防止图陷入无限循环，保护计算资源"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3030f305",
   "metadata": {},
   "source": [
    "##### 示例 3-19：递归限制是对并行分支流程的限制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f2c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Any\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.errors import GraphRecursionError  # 导入 GraphRecursionError\n",
    "\n",
    "class State(TypedDict):\n",
    "    # operator.add 是状态归约器，确保状态键 aggregate 为 append-only 列表\n",
    "    aggregate: Annotated[list, operator.add]\n",
    "\n",
    "def node_a(state):\n",
    "    print(\"🔄 执行节点 A\")\n",
    "    return {\"aggregate\": [\"I'm A\"]}\n",
    "\n",
    "def node_b(state):\n",
    "    print(\"🔄 执行节点 B\")\n",
    "    return {\"aggregate\": [\"I'm B\"]}\n",
    "\n",
    "def node_c(state):\n",
    "    print(\"🔄 执行节点 C\")\n",
    "    return {\"aggregate\": [\"I'm C\"]}\n",
    "\n",
    "def node_d(state):\n",
    "    print(\"🔄 执行节点 D\")\n",
    "    return {\"aggregate\": [\"I'm D\"]}\n",
    "\n",
    "# 构建图\n",
    "print(\"🏗️ 构建并行分支图...\")\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"a\", node_a)\n",
    "builder.add_node(\"b\", node_b)\n",
    "builder.add_node(\"c\", node_c)\n",
    "builder.add_node(\"d\", node_d)\n",
    "\n",
    "# 添加边 - 创建并行分支结构\n",
    "builder.add_edge(START, \"a\")\n",
    "builder.add_edge(\"a\", \"b\")\n",
    "builder.add_edge(\"a\", \"c\")  # 从 a 扇出到 b 和 c\n",
    "builder.add_edge(\"b\", \"d\")\n",
    "builder.add_edge(\"c\", \"d\")  # b 和 c 扇入到 d\n",
    "builder.add_edge(\"d\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "print(\"✅ 图构建完成！\")\n",
    "\n",
    "print(\"\\n=== 递归限制和并行分支流程的限制 ===\\n\")\n",
    "\n",
    "# 测试 1: 正常执行（在递归限制内）\n",
    "print(\"📊 测试 1: 正常执行 (recursion_limit=10)\")\n",
    "try:\n",
    "    result = graph.invoke({\"aggregate\": []}, {\"recursion_limit\": 10})\n",
    "    print(f\"✅ 执行成功，最终结果: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 执行失败: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# 测试 2: 设置较低的递归限制来触发 GraphRecursionError\n",
    "print(\"📊 测试 2: 递归限制过低 (recursion_limit=3)\")\n",
    "try:\n",
    "    # 设置 recursion_limit=3，少于完整流程所需的 Superstep 数量\n",
    "    result = graph.invoke({\"aggregate\": []}, {\"recursion_limit\": 3})\n",
    "    print(f\"✅ 执行成功，结果: {result}\")\n",
    "except GraphRecursionError as e:\n",
    "    print(f\"⚠️ 捕获 GraphRecursionError 异常: {e}\")\n",
    "    print(\"📝 说明: 递归限制过低，无法完成完整的并行分支流程\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82544806",
   "metadata": {},
   "source": [
    "在设计包含并行分支的 LangGraph 流程时，需要根据流程的复杂度合理地设置 `recursion_limit` 参数。\n",
    "\n",
    "- 如果设置得过低，则可能导致流程在并行分支执行完成前就因为达到限制而中止，抛出 `GraphRecursionError` 异常。\n",
    "- 如果设置得过高，则可能无法有效防止流程陷入无限循环，造成不必要的计算资源消耗。\n",
    "- 建议通过实验和调优，根据流程的实际迭代次数和复杂度选择一个合适的 `recursion_limit` 值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "br5s06thhnv",
   "metadata": {},
   "source": [
    "## 3.3 MapReduce 模式：任务分解与并行处理\n",
    "\n",
    "在构建复杂智能体系统时，经常会遇到需要处理大规模数据或执行计算密集型任务的场景。例如：\n",
    "- 批量处理海量文档进行信息提取\n",
    "- 并行生成多个创意文案\n",
    "- 分布式分析用户行为数据\n",
    "\n",
    "MapReduce (映射-归约) 模式为我们提供了一种高效、可扩展地处理这类问题的通用解决方案。\n",
    "\n",
    "### 3.3.1 MapReduce 模式的核心思想\n",
    "\n",
    "MapReduce 模式的核心思想可以用两个词概括：\"分而治之\"。它将一个复杂、大规模的计算任务分解成两个相互协作的阶段：\n",
    "\n",
    "#### Map 阶段 (映射)\n",
    "- **\"分\"的过程**：将原始的、大规模的输入数据分割成多个独立的、规模较小的子数据集\n",
    "- **并行处理**：每个子数据集分配给不同的计算节点并行处理\n",
    "- **独立执行**：每个计算节点独立地对分配的子数据集执行相同的\"映射\"操作\n",
    "\n",
    "#### Reduce 阶段 (归约) \n",
    "- **\"治\"的过程**：将 Map 阶段并行生成的多个中间结果进行\"归约\"操作\n",
    "- **聚合汇总**：将分散的、局部的中间结果合并成最终的、全局的结果\n",
    "- **整合提炼**：将 Map 阶段的\"半成品\"组装成\"成品\"\n",
    "\n",
    "#### MapReduce 的核心优势\n",
    "\n",
    "- **并行处理**：充分利用并行计算资源，显著提高数据处理效率\n",
    "- **高扩展性**：易于扩展，可以通过增加计算节点来处理更大规模的数据\n",
    "- **简化编程模型**：隐藏了底层并行计算的复杂性，开发者只需关注业务逻辑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6752btnaevh",
   "metadata": {},
   "source": [
    "##### 示例 3-20 ~ 3-25：LangGraph 中的 MapReduce 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oofs1kxehq",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Any\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.constants import Send\n",
    "import operator\n",
    "import re\n",
    "\n",
    "# 定义整体状态结构体\n",
    "class OverallState(TypedDict):\n",
    "    # 原始大规模输入数据\n",
    "    large_input_data: List[str]\n",
    "    # 分割后的子数据集\n",
    "    sub_datasets: List[List[str]]\n",
    "    # Map 阶段的处理结果 (使用 operator.add Reducer 收集结果)\n",
    "    intermediate_results: Annotated[List[dict], operator.add]\n",
    "    # Reduce 阶段的最终结果\n",
    "    final_result: dict\n",
    "\n",
    "# 定义 Map 节点的私有状态结构体\n",
    "class MapState(TypedDict):\n",
    "    sub_data: Any  # 子任务数据类型可以是任意类型\n",
    "\n",
    "def split_large_data(input_data: List[str], num_sub_tasks: int = 10) -> List[List[str]]:\n",
    "    \"\"\"将大规模数据分割成子数据集\"\"\"\n",
    "    chunk_size = max(1, len(input_data) // num_sub_tasks)\n",
    "    chunks = []\n",
    "    for i in range(0, len(input_data), chunk_size):\n",
    "        chunks.append(input_data[i:i + chunk_size])\n",
    "    return chunks\n",
    "\n",
    "def split_input_data(state: OverallState):\n",
    "    \"\"\"分割节点函数：只负责数据分割，不返回 Send 对象\"\"\"\n",
    "    input_data = state[\"large_input_data\"]  # 从状态中获取大规模输入数据\n",
    "    sub_datasets = split_large_data(input_data, num_sub_tasks=4)  # 将大规模数据分割成子数据集\n",
    "\n",
    "    print(f\"🔄 分割节点: 将 {len(input_data)} 个文档分割成 {len(sub_datasets)} 个子数据集\")\n",
    "    for i, sub_dataset in enumerate(sub_datasets):\n",
    "        print(f\"📦 子数据集 {i}: {len(sub_dataset)} 个文档\")\n",
    "\n",
    "    return {\"sub_datasets\": sub_datasets}\n",
    "\n",
    "def route_to_map_nodes(state: OverallState):\n",
    "    \"\"\"路由函数：根据分割的数据创建 Send 对象\"\"\"\n",
    "    sub_datasets = state[\"sub_datasets\"]\n",
    "\n",
    "    print(f\"🔀 路由函数: 创建 {len(sub_datasets)} 个并行任务\")\n",
    "\n",
    "    send_list = []\n",
    "    for i, sub_dataset in enumerate(sub_datasets):  # 遍历每个子数据集\n",
    "        send_list.append(\n",
    "            Send(\"map_node\", {\"sub_data\": sub_dataset})  # 为每个子数据集创建一个 Send 对象\n",
    "        )\n",
    "\n",
    "    print(f\"✅ 路由完成: 创建了 {len(send_list)} 个 Send 对象\")\n",
    "    return send_list  # 返回 Send 对象列表，用于动态路由到多个 Map 节点实例\n",
    "\n",
    "def process_sub_data(sub_data: List[str]) -> dict:\n",
    "    \"\"\"处理子任务数据，生成中间结果\"\"\"\n",
    "    word_count = {}\n",
    "    total_chars = 0\n",
    "\n",
    "    for doc in sub_data:\n",
    "        # 统计词频\n",
    "        words = re.findall(r'\\b\\w+\\b', doc.lower())\n",
    "        for word in words:\n",
    "            word_count[word] = word_count.get(word, 0) + 1\n",
    "        # 统计字符数\n",
    "        total_chars += len(doc)\n",
    "\n",
    "    return {\n",
    "        \"word_count\": word_count,\n",
    "        \"doc_count\": len(sub_data),\n",
    "        \"total_chars\": total_chars,\n",
    "        \"unique_words\": len(word_count)\n",
    "    }\n",
    "\n",
    "def map_node(state: MapState):\n",
    "    \"\"\"Map 节点函数，输入状态为 MapState\"\"\"\n",
    "    sub_data = state[\"sub_data\"]  # 从状态中获取子任务数据\n",
    "    print(f\"🔧 Map 节点: 开始处理 {len(sub_data)} 个文档\")\n",
    "\n",
    "    intermediate_result = process_sub_data(sub_data)  # 处理子任务数据，生成中间结果\n",
    "\n",
    "    print(f\"✅ Map 节点: 处理完成，找到 {intermediate_result['unique_words']}个不同单词\")\n",
    "\n",
    "    return {\"intermediate_results\": [intermediate_result]}  # 返回中间结果，用于后续 Reduce 阶段聚合\n",
    "\n",
    "def aggregate_results(intermediate_results: List[dict]) -> dict:\n",
    "    \"\"\"聚合中间结果，生成最终结果\"\"\"\n",
    "    global_word_count = {}\n",
    "    total_docs = 0\n",
    "    total_chars = 0\n",
    "\n",
    "    for result in intermediate_results:\n",
    "        total_docs += result[\"doc_count\"]\n",
    "        total_chars += result[\"total_chars\"]\n",
    "\n",
    "        # 合并词频统计\n",
    "        for word, count in result[\"word_count\"].items():\n",
    "            global_word_count[word] = global_word_count.get(word, 0) + count\n",
    "\n",
    "    # 找出最高频和最低频的词\n",
    "    if global_word_count:\n",
    "        sorted_words = sorted(global_word_count.items(), key=lambda x: x[1],\n",
    "reverse=True)\n",
    "        most_common = sorted_words[0]\n",
    "        least_common = sorted_words[-1]\n",
    "    else:\n",
    "        most_common = (\"\", 0)\n",
    "        least_common = (\"\", 0)\n",
    "\n",
    "    return {\n",
    "        \"total_documents\": total_docs,\n",
    "        \"total_characters\": total_chars,\n",
    "        \"total_unique_words\": len(global_word_count),\n",
    "        \"total_words\": sum(global_word_count.values()),\n",
    "        \"most_common_word\": most_common,\n",
    "        \"least_common_word\": least_common,\n",
    "        \"word_distribution\": dict(sorted_words[:10])  # 只保留前10个高频词\n",
    "    }\n",
    "\n",
    "def reduce_node(state: OverallState):\n",
    "    \"\"\"Reduce 节点函数，输入状态为 OverallState\"\"\"\n",
    "    intermediate_results = state[\"intermediate_results\"]  # 从状态中获取 Map 阶段生成的中间结果列表\n",
    "\n",
    "    print(f\"🔄 Reduce 节点: 汇聚 {len(intermediate_results)} 个中间结果\")\n",
    "\n",
    "    final_result = aggregate_results(intermediate_results)  # 聚合中间结果，生成最终结果\n",
    "\n",
    "    print(f\"✅ Reduce 完成: 汇总了 {final_result['total_documents']} 个文档\")\n",
    "\n",
    "    return {\"final_result\": final_result}  # 返回最终结果\n",
    "\n",
    "# 构建 MapReduce 图\n",
    "print(\"🏗️ 构建标准 MapReduce 图...\")\n",
    "builder = StateGraph(OverallState)\n",
    "\n",
    "# 添加节点\n",
    "builder.add_node(\"split_node\", split_input_data)\n",
    "builder.add_node(\"map_node\", map_node)\n",
    "builder.add_node(\"reduce_node\", reduce_node)\n",
    "\n",
    "# 连接 MapReduce 流程中的节点和边\n",
    "builder.add_edge(START, \"split_node\")\n",
    "\n",
    "# 关键修正：分离数据分割和任务路由\n",
    "# 分割节点 -> Map 节点 (条件边, 使用专门的路由函数)\n",
    "builder.add_conditional_edges(\"split_node\", route_to_map_nodes, [\"map_node\"])\n",
    "\n",
    "# Map 节点 -> Reduce 节点 (普通边)\n",
    "builder.add_edge(\"map_node\", \"reduce_node\")\n",
    "\n",
    "# Reduce 节点 -> END (普通边)\n",
    "builder.add_edge(\"reduce_node\", END)\n",
    "\n",
    "mapreduce_graph = builder.compile()\n",
    "print(\"✅ 图构建完成！\")\n",
    "\n",
    "# 测试数据：模拟大规模文档数据\n",
    "large_documents = [\n",
    "    \"LangGraph is a powerful framework for building AI agent systems with complex workflows.\",\n",
    "    \"The framework provides comprehensive state management and advanced flow control capabilities.\",\n",
    "    \"Parallel processing in LangGraph enables efficient task execution and resource utilization.\",\n",
    "    \"MapReduce pattern helps process large datasets effectively using distributed computing principles.\",\n",
    "    \"AI agents can use various tools and manage complex workflows with sophisticated coordination.\",\n",
    "    \"State management is crucial for building reliable and scalable distributed systems.\",\n",
    "    \"LangGraph supports dynamic branching with Send API for flexible workflowdesign.\",\n",
    "    \"Concurrent execution improves overall system performance and throughput significantly.\",\n",
    "    \"The Send API enables dynamic task distribution and parallel processing capabilities.\",\n",
    "    \"Reducer functions ensure safe concurrent state updates in multi-threadedenvironments.\",\n",
    "    \"Graph-based workflows provide clear visualization and better debugging capabilities.\",\n",
    "    \"Advanced error handling and retry mechanisms ensure robust system operation.\"\n",
    "]\n",
    "\n",
    "print(\"\\n=== 🚀 MapReduce 大规模文档处理演示 ===\")\n",
    "print(f\"📄 输入文档数量: {len(large_documents)}\")\n",
    "print(f\"📊 使用 Send API 实现动态任务分发\")\n",
    "print(f\"🔄 MapReduce 流程: 分割 -> 并行映射 -> 归约\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# 执行 MapReduce 流程\n",
    "result = mapreduce_graph.invoke({\n",
    "    \"large_input_data\": large_documents,\n",
    "    \"sub_datasets\": [],\n",
    "    \"intermediate_results\": [],\n",
    "    \"final_result\": {}\n",
    "})\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\\n=== ✨ MapReduce 处理结果 ===\")\n",
    "final_result = result[\"final_result\"]\n",
    "print(f\"📊 总文档数: {final_result['total_documents']}\")\n",
    "print(f\"📝 总字符数: {final_result['total_characters']}\")\n",
    "print(f\"🔤 不同单词数: {final_result['total_unique_words']}\")\n",
    "print(f\"🔢 总单词数: {final_result['total_words']}\")\n",
    "print(f\"🏆 最高频词: '{final_result['most_common_word'][0]}' ({final_result['most_common_word'][1]} 次)\")\n",
    "print(f\"🥉 最低频词: '{final_result['least_common_word'][0]}' ({final_result['least_common_word'][1]} 次)\")\n",
    "\n",
    "print(f\"\\n📈 高频词汇 TOP 10:\")\n",
    "for word, count in final_result['word_distribution'].items():\n",
    "    print(f\"  📌 {word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lust6ioew1o",
   "metadata": {},
   "source": [
    "**💡 MapReduce 实现核心要点**：\n",
    "\n",
    "#### 流程设计\n",
    "1. **分割阶段 (Split)**：将输入文档按块大小分割，为并行处理做准备\n",
    "2. **映射阶段 (Map)**：多个 Map 节点并发处理不同的数据块，执行词频统计\n",
    "3. **归约阶段 (Reduce)**：汇聚所有 Map 结果，生成全局统计\n",
    "\n",
    "#### 实际应用场景\n",
    "- **文档分析**：批量处理大量文档进行内容分析\n",
    "- **数据挖掘**：从海量数据中提取统计信息\n",
    "- **并行计算**：任何可以分割处理的计算密集型任务\n",
    "\n",
    "这个例子展示了如何将传统的 MapReduce 思想与 LangGraph 的图计算模型相结合，构建高效的并行数据处理流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i1p8k8um7mi",
   "metadata": {},
   "source": [
    "## 3.4 子图机制：模块化、复用与复杂性管理\n",
    "\n",
    "在构建日益复杂的 AI 智能体系统时，模块化 (Modularity) 和复用 (Reuse) 变得至关重要。LangGraph 框架通过子图 (Subgraph) 机制，为我们提供了强大的模块化和复用能力，使得我们可以像搭积木一样构建复杂的智能体系统。\n",
    "\n",
    "### 3.4.1 子图 (Subgraph) 的概念与优势\n",
    "\n",
    "子图 (Subgraph) 在 LangGraph 中，指的是一个\"嵌套\"在另一个 LangGraph 图 (父图，Parent Graph) 内部的图结构。子图本质上仍然是一个 LangGraph 图，但它被\"封装\"在父图内部，作为父图的一个组成部分。\n",
    "\n",
    "#### 子图的核心优势：\n",
    "\n",
    "- **模块化**：将复杂系统分解成多个独立的、职责单一的子图模块\n",
    "- **复用性**：子图作为独立模块，可以在不同的父图中重复使用  \n",
    "- **状态隔离**：子图拥有独立的状态结构体和状态空间，与父图状态相互隔离\n",
    "- **命名空间管理**：避免不同子图或父图中节点名称的冲突\n",
    "- **简化复杂性**：通过层层嵌套和模块化组合，有效控制系统复杂性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nkn4cj8ozc",
   "metadata": {},
   "source": [
    "### 3.4.2 LangGraph 中定义和使用子图\n",
    "\n",
    "在 LangGraph 中，定义和使用子图主要有两种方式：\n",
    "\n",
    "#### 方式 1：将已编译的子图作为节点添加到父图\n",
    "\n",
    "这是最简单、最直接的子图使用方式。如果父图和子图之间需要共享状态键（例如，共享 `messages` 对话历史状态键），可以直接将已编译的子图作为特殊节点添加到父图中。\n",
    "\n",
    "#### 方式 2：使用节点函数调用子图，并进行状态转换\n",
    "\n",
    "对于更复杂的系统，父图和子图的状态结构体可能完全不同。这时需要创建节点函数，在函数内部调用子图，并进行状态转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bmmrjjz7yyc",
   "metadata": {},
   "source": [
    "##### 示例 3-26：子图模块化设计示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qfuf04x3rmc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# ===== 定义子图 1：数据处理子图 =====\n",
    "class DataProcessingState(TypedDict):\n",
    "    input_data: str\n",
    "    processed_data: str\n",
    "    processing_steps: list\n",
    "\n",
    "def validate_data(state: DataProcessingState):\n",
    "    \"\"\"数据验证节点\"\"\"\n",
    "    input_data = state[\"input_data\"]\n",
    "    is_valid = len(input_data.strip()) > 0\n",
    "    return {\n",
    "        \"processing_steps\": [f\"Validation: {'Passed' if is_valid else 'Failed'}\"],\n",
    "        \"processed_data\": input_data if is_valid else \"\"\n",
    "    }\n",
    "\n",
    "def clean_data(state: DataProcessingState):\n",
    "    \"\"\"数据清洗节点\"\"\"\n",
    "    data = state[\"processed_data\"]\n",
    "    cleaned_data = data.strip().lower().replace(\",\", \"\")\n",
    "    return {\n",
    "        \"processing_steps\": [f\"Cleaning: Removed whitespace and special chars\"],\n",
    "        \"processed_data\": cleaned_data\n",
    "    }\n",
    "\n",
    "def transform_data(state: DataProcessingState):\n",
    "    \"\"\"数据转换节点\"\"\"\n",
    "    data = state[\"processed_data\"]\n",
    "    transformed_data = f\"PROCESSED: {data.upper()}\"\n",
    "    return {\n",
    "        \"processing_steps\": [f\"Transform: Converted to uppercase with prefix\"],\n",
    "        \"processed_data\": transformed_data\n",
    "    }\n",
    "\n",
    "# 构建数据处理子图\n",
    "data_processing_builder = StateGraph(DataProcessingState)\n",
    "data_processing_builder.add_node(\"validate\", validate_data)\n",
    "data_processing_builder.add_node(\"clean\", clean_data)  \n",
    "data_processing_builder.add_node(\"transform\", transform_data)\n",
    "\n",
    "data_processing_builder.add_edge(START, \"validate\")\n",
    "data_processing_builder.add_edge(\"validate\", \"clean\")\n",
    "data_processing_builder.add_edge(\"clean\", \"transform\")\n",
    "data_processing_builder.add_edge(\"transform\", END)\n",
    "\n",
    "# 编译数据处理子图\n",
    "data_processing_subgraph = data_processing_builder.compile()\n",
    "\n",
    "print(\"数据处理子图构建完成\")\n",
    "print(\"流程: START -> validate -> clean -> transform -> END\")\n",
    "\n",
    "# ===== 定义子图 2：报告生成子图 =====\n",
    "class ReportState(TypedDict):\n",
    "    processed_data: str\n",
    "    report_title: str\n",
    "    final_report: str\n",
    "\n",
    "def generate_title(state: ReportState):\n",
    "    \"\"\"生成报告标题\"\"\"\n",
    "    processed_data = state[\"processed_data\"]\n",
    "    title = f\"Data Analysis Report: {processed_data[:20]}...\"\n",
    "    return {\"report_title\": title}\n",
    "\n",
    "def create_report(state: ReportState):\n",
    "    \"\"\"创建完整报告\"\"\"\n",
    "    title = state[\"report_title\"]  \n",
    "    data = state[\"processed_data\"]\n",
    "    report = f\"\"\"{title}\n",
    "    \n",
    "Data Content: {data}\n",
    "Report Generated: Successfully processed data\n",
    "Status: Complete\n",
    "\"\"\"\n",
    "    return {\"final_report\": report}\n",
    "\n",
    "# 构建报告生成子图  \n",
    "report_builder = StateGraph(ReportState)\n",
    "report_builder.add_node(\"generate_title\", generate_title)\n",
    "report_builder.add_node(\"create_report\", create_report)\n",
    "\n",
    "report_builder.add_edge(START, \"generate_title\")\n",
    "report_builder.add_edge(\"generate_title\", \"create_report\") \n",
    "report_builder.add_edge(\"create_report\", END)\n",
    "\n",
    "# 编译报告生成子图\n",
    "report_subgraph = report_builder.compile()\n",
    "\n",
    "print(\"报告生成子图构建完成\")\n",
    "print(\"流程: START -> generate_title -> create_report -> END\")\n",
    "\n",
    "# ===== 定义父图：整合两个子图 =====\n",
    "class MainWorkflowState(TypedDict):\n",
    "    raw_input: str\n",
    "    workflow_status: str\n",
    "    final_output: str\n",
    "\n",
    "def call_data_processing(state: MainWorkflowState):\n",
    "    \"\"\"调用数据处理子图的节点函数\"\"\"\n",
    "    # 状态转换：父图状态 -> 子图状态\n",
    "    subgraph_input = {\n",
    "        \"input_data\": state[\"raw_input\"],\n",
    "        \"processed_data\": \"\",\n",
    "        \"processing_steps\": []\n",
    "    }\n",
    "    \n",
    "    # 调用数据处理子图\n",
    "    subgraph_output = data_processing_subgraph.invoke(subgraph_input)\n",
    "    \n",
    "    # 状态转换：子图状态 -> 父图状态  \n",
    "    return {\n",
    "        \"workflow_status\": \"Data processing completed\",\n",
    "        \"final_output\": subgraph_output[\"processed_data\"]\n",
    "    }\n",
    "\n",
    "def call_report_generation(state: MainWorkflowState):\n",
    "    \"\"\"调用报告生成子图的节点函数\"\"\"\n",
    "    # 状态转换：父图状态 -> 子图状态\n",
    "    subgraph_input = {\n",
    "        \"processed_data\": state[\"final_output\"],\n",
    "        \"report_title\": \"\",\n",
    "        \"final_report\": \"\"\n",
    "    }\n",
    "    \n",
    "    # 调用报告生成子图\n",
    "    subgraph_output = report_subgraph.invoke(subgraph_input)\n",
    "    \n",
    "    # 状态转换：子图状态 -> 父图状态\n",
    "    return {\n",
    "        \"workflow_status\": \"Report generation completed\", \n",
    "        \"final_output\": subgraph_output[\"final_report\"]\n",
    "    }\n",
    "\n",
    "# 构建主工作流父图\n",
    "main_builder = StateGraph(MainWorkflowState)\n",
    "main_builder.add_node(\"data_processing\", call_data_processing)\n",
    "main_builder.add_node(\"report_generation\", call_report_generation)\n",
    "\n",
    "main_builder.add_edge(START, \"data_processing\")\n",
    "main_builder.add_edge(\"data_processing\", \"report_generation\")  \n",
    "main_builder.add_edge(\"report_generation\", END)\n",
    "\n",
    "# 编译主工作流\n",
    "main_workflow = main_builder.compile()\n",
    "\n",
    "print(\"主工作流构建完成\")\n",
    "print(\"流程: START -> data_processing(子图1) -> report_generation(子图2) -> END\")\n",
    "\n",
    "# ===== 测试子图模块化系统 =====\n",
    "print(\"\\n=== 测试子图模块化系统 ===\")\n",
    "test_input = \"Hello, World! This is sample data for processing.\"\n",
    "\n",
    "result = main_workflow.invoke({\n",
    "    \"raw_input\": test_input,\n",
    "    \"workflow_status\": \"\",\n",
    "    \"final_output\": \"\"\n",
    "})\n",
    "\n",
    "print(f\"\\n输入数据: {test_input}\")\n",
    "print(f\"工作流状态: {result['workflow_status']}\")\n",
    "print(\"\\n最终报告:\")\n",
    "print(result[\"final_output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80edb534",
   "metadata": {},
   "source": [
    "##### 示例 3-27：使用节点函数调用子图并进行状态转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925efec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# 模拟子图 child_graph 的定义和编译（这里用简化版本）\n",
    "class ChildState(TypedDict):\n",
    "    my_child_key: str\n",
    "\n",
    "def child_node_1(state: ChildState):\n",
    "    print(f\"🔧 子图节点1: 处理输入 '{state['my_child_key']}'\")\n",
    "    return {\"my_child_key\": f\"子图处理: {state['my_child_key']}\"}\n",
    "\n",
    "def child_node_2(state: ChildState):\n",
    "    print(f\"🔧 子图节点2: 进一步处理 '{state['my_child_key']}'\")\n",
    "    return {\"my_child_key\": f\"{state['my_child_key']} -> 完成处理\"}\n",
    "\n",
    "# 构建子图\n",
    "print(\"🏗️ 构建子图...\")\n",
    "child_builder = StateGraph(ChildState)\n",
    "child_builder.add_node(\"child_1\", child_node_1)\n",
    "child_builder.add_node(\"child_2\", child_node_2)\n",
    "child_builder.add_edge(START, \"child_1\")\n",
    "child_builder.add_edge(\"child_1\", \"child_2\")\n",
    "child_builder.add_edge(\"child_2\", END)\n",
    "\n",
    "child_graph = child_builder.compile()\n",
    "print(\"✅ 子图编译完成\")\n",
    "\n",
    "# 定义父图\n",
    "class ParentState(TypedDict):  # 父图的状态结构体 \n",
    "    my_key: str  # 父图状态键: my_key\n",
    "\n",
    "def call_child_graph(state: ParentState) -> ParentState:  # 节点函数，输入输出状态类型都为 ParentState\n",
    "    print(f\"🔄 调用子图节点: 接收父图状态 '{state['my_key']}'\")\n",
    "\n",
    "    # 状态转换: 父图状态 -> 子图状态 (ParentState.my_key -> ChildState.my_child_key)\n",
    "    child_graph_input = {\"my_child_key\": state[\"my_key\"]}  # 将父图状态的 my_key 值，赋值给子图状态的 my_child_key 键\n",
    "    print(f\"🔀 状态转换: 父图状态 -> 子图状态\")\n",
    "    print(f\"   输入子图: {child_graph_input}\")\n",
    "\n",
    "    # 调用子图\n",
    "    child_graph_output = child_graph.invoke(child_graph_input)  # 调用子图 child_graph\n",
    "    print(f\"📤 子图输出: {child_graph_output}\")\n",
    "\n",
    "    # 状态转换: 子图状态 -> 父图状态 (ChildState.my_child_key -> ParentState.my_key)\n",
    "    result = {\"my_key\": child_graph_output[\"my_child_key\"]}  # 将子图输出状态的 my_child_key 值，赋值给父图状态的 my_key 键\n",
    "    print(f\"🔀 状态转换: 子图状态 -> 父图状态\")\n",
    "    print(f\"   返回父图: {result}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def parent_node_1(state: ParentState):\n",
    "    print(f\"🔧 父图节点1: 预处理 '{state['my_key']}'\")\n",
    "    return {\"my_key\": f\"父图预处理: {state['my_key']}\"}\n",
    "\n",
    "def parent_node_2(state: ParentState):\n",
    "    print(f\"🔧 父图节点2: 后处理 '{state['my_key']}'\")\n",
    "    return {\"my_key\": f\"{state['my_key']} -> 父图完成\"}\n",
    "\n",
    "print(\"\\n🏗️ 构建父图...\")\n",
    "builder = StateGraph(ParentState)  # 创建父图 StateGraph，指定状态结构体为 \n",
    "ParentState\n",
    "\n",
    "# 父图的其他节点定义\n",
    "builder.add_node(\"parent_1\", parent_node_1)\n",
    "builder.add_node(\"parent_2\", parent_node_2)\n",
    "builder.add_node(\"child\", call_child_graph)  # 将节点函数 call_child_graph 作为节点添加到父图，节点名为 \"child\"\n",
    "\n",
    "builder.add_edge(START, \"parent_1\")  # 父图节点 parent_1 -> 节点函数 call_child_graph (普通边)\n",
    "builder.add_edge(\"parent_1\", \"child\")\n",
    "builder.add_edge(\"child\", \"parent_2\")\n",
    "builder.add_edge(\"parent_2\", END)\n",
    "\n",
    "graph = builder.compile()  # 编译父图\n",
    "print(\"✅ 父图构建完成！\")\n",
    "\n",
    "# 测试运行\n",
    "initial_state = {\"my_key\": \"用户输入数据\"}\n",
    "print(f\"\\n📥 初始父图状态: {initial_state}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "result = graph.invoke(initial_state)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n📤 最终父图状态: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22458d3e",
   "metadata": {},
   "source": [
    "🔄 核心价值\n",
    "\n",
    "- 灵活性: 支持父子图使用完全不同的状态结构体\n",
    "- 模块化: 实现复杂系统的模块化设计\n",
    "- 解耦合: 不同组件可以独立设计状态结构\n",
    "\n",
    "🎯 典型应用场景\n",
    "\n",
    "多智能体RAG系统示例：\n",
    "- 父图(Supervisor Agent): 关注最终RAG报告\n",
    "- 子图(ReAct Agent): 维护详细对话历史和工具调用记录\n",
    "\n",
    "🔀 状态转换四步流程\n",
    "\n",
    "1. 输入转换: 父图状态 → 子图状态\n",
    "2. 子图处理: 子图内部执行业务逻辑\n",
    "3. 输出转换: 子图状态 → 父图状态\n",
    "4. 状态更新: 返回转换后的父图状态\n",
    "\n",
    "✅ 选择策略\n",
    "\n",
    "- 共享状态键 → 直接将子图作为节点添加\n",
    "- 异构状态结构 → 使用节点函数+状态转换方式\n",
    "- 复杂多智能体系统 → 各智能体独立状态结构体\n",
    "\n",
    "关键优势: 实现了状态结构的完全解耦，支持复杂系统的分层设计和模块化开发。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rmkyk31y4e",
   "metadata": {},
   "source": [
    "**💡 子图机制核心价值**：\n",
    "\n",
    "#### 模块化设计\n",
    "- **数据处理子图**：封装了数据验证、清洗、转换的完整流程，可以在不同场景中复用\n",
    "- **报告生成子图**：专门负责报告生成逻辑，独立维护和测试\n",
    "- **主工作流**：通过组合不同子图，构建完整的数据处理管道\n",
    "\n",
    "#### 状态隔离与转换\n",
    "- 每个子图维护自己的状态结构\n",
    "- 通过节点函数进行状态转换，实现父图与子图之间的数据适配\n",
    "- 状态隔离避免了模块间的相互干扰\n",
    "\n",
    "#### 复用与扩展\n",
    "- 子图可以在不同的父图中复用，提高开发效率\n",
    "- 新的处理步骤可以通过添加新子图或修改现有子图来实现\n",
    "- 模块化设计使系统易于维护和扩展"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oqdf6x1e7k",
   "metadata": {},
   "source": [
    "## 3.5 工具调用：扩展智能体的能力边界\n",
    "\n",
    "在构建智能体系统的过程中，工具调用 (Tool Calling) 是一项至关重要的能力。智能体通过调用各种外部工具，可以扩展自身的能力边界，完成更复杂、更实用的任务。\n",
    "\n",
    "LangGraph 框架提供了强大的工具调用支持，并预置了 `ToolNode` 组件，极大地简化了在 LangGraph 图中集成和使用工具的流程。\n",
    "\n",
    "### 3.5.1 ToolNode：LangGraph 的工具调用中心\n",
    "\n",
    "`ToolNode` 是 LangGraph 框架预置的核心组件，专门用于处理工具调用操作。可以将其理解为 LangGraph 图中的\"工具执行器\"或\"工具调度中心\"。\n",
    "\n",
    "#### ToolNode 的核心职责：\n",
    "\n",
    "1. **接收来自 LLM 的工具调用请求**：与支持工具调用的 LLM 模型集成，接收工具调用请求\n",
    "2. **执行工具调用**：动态调度和调用预先注册的工具，并返回执行结果  \n",
    "3. **更新图状态**：将工具执行结果封装成 `ToolMessage` 并添加到图状态中\n",
    "\n",
    "#### 使用 ToolNode 的优势：\n",
    "\n",
    "- **简化工具集成**：封装工具调用复杂性，开发者只需简单注册工具列表\n",
    "- **原生支持 LangChain 工具**：与 LangChain 工具体系无缝集成\n",
    "- **内置错误处理**：自动捕获工具执行异常，提高系统鲁棒性\n",
    "- **兼容 ReAct Agent**：与 LangGraph 预置的 ReAct 组件高度兼容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m2y219n8kbj",
   "metadata": {},
   "source": [
    "##### 示例 3-28 & 3-29：使用 ToolNode 构建工具调用智能体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12394k6achoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "@tool # 使用 @tool 装饰器，将 Python 函数转换为 LangChain Tool\n",
    "def get_weather(location: str): # 定义工具函数 get_weather, location 参数用于接收城市名称\n",
    "    \"\"\"Call to get the current weather.\"\"\" # 工具函数的 docstring 会被作为工具的描述信息，提供给 LLM\n",
    "    if location.lower() in [\"sf\", \"san francisco\"]:\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    else:\n",
    "        return \"It's 90 degrees and sunny.\"\n",
    "\n",
    "@tool\n",
    "def get_coolest_cities():\n",
    "    \"\"\"Get a list of coolest cities\"\"\"\n",
    "    return \"nyc, sf\"\n",
    "\n",
    "\n",
    "\n",
    "# 创建 ToolNode 实例，注册工具列表 (包含 get_weather 和 get_coolest_cities 两个工具)\n",
    "tools = [get_weather, get_coolest_cities]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# 构造包含单个工具调用请求的 AIMessage\n",
    "message_with_single_tool_call = AIMessage( # 创建 AIMessage\n",
    "    content=\"\", # content 为空字符串，表示该消息主要用于工具调用，不包含文本内容\n",
    "    tool_calls=[ # tool_calls 参数，包含工具调用请求列表\n",
    "        {\n",
    "            \"name\": \"get_weather\", #  工具名称，必须与注册的工具名称一致\n",
    "            \"args\": {\"location\": \"sf\"}, #  工具参数，必须与工具函数定义的参数匹配\n",
    "            \"id\": \"tool_call_id\", #  工具调用 ID，用于唯一标识工具调用，  可以自定义\n",
    "            \"type\": \"tool_call\", #  消息类型，固定为 \"tool_call\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 手动调用 ToolNode，输入为包含 AIMessage 的状态字典\n",
    "tool_node_output = tool_node.invoke({\"messages\": [message_with_single_tool_call]})\n",
    "\n",
    "print(tool_node_output) # 打印 ToolNode 的输出结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27e1dce",
   "metadata": {},
   "source": [
    "##### 示例 3-30：手动调用 ToolNode（并行工具调用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7384c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造包含多个工具调用请求的 AIMessage\n",
    "message_with_multiple_tool_calls = AIMessage( # 创建 AIMessage\n",
    "    content=\"\",\n",
    "    tool_calls=[ # tool_calls 参数，包含多个工具调用请求\n",
    "        {\n",
    "            \"name\": \"get_coolest_cities\", # 工具 1：get_coolest_cities\n",
    "            \"args\": {},\n",
    "            \"id\": \"tool_call_id_1\",\n",
    "            \"type\": \"tool_call\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"get_weather\", # 工具 2：get_weather\n",
    "            \"args\": {\"location\": \"sf\"},\n",
    "            \"id\": \"tool_call_id_2\",\n",
    "            \"type\": \"tool_call\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 手动调用 ToolNode,  输入为包含 AIMessage 的状态字典\n",
    "tool_node_output = tool_node.invoke({\"messages\": [message_with_multiple_tool_calls]})\n",
    "\n",
    "print(tool_node_output) # 打印 ToolNode 的输出结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c18ae78",
   "metadata": {},
   "source": [
    "##### 示例 3-31：在 LangGraph 图中使用 ToolNode 构建 ReAct 智能体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a94d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, START, END # 导入 MessagesState\n",
    "from langgraph.prebuilt import ToolNode # 导入 ToolNode\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ... (get_weather, get_coolest_cities 工具函数的定义，此处省略) ...\n",
    "\n",
    "tools = [get_weather, get_coolest_cities] #  工具列表\n",
    "\n",
    "tool_node = ToolNode(tools) # 创建 ToolNode 实例，注册工具列表\n",
    "\n",
    "model_with_tools = ChatOpenAI(model=\"Qwen/Qwen3-8B\", temperature=0).bind_tools(tools) # 绑定工具列表到 LLM 模型\n",
    "\n",
    "def should_continue(state: MessagesState): # 条件路由函数，判断是否继续工具调用\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1] # 获取最后一个消息 (LLM 模型的输出)\n",
    "    if last_message.tool_calls: # 判断最后一个消息是否包含 tool_calls (工具调用请求)\n",
    "        return \"tools\" # 如果包含 tool_calls, 则路由到 \"tools\" 节点 (ToolNode)，执行工具调用\n",
    "    return END # 如果不包含 tool_calls,  则路由到 END 节点，结束流程\n",
    "\n",
    "def call_model(state: MessagesState): #  LLM 模型节点函数\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_tools.invoke(messages) # 调用 LLM 模型，生成 AI 消息 (可能包含 tool_calls)\n",
    "    return {\"messages\": [response]} # 返回包含 AI 消息的状态更新\n",
    "\n",
    "workflow = StateGraph(MessagesState) # 创建 StateGraph 实例，状态 Schema 为 MessagesState\n",
    "\n",
    "workflow.add_node(\"agent\", call_model) # 添加 LLM 模型节点，节点名为 \"agent\"\n",
    "workflow.add_node(\"tools\", tool_node) # 添加 ToolNode 节点，节点名为 \"tools\"\n",
    "\n",
    "workflow.add_edge(START, \"agent\") # 定义从 START 节点到 \"agent\" 节点的边 (流程入口)\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, [\"tools\", END]) #  定义条件边，根据 \"agent\" 节点的输出，动态路由到 \"tools\" 节点或 END 节点\n",
    "workflow.add_edge(\"tools\", \"agent\") # 定义从 \"tools\" 节点到 \"agent\" 节点的边 (ReAct 循环)\n",
    "\n",
    "app = workflow.compile() # 编译 LangGraph 图\n",
    "\n",
    "app.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e21f3b",
   "metadata": {},
   "source": [
    "##### 示例 3-32：自定义工具调用错误处理策略 （模型降级 + 清理错误信息）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bee9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "from langchain_core.messages.modifier import RemoveMessage\n",
    "\n",
    "from langgraph.graph import MessagesState, StateGraph, END, START\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class HaikuRequest(BaseModel):\n",
    "    topic: list[str] = Field(\n",
    "        max_length=3,\n",
    "        min_length=3,\n",
    "    )\n",
    "\n",
    "@tool\n",
    "def master_haiku_generator(request: HaikuRequest):\n",
    "    \"\"\"Generates a haiku based on the provided topics.\"\"\"\n",
    "    model = ChatOpenAI(model=\"Qwen/Qwen2-1.5B-Instruct\", temperature=0)\n",
    "    chain = model | StrOutputParser()\n",
    "    topics = \", \".join(request.topic)\n",
    "    haiku = chain.invoke(f\"Write a haiku about {topics}\")\n",
    "    return haiku\n",
    "\n",
    "def call_tool(state: MessagesState):\n",
    "    # 创建工具名称到工具函数的映射字典\n",
    "    tools_by_name = {master_haiku_generator.name: master_haiku_generator}\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]  # 获取最后一条消息\n",
    "    output_messages = []\n",
    "    # 遍历最后一条消息中的所有工具调用\n",
    "    for tool_call in last_message.tool_calls:\n",
    "        try:\n",
    "            # 根据工具名称找到对应的工具函数并调用，传入参数\n",
    "            tool_result = tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "            # 将工具调用结果封装为ToolMessage添加到输出消息列表\n",
    "            output_messages.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # 如果工具调用失败，捕获异常并返回错误信息\n",
    "            # 将错误信息封装为ToolMessage，并在additional_kwargs中标记错误\n",
    "            output_messages.append(\n",
    "                ToolMessage(\n",
    "                    content=str(e), \n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                    additional_kwargs={\"error\": e},  # 在额外参数中存储错误对象，用于后续错误处理\n",
    "                )\n",
    "            )\n",
    "    return {\"messages\": output_messages}\n",
    "\n",
    "# 初始化基础模型（较弱的模型）\n",
    "model = ChatOpenAI(model=\"Qwen/Qwen2-1.5B-Instruct\", temperature=0)\n",
    "model_with_tools = model.bind_tools([master_haiku_generator])\n",
    "\n",
    "# 初始化更强大的模型（用于降级策略）\n",
    "better_model = ChatOpenAI(model=\"Qwen/Qwen2.5-7B-Instruct\", temperature=0)\n",
    "better_model_with_tools = better_model.bind_tools([master_haiku_generator])\n",
    "\n",
    "def should_continue(state: MessagesState):\n",
    "    # 决定是否继续工具调用循环或结束流程\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:  # 如果最后一条消息包含工具调用请求\n",
    "        return \"tools\"  # 继续执行工具调用\n",
    "    return END  # 否则结束流程\n",
    "\n",
    "def should_fallback(\n",
    "    state: MessagesState,\n",
    ") -> Literal[\"agent\", \"remove_failed_tool_call_attempt\"]:\n",
    "    # 决定是否需要降级到更强大的模型\n",
    "    messages = state[\"messages\"]\n",
    "    # 查找是否有失败的工具调用消息（通过 additional_kwargs 中的 error 标记识别）\n",
    "    failed_tool_messages = [\n",
    "        msg\n",
    "        for msg in messages\n",
    "        if isinstance(msg, ToolMessage)\n",
    "        and msg.additional_kwargs.get(\"error\") is not None\n",
    "    ]\n",
    "    if failed_tool_messages:  # 如果存在失败的工具调用\n",
    "        return \"remove_failed_tool_call_attempt\"  # 路由到移除失败尝试的节点\n",
    "    return \"agent\"  # 否则继续使用当前模型\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    # 使用基础模型处理消息\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def remove_failed_tool_call_attempt(state: MessagesState):\n",
    "    # 移除失败的工具调用尝试，清理消息历史\n",
    "    messages = state[\"messages\"]\n",
    "    # 从后向前查找最近的AI消息索引\n",
    "    last_ai_message_index = next(\n",
    "        i\n",
    "        for i, msg in reversed(list(enumerate(messages)))\n",
    "        if isinstance(msg, AIMessage)\n",
    "    )\n",
    "    # 获取需要移除的消息（从最近的AI消息开始的所有消息）\n",
    "    messages_to_remove = messages[last_ai_message_index:]\n",
    "    # 返回移除指令，通过RemoveMessage标记需要移除的消息\n",
    "    return {\"messages\": [RemoveMessage(id=m.id) for m in messages_to_remove]}\n",
    "\n",
    "# 降级策略：使用更强大的模型重试\n",
    "def call_fallback_model(state: MessagesState):\n",
    "    # 使用更强大的模型处理消息\n",
    "    messages = state[\"messages\"]\n",
    "    response = better_model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# 创建状态图\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# 添加节点\n",
    "workflow.add_node(\"agent\", call_model)  # 基础模型节点\n",
    "workflow.add_node(\"tools\", call_tool)  # 工具调用节点\n",
    "workflow.add_node(\"remove_failed_tool_call_attempt\", remove_failed_tool_call_attempt)  # 清理失败尝试节点\n",
    "workflow.add_node(\"fallback_agent\", call_fallback_model)  # 降级模型节点\n",
    "\n",
    "# 添加边和条件边\n",
    "workflow.add_edge(START, \"agent\")  # 流程从agent节点开始\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])  # 根据should_continue函数决定是继续工具调用还是结束\n",
    "# 根据工具调用结果决定是继续使用当前模型还是清理失败尝试\n",
    "workflow.add_conditional_edges(\"tools\", should_fallback, path_map = {\"agent\": \"agent\", \"remove_failed_tool_call_attempt\": \"remove_failed_tool_call_attempt\"}) \n",
    "workflow.add_edge(\"remove_failed_tool_call_attempt\", \"fallback_agent\")  # 清理失败尝试后使用降级模型\n",
    "workflow.add_edge(\"fallback_agent\", \"tools\")  # 降级模型生成的工具调用请求继续由tools节点处理\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb149d8",
   "metadata": {},
   "source": [
    "##### 示例 3-33：工具函数返回 Command 对象，更新图状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8dfc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing_extensions import Annotated, Any\n",
    "\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from langgraph.prebuilt import ToolNode, InjectedState\n",
    "\n",
    "\n",
    "USER_INFO = [ # 定义用户信息列表 (示例数据)\n",
    "    {\"user_id\": \"1\", \"name\": \"Bob Dylan\", \"location\": \"New York, NY\"},\n",
    "    {\"user_id\": \"2\", \"name\": \"Taylor Swift\", \"location\": \"Beverly Hills, CA\"},\n",
    "]\n",
    "\n",
    "USER_ID_TO_USER_INFO = {info[\"user_id\"]: info for info in USER_INFO} #  用户 ID -> 用户信息 字典\n",
    "\n",
    "class State(AgentState): # 定义图状态结构体, 继承自 AgentState, 并添加 user_info 状态键\n",
    "    user_info: dict[str, Any]\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def lookup_user_info( # 定义工具函数 lookup_user_info\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    user_id: Annotated[str, InjectedState(\"user_id\")]\n",
    "):\n",
    "    \"\"\"Use this to look up user information to better assist them with their questions.\"\"\" # 工具描述信息\n",
    "    if user_id is None:\n",
    "        raise ValueError(\"Please provide user ID\")\n",
    "    if user_id not in USER_ID_TO_USER_INFO:\n",
    "        raise ValueError(f\"User '{user_id}' not found\")\n",
    "\n",
    "    user_info = USER_ID_TO_USER_INFO[user_id] # 根据 user_id 查询用户信息\n",
    "\n",
    "    return Command( # 工具函数返回 Command 对象\n",
    "        update={ # Command 对象包含状态更新指令\n",
    "            \"user_info\": user_info, # 更新 user_info 状态键，值为查询到的用户信息\n",
    "            \"messages\": [ # 更新 messages 状态键，添加 ToolMessage\n",
    "                ToolMessage(\n",
    "                    \"Successfully looked up user information\", tool_call_id=tool_call_id\n",
    "                )\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "# 初始化状态图\n",
    "graph = StateGraph(State)\n",
    "\n",
    "# 定义节点\n",
    "def agent_node(state: State):\n",
    "    \"\"\"智能体节点，处理用户请求\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    user_info = state.get(\"user_info\", {})\n",
    "    \n",
    "    # 如果有用户信息，将其添加到系统消息中\n",
    "    if user_info:\n",
    "        system_message = f\"You are assisting {user_info['name']} who lives in {user_info['location']}.\"\n",
    "    else:\n",
    "        system_message = \"You are a helpful assistant.\"\n",
    "    \n",
    "    # 调用模型处理请求\n",
    "    model = ChatOpenAI(model=\"Qwen/Qwen3-8B\", temperature=0)\n",
    "    model_with_tools = model.bind_tools([lookup_user_info])\n",
    "    response = model_with_tools.invoke([{\"role\": \"system\", \"content\": system_message}] + messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_use_tools(state: State):\n",
    "    \"\"\"决定是否使用工具\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # 检查最后一条消息是否包含工具调用\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"end\"\n",
    "\n",
    "# 使用 ToolNode 简化工具调用逻辑\n",
    "tools_node = ToolNode([lookup_user_info])\n",
    "\n",
    "# 添加节点到图\n",
    "graph.add_node(\"agent\", agent_node)\n",
    "graph.add_node(\"tools\", tools_node)\n",
    "\n",
    "# 添加边和条件边\n",
    "graph.add_edge(START, \"agent\")\n",
    "graph.add_edge(\"tools\", \"agent\")\n",
    "graph.add_conditional_edges(\"agent\", should_use_tools, {\"tools\": \"tools\", \"end\": END})\n",
    "\n",
    "# 编译图\n",
    "agent = graph.compile()\n",
    "\n",
    "# 调用 ReAct 智能体，通过 config 参数传递运行时参数 user_id\n",
    "for chunk in agent.stream(\n",
    "    # 通过 user_id 状态键传递运行时参数\n",
    "    {\"messages\": [(\"human\", \"who am i and where do i live?\")], \"user_id\": \"1\"},\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5590b732",
   "metadata": {},
   "source": [
    "##### 示例 3-34：使用 Annotated 和 InjectedState 注解传递运行时参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing_extensions import Annotated, Any\n",
    "\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from langgraph.prebuilt import ToolNode, InjectedState\n",
    "\n",
    "\n",
    "USER_INFO = [ #  用户信息列表 (示例数据)\n",
    "    {\"user_id\": \"1\", \"name\": \"Bob Dylan\", \"location\": \"New York, NY\"},\n",
    "    {\"user_id\": \"2\", \"name\": \"Taylor Swift\", \"location\": \"Beverly Hills, CA\"},\n",
    "]\n",
    "\n",
    "USER_ID_TO_USER_INFO = {info[\"user_id\"]: info for info in USER_INFO} #  用户 ID -> 用户信息 字典\n",
    "\n",
    "class State(AgentState): # 定义图状态结构体, 继承自 AgentState, 并添加 user_info 状态键\n",
    "    user_info: dict[str, Any]\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def lookup_user_info( # 定义工具函数 lookup_user_info\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    user_id: Annotated[str, InjectedState(\"user_id\")]\n",
    "):\n",
    "    \"\"\"Use this to look up user information to better assist them with their questions.\"\"\" # 工具描述信息\n",
    "    if user_id is None:\n",
    "        raise ValueError(\"Please provide user ID\")\n",
    "    if user_id not in USER_ID_TO_USER_INFO:\n",
    "        raise ValueError(f\"User '{user_id}' not found\")\n",
    "\n",
    "    user_info = USER_ID_TO_USER_INFO[user_id] # 根据 user_id 查询用户信息\n",
    "\n",
    "    return Command( # 工具函数返回 Command 对象\n",
    "        update={ # Command 对象包含状态更新指令\n",
    "            \"user_info\": user_info, # 更新 user_info 状态键，值为查询到的用户信息\n",
    "            \"messages\": [ # 更新 messages 状态键，添加 ToolMessage\n",
    "                ToolMessage(\n",
    "                    \"Successfully looked up user information\", tool_call_id=tool_call_id\n",
    "                )\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "# 初始化状态图\n",
    "graph = StateGraph(State)\n",
    "\n",
    "# 定义节点\n",
    "def agent_node(state: State):\n",
    "    \"\"\"智能体节点，处理用户请求\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    user_info = state.get(\"user_info\", {})\n",
    "    \n",
    "    # 如果有用户信息，将其添加到系统消息中\n",
    "    if user_info:\n",
    "        system_message = f\"You are assisting {user_info['name']} who lives in {user_info['location']}.\"\n",
    "    else:\n",
    "        system_message = \"You are a helpful assistant.\"\n",
    "    \n",
    "    # 调用模型处理请求\n",
    "    model = ChatOpenAI(model=\"Qwen/Qwen3-8B\", temperature=0)\n",
    "    model_with_tools = model.bind_tools([lookup_user_info])\n",
    "    response = model_with_tools.invoke([{\"role\": \"system\", \"content\": system_message}] + messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_use_tools(state: State):\n",
    "    \"\"\"决定是否使用工具\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # 检查最后一条消息是否包含工具调用\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"end\"\n",
    "\n",
    "# 使用 ToolNode 简化工具调用逻辑\n",
    "tools_node = ToolNode([lookup_user_info])\n",
    "\n",
    "# 添加节点到图\n",
    "graph.add_node(\"agent\", agent_node)\n",
    "graph.add_node(\"tools\", tools_node)\n",
    "\n",
    "# 添加边和条件边\n",
    "graph.add_edge(START, \"agent\")\n",
    "graph.add_edge(\"tools\", \"agent\")\n",
    "graph.add_conditional_edges(\"agent\", should_use_tools, {\"tools\": \"tools\", \"end\": END})\n",
    "\n",
    "# 编译图\n",
    "agent = graph.compile()\n",
    "\n",
    "# 调用 ReAct 智能体，通过 config 参数传递运行时参数 user_id\n",
    "for chunk in agent.stream(\n",
    "    # 通过 user_id 状态键传递运行时参数\n",
    "    {\"messages\": [(\"human\", \"who am i and where do i live?\")], \"user_id\": \"1\"},\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8g4owxr8xk",
   "metadata": {},
   "source": [
    "**💡 工具调用核心要点**：\n",
    "\n",
    "#### 工具定义与注册\n",
    "- **@tool 装饰器**：将 Python 函数转换为 LangChain 工具，自动生成工具描述\n",
    "- **清晰的 docstring**：工具描述信息帮助 LLM 理解何时和如何使用工具\n",
    "- **类型提示**：为工具参数添加类型提示，提高工具调用的准确性\n",
    "\n",
    "#### ToolNode 工作机制\n",
    "- **工具调度**：根据 LLM 的工具调用请求，动态调度对应的工具函数\n",
    "- **错误处理**：自动捕获工具执行异常，将错误信息封装为 ToolMessage\n",
    "- **状态更新**：将工具执行结果添加到图状态的消息历史中\n",
    "\n",
    "#### ReAct 循环实现\n",
    "- **Agent 节点**：负责接收输入，决定是否需要调用工具\n",
    "- **Tools 节点**：执行具体的工具调用操作\n",
    "- **条件路由**：根据是否包含 tool_calls 决定流程走向\n",
    "- **循环反馈**：工具结果返回给 Agent，形成“推理-行动-观察”循环"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfh581kwcus",
   "metadata": {},
   "source": [
    "## 3.6 图的可视化\n",
    "\n",
    "随着 LangGraph 流程变得越来越复杂，特别是当系统中引入了子图机制后，仅仅依靠代码来理解整个流程的结构和执行逻辑变得越来越困难。图的可视化成为了一种至关重要的辅助工具。\n",
    "\n",
    "通过将 LangGraph 图结构可视化地渲染成易于理解的图表，我们可以直观地把握流程的整体结构、节点之间的连接关系以及数据流动的方向。\n",
    "\n",
    "### 3.6.1 Mermaid 语法\n",
    "\n",
    "Mermaid 是一种流行的文本描述语言，用于快速创建各种类型的图表。LangGraph 内置了将 Graph 对象转换为 Mermaid 语法的功能。\n",
    "\n",
    "#### Mermaid 的优势：\n",
    "- **轻量级**：无需安装额外的依赖库，跨平台使用  \n",
    "- **易于编辑**：可以直接在浏览器或 Markdown 编辑器中查看和编辑\n",
    "- **易于分享**：文本格式便于版本控制和团队协作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h86f4i16z4",
   "metadata": {},
   "source": [
    "##### 示例 3-35 & 3-36：图可视化演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ohfvi2nrw",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Any\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    aggregate: Annotated[list, operator.add]\n",
    "\n",
    "def a(state: State):\n",
    "    print(f'Adding \"A\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"A\"]}\n",
    "\n",
    "def b(state: State):\n",
    "    print(f'Adding \"B\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"B\"]}\n",
    "\n",
    "def c(state: State):\n",
    "    print(f'Adding \"C\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"C\"]}\n",
    "\n",
    "def d(state: State):\n",
    "    print(f'Adding \"D\" to {state[\"aggregate\"]}')\n",
    "    return {\"aggregate\": [\"D\"]}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(a)\n",
    "builder.add_node(b)\n",
    "builder.add_node(c)\n",
    "builder.add_node(d)\n",
    "builder.add_edge(START, \"a\")\n",
    "builder.add_edge(\"a\", \"b\")\n",
    "builder.add_edge(\"a\", \"c\")\n",
    "builder.add_edge(\"b\", \"d\")\n",
    "builder.add_edge(\"c\", \"d\")\n",
    "builder.add_edge(\"d\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "print(graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7372cc0f",
   "metadata": {},
   "source": [
    "##### 示例 3-37：使用 Mermaid.ink API 渲染 PNG 图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb71a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "png_bytes = graph.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API) #  使用 MermaidDrawMethod.API 指定使用 Mermaid.ink API 渲染\n",
    "display(Image(png_bytes)) #  在 Notebook 中显示 PNG 图片"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afd74b",
   "metadata": {},
   "source": [
    "##### 示例 3-38：使用 Mermaid 和 Pyppeteer 库渲染 PNG 图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2cf151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "class MyNode:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, state: State):\n",
    "        return {\"messages\": [(\"assistant\", f\"Called node {self.name}\")]}\n",
    "\n",
    "\n",
    "def route(state) -> Literal[\"entry_node\", \"__end__\"]:\n",
    "    if len(state[\"messages\"]) > 10:\n",
    "        return \"__end__\"\n",
    "    return \"entry_node\"\n",
    "\n",
    "\n",
    "def add_fractal_nodes(builder, current_node, level, max_level):\n",
    "    if level > max_level:\n",
    "        return\n",
    "\n",
    "    # Number of nodes to create at this level\n",
    "    num_nodes = random.randint(1, 3)  # Adjust randomness as needed\n",
    "    for i in range(num_nodes):\n",
    "        nm = [\"A\", \"B\", \"C\"][i]\n",
    "        node_name = f\"node_{current_node}_{nm}\"\n",
    "        builder.add_node(node_name, MyNode(node_name))\n",
    "        builder.add_edge(current_node, node_name)\n",
    "\n",
    "        # Recursively add more nodes\n",
    "        r = random.random()\n",
    "        if r > 0.2 and level + 1 < max_level:\n",
    "            add_fractal_nodes(builder, node_name, level + 1, max_level)\n",
    "        elif r > 0.05:\n",
    "            builder.add_conditional_edges(node_name, route, node_name)\n",
    "        else:\n",
    "            # End\n",
    "            builder.add_edge(node_name, \"__end__\")\n",
    "\n",
    "\n",
    "def build_fractal_graph(max_level: int):\n",
    "    builder = StateGraph(State)\n",
    "    entry_point = \"entry_node\"\n",
    "    builder.add_node(entry_point, MyNode(entry_point))\n",
    "    builder.add_edge(START, entry_point)\n",
    "\n",
    "    add_fractal_nodes(builder, entry_point, 1, max_level)\n",
    "\n",
    "    # Optional: set a finish point if required\n",
    "    builder.add_edge(entry_point, END)  # or any specific node\n",
    "\n",
    "    return builder.compile()\n",
    "\n",
    "\n",
    "app = build_fractal_graph(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d422f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "import nest_asyncio\n",
    "\n",
    "# 修复 asyncio 运行时错误\n",
    "nest_asyncio.apply()\n",
    "\n",
    "png_bytes = app.get_graph().draw_mermaid_png( #  使用 draw_mermaid_png() 方法渲染 PNG 图片\n",
    "    draw_method=MermaidDrawMethod.PYPPETEER, #  指定使用 MermaidDrawMethod.PYPPETEER,  使用 Mermaid + Pyppeteer 渲染\n",
    "    curve_style=CurveStyle.LINEAR, #  设置曲线风格为线性\n",
    "    node_colors=NodeStyles(first=\"#ffdfba\", last=\"#baffc9\", default=\"#fad7de\"), #  自定义节点颜色\n",
    "    wrap_label_n_words=9, #  设置节点标签自动换行，  每行最多 9 个单词\n",
    "    output_file_path=None, #  不输出到文件\n",
    "    background_color=\"white\", #  设置背景色为白色\n",
    "    padding=10, #  设置边距为 10 像素\n",
    ")\n",
    "display(Image(png_bytes)) #  在 Notebook 中显示 PNG 图片"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "je31bve7tv",
   "metadata": {},
   "source": [
    "**💡 图可视化核心价值**：\n",
    "\n",
    "#### 可视化方式对比\n",
    "\n",
    "| 方式 | 优点 | 缺点 | 适用场景 |\n",
    "|------|------|------|----------|\n",
    "| **Mermaid 语法** | 轻量级，无需依赖，跨平台 | 定制化选项有限 | 快速原型，文档嵌入 |\n",
    "| **PNG 图片** | 直观清晰，易于分享 | 无法动态编辑 | 报告展示，静态文档 |\n",
    "| **交互式图表** | 可交互，功能丰富 | 需要额外工具 | 复杂系统分析 |\n",
    "\n",
    "#### 实际应用场景\n",
    "\n",
    "- **开发阶段**：使用 Mermaid 快速验证流程逻辑\n",
    "- **调试阶段**：通过图可视化发现流程问题\n",
    "- **文档阶段**：生成图表用于技术文档和团队分享\n",
    "- **维护阶段**：通过图结构分析优化系统架构\n",
    "\n",
    "图可视化不仅是一个开发辅助工具，更是理解和优化 LangGraph 系统的重要手段，特别是在处理复杂的多智能体系统和子图嵌套场景时发挥重要作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occ4jxydkyr",
   "metadata": {},
   "source": [
    "## 📚 本章总结\n",
    "\n",
    "通过本章的学习，我们深入探讨了 LangGraph 的图驱动 AI 智能体系统，掌握了状态、节点、边、命令四大核心原语的应用，学会了并行处理、MapReduce 模式、子图机制等高级技术，以及工具集成和图可视化等实用开发技能。LangGraph 的图计算模型为我们提供了构建复杂、动态、可扩展智能体系统的强大能力，让我们能够设计出真正适应现实世界复杂场景的 AI 应用。在下一章中，我们将探讨 AI 智能体的交互体验设计，学习如何构建更加人性化、直观易用的智能体界面和交互模式。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
