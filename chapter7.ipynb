{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chapter-intro",
   "metadata": {},
   "source": [
    "# ç¬¬ 7 ç« ï¼šAI æ™ºèƒ½ä½“ç³»ç»Ÿçš„æ¶æ„ä¸èŒƒå¼\n",
    "\n",
    "> æœ¬ç¬”è®°æ–‡ä»¶éœ€è¦ä¸ã€ŠLangGraphå®æˆ˜ã€‹çš„ç¬¬ 7 ç« çš„å†…å®¹é…å¥—ä½¿ç”¨ã€‚\n",
    "\n",
    "åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢ç´¢æ„å»ºå¤æ‚ã€é«˜æ•ˆä¸”å¯æ‰©å±•çš„ AI æ™ºèƒ½ä½“ç³»ç»Ÿçš„æ ¸å¿ƒè¦ç´ ï¼šæ¶æ„è®¾è®¡ä¸æ¨¡å¼åº”ç”¨ã€‚éšç€æˆ‘ä»¬ä¸æ–­æå‡ AI æ™ºèƒ½ä½“çš„èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†æ—¥ç›Šå¤æ‚çš„ä»»åŠ¡ï¼Œä»…ä»…ä¾èµ–å•ä¸€ã€çº¿æ€§çš„æ™ºèƒ½ä½“æ¨¡å‹å·²æ˜¾å¾—åŠ›ä¸ä»å¿ƒã€‚å¦‚åŒåŸå¸‚è§„åˆ’éœ€è¦è“å›¾ã€è½¯ä»¶å¼€å‘éœ€è¦æ¶æ„è®¾è®¡ï¼Œæ„å»ºå¼ºå¤§çš„ AI æ™ºèƒ½ä½“ç³»ç»ŸåŒæ ·éœ€è¦ç²¾å¿ƒè®¾è®¡çš„æ¶æ„ä½œä¸ºæ”¯æ’‘ã€‚\n",
    "\n",
    "æˆ‘ä»¬å°†ä»åŸºç¡€ä½†è‡³å…³é‡è¦çš„æ™ºèƒ½ä½“å·¥ä½œæµæ¨¡å¼å¼€å§‹ï¼Œä¾‹å¦‚æç¤ºé“¾ã€è·¯ç”±ã€å¹¶è¡ŒåŒ–ã€åè°ƒå™¨-å·¥ä½œè€…å’Œè¯„ä¼°å™¨-ä¼˜åŒ–å™¨ï¼Œè¿™äº›æ¨¡å¼æ„æˆäº†æ„å»ºå¤æ‚æ™ºèƒ½ä½“è¡Œä¸ºçš„åŸºçŸ³ã€‚éšåï¼Œæˆ‘ä»¬å°†é€æ­¥æ·±å…¥å¤šæ™ºèƒ½ä½“æ¶æ„çš„ä¸–ç•Œï¼Œé‡ç‚¹ä»‹ç»ä¸»ç®¡æ¶æ„å’Œåˆ†å±‚æ¶æ„ï¼Œæ­ç¤ºå¦‚ä½•é€šè¿‡ç»„ç»‡å’Œåè°ƒå¤šä¸ªä¸“ä¸šæ™ºèƒ½ä½“æ¥æå‡ç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½å’Œå¯ç®¡ç†æ€§ã€‚æœ€åï¼Œæˆ‘ä»¬å°†å‰ç»æ€§åœ°å®¡è§†æƒ…å¢ƒæ„ŸçŸ¥æ™ºèƒ½ä½“æ¶æ„ï¼Œè¿™ç§æ¶æ„ä»£è¡¨äº† AI æ™ºèƒ½ä½“å‘å±•çš„æ–°æ–¹å‘ã€‚\n",
    "\n",
    "é€šè¿‡æœ¬ç« çš„å­¦ä¹ ï¼Œæ‚¨å°†ä¸ä»…äº†è§£å„ç§æ™ºèƒ½ä½“ç³»ç»Ÿçš„æ¶æ„è“å›¾ï¼Œæ›´å°†æŒæ¡åœ¨ LangGraph ä¸­å®è·µè¿™äº›æ¶æ„æ¨¡å¼çš„å…³é”®æŠ€æœ¯å’Œæ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environment-setup",
   "metadata": {},
   "source": [
    "### ğŸš€ ç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "é¦–å…ˆåŠ è½½å¿…è¦çš„ç¯å¢ƒå˜é‡é…ç½®ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7-1",
   "metadata": {},
   "source": [
    "## 7.1 å¸¸è§çš„æ™ºèƒ½ä½“ç³»ç»Ÿå·¥ä½œæµ\n",
    "\n",
    "åœ¨äººå·¥æ™ºèƒ½ä½“å¼€å‘é¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨ AI æ™ºèƒ½ä½“ç”Ÿæ€ç³»ç»Ÿä¸­ï¼Œç†è§£ä¸åŒç±»å‹çš„æ™ºèƒ½ä½“ç³»ç»Ÿä¹‹é—´çš„ç»†å¾®å·®åˆ«è‡³å…³é‡è¦ã€‚æ­£å¦‚ Anthropic åœ¨å…¶å¯¹æ™ºèƒ½ä½“æ„å»ºæ¨¡å¼çš„å¯Œæœ‰æ´å¯ŸåŠ›çš„åˆ†æä¸­æ‰€å¼ºè°ƒçš„é‚£æ ·ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°é©¾é©­ AI ç³»ç»Ÿçš„å¤æ‚æ€§ã€‚\n",
    "\n",
    "Anthropic çš„ç ”ç©¶çªå‡ºäº†å·¥ä½œæµï¼ˆWorkflowï¼‰å’Œæ™ºèƒ½ä½“ï¼ˆAgentï¼‰ä¹‹é—´çš„ä¸€ä¸ªå…³é”®åŒºåˆ«ï¼š\n",
    "\n",
    "- **å·¥ä½œæµ**ï¼šLLM å’Œç›¸å…³å·¥å…·é€šè¿‡æ˜¾å¼é¢„å®šä¹‰çš„ä»£ç è·¯å¾„è¿›è¡Œç¼–æ’çš„ç³»ç»Ÿ\n",
    "- **æ™ºèƒ½ä½“**ï¼šå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åŠ¨æ€æŒ‡å¯¼è‡ªèº«æµç¨‹çš„ç³»ç»Ÿï¼Œå®æ—¶å†³ç­–å·¥å…·çš„ä½¿ç”¨ä»¥åŠå®ç°ç›®æ ‡æ‰€éœ€çš„æ­¥éª¤\n",
    "\n",
    "åœ¨ LangGraph çš„èƒŒæ™¯ä¸‹ï¼Œå·¥ä½œæµä½¿ç”¨å…¶çŠ¶æ€å›¾æ¶æ„ä¼˜é›…åœ°å®ç°ï¼Œå…è®¸å¼€å‘äººå‘˜ä»¥å¯è§†åŒ–å’Œç¼–ç¨‹æ–¹å¼å®šä¹‰ç³»ç»Ÿä¸­ä¸åŒç»„ä»¶ä¹‹é—´çš„ä¿¡æ¯å’Œæ§åˆ¶æµã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7-1-1",
   "metadata": {},
   "source": [
    "### 7.1.1 å·¥ä½œæµçš„åŸºç¡€æ„å»ºæ¨¡å—ï¼šå¢å¼ºå‹ LLM\n",
    "\n",
    "ç°ä»£ LLM ä¸ä»…ä»…æ˜¯ç‹¬ç«‹çš„æ¨¡å‹ï¼Œå®ƒä»¬é€šè¿‡ä¸€ç³»åˆ—åŠŸèƒ½å¾—åˆ°å¢å¼ºï¼Œè¿™äº›åŠŸèƒ½ä½¿å®ƒä»¬èƒ½å¤Ÿä¸ä¸–ç•Œäº’åŠ¨å¹¶æ‰§è¡Œè¶…å‡ºç®€å•æ–‡æœ¬ç”Ÿæˆçš„å¤æ‚ä»»åŠ¡ã€‚æ ¸å¿ƒå¢å¼ºåŠŸèƒ½é€šå¸¸åŒ…æ‹¬ï¼š\n",
    "\n",
    "- **æ£€ç´¢ï¼ˆRetrievalï¼‰**ï¼šå…è®¸ LLM è®¿é—®å’Œæ•´åˆæ¥è‡ªå¤–éƒ¨æ¥æºçš„ä¿¡æ¯\n",
    "- **å·¥å…·ï¼ˆToolsï¼‰**ï¼šä½¿ LLM èƒ½å¤Ÿä¸å¤–éƒ¨ç³»ç»Ÿäº¤äº’å¹¶åœ¨ç°å®ä¸–ç•Œä¸­æ‰§è¡Œæ“ä½œ\n",
    "- **è®°å¿†ï¼ˆMemoryï¼‰**ï¼šå…è®¸ LLM ä¿ç•™å’Œåˆ©ç”¨æ¥è‡ªè¿‡å»äº¤äº’æˆ–å·¥ä½œæµæ­¥éª¤çš„ä¿¡æ¯\n",
    "\n",
    "è¿™äº›å¢å¼ºåŠŸèƒ½ä¸æ ¸å¿ƒ LLM ååŒå·¥ä½œï¼Œæ„æˆäº†æ„å»ºå¤æ‚å·¥ä½œæµå’Œæ™ºèƒ½ä½“çš„åŸºç¡€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7-1-2",
   "metadata": {},
   "source": [
    "### 7.1.2 æç¤ºé“¾ï¼ˆPrompt Chainingï¼‰\n",
    "\n",
    "æç¤ºé“¾æ˜¯ä¸€ç§åŸºæœ¬çš„å·¥ä½œæµæ¨¡å¼ï¼Œä¸“æ³¨äºå°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºä¸€ç³»åˆ—æ›´ç®€å•ã€ç›¸äº’å…³è”çš„æ­¥éª¤ã€‚åœ¨è¿™ç§å·¥ä½œæµä¸­ï¼Œä¸€ä¸ª LLM è°ƒç”¨çš„è¾“å‡ºæˆä¸ºåç»­è°ƒç”¨çš„è¾“å…¥ï¼Œä»è€Œåˆ›å»ºä¸€ç³»åˆ—å¤„ç†é˜¶æ®µã€‚\n",
    "\n",
    "æç¤ºé“¾çš„ä¸»è¦ä¼˜åŠ¿åœ¨äºå®ƒèƒ½å¤Ÿé€šè¿‡ç®€åŒ–æ¯ä¸ª LLM è°ƒç”¨æ¥æé«˜å‡†ç¡®æ€§ã€‚é€šè¿‡å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºæ›´å°ã€æ›´æ˜“äºç®¡ç†çš„å­ä»»åŠ¡ï¼Œæ¯ä¸ª LLM è°ƒç”¨éƒ½ä¼šè·å¾—æ›´é›†ä¸­ä¸”æ›´æ˜ç¡®çš„æç¤ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-7-1",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 7-1ï¼šåŸºäº Graph API çš„æç¤ºé“¾å·¥ä½œæµå®ç°\n",
    "\n",
    "é¦–å…ˆå¯¼å…¥å¿…è¦çš„ LangGraph å’Œ LangChain ç»„ä»¶ï¼Œå¹¶å®ç°ä¸€ä¸ªç¬‘è¯ç”Ÿæˆå’Œæ”¹è¿›çš„æç¤ºé“¾ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆå§‹ç¬‘è¯ï¼š\n",
      "ä¸ºä»€ä¹ˆçŒ«å’ªä¸å–œæ¬¢ä¸Šç½‘ï¼Ÿ\n",
      "\n",
      "å› ä¸ºå®ƒä»¬æ€•â€œé¼ â€æ ‡ï¼\n",
      "\n",
      "æ”¹è¿›åçš„ç¬‘è¯ï¼š\n",
      "ä¸ºä»€ä¹ˆçŒ«å’ªä¸å–œæ¬¢ä¸Šç½‘ï¼Ÿ\n",
      "\n",
      "å› ä¸ºå®ƒä»¬æ€•â€œé¼ â€æ ‡ï¼Œä½†å®ƒä»¬æ›´å–œæ¬¢â€œç‚¹â€å¿ƒï¼Œå°¤å…¶æ˜¯â€œå–µâ€ç‚¹å¿ƒï¼\n",
      "\n",
      "æœ€ç»ˆç¬‘è¯ï¼š\n",
      "ä¸ºä»€ä¹ˆçŒ«å’ªä¸å–œæ¬¢ä¸Šç½‘ï¼Ÿ\n",
      "\n",
      "å› ä¸ºå®ƒä»¬æ€•â€œé¼ â€æ ‡ï¼Œä½†å®ƒä»¬æ›´å–œæ¬¢â€œç‚¹â€å¿ƒï¼Œå°¤å…¶æ˜¯â€œå–µâ€ç‚¹å¿ƒï¼ç„¶è€Œï¼Œæœ‰ä¸€å¤©ï¼Œä¸€åªçŒ«å’ªæ„å¤–æ‰“å¼€äº†ä¸€ä¸ªå…³äºâ€œå…»ç”Ÿâ€çš„ç½‘ç«™ï¼Œç»“æœå®ƒå‘ç°åªè¦è™šæ‹Ÿç‚¹å‡»å°±èƒ½è·å¾—æ— é™çš„â€œé±¼â€å¹²å’Œâ€œå¥¶â€ç“¶ï¼Œé¡¿æ—¶å°±æˆäº†ç½‘ä¸Šè´­ç‰©çš„ç‹‚æ¬¢è€…ï¼Œå½»åº•æŠ›å¼ƒäº†å¯¹â€œé¼ â€æ ‡çš„ææƒ§ï¼\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from llm_utils import llm\n",
    "\n",
    "# ä½¿ç”¨ TypedDict å®šä¹‰å›¾çŠ¶æ€ï¼Œç”¨äºç±»å‹æç¤ºå’ŒçŠ¶æ€ç®¡ç†\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    joke: str\n",
    "    improved_joke: str\n",
    "    final_joke: str\n",
    "\n",
    "# å›¾ä¸­çš„èŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨æç¤ºé“¾ä¸­çš„ä¸€ä¸ªæ­¥éª¤\n",
    "def generate_joke(state: State):\n",
    "    \"\"\"ç¬¬ä¸€ä¸ª LLM è°ƒç”¨ï¼Œæ ¹æ®ä¸»é¢˜ç”Ÿæˆåˆå§‹ç¬‘è¯\"\"\"\n",
    "    msg = llm.invoke(f\"å†™ä¸€ä¸ªå…³äº {state['topic']} çš„ç®€çŸ­ç¬‘è¯\") # ä½¿ç”¨çŠ¶æ€ä¸­çš„ä¸»é¢˜è°ƒç”¨ LLM\n",
    "    return {\"joke\": msg.content} # è¿”å›ç”Ÿæˆçš„ç¬‘è¯ï¼Œæ›´æ–°çŠ¶æ€ä¸­çš„ 'joke' é”®\n",
    "\n",
    "def check_punchline(state: State):\n",
    "    \"\"\"é—¨æ§å‡½æ•°ï¼Œæ£€æŸ¥ç¬‘è¯æ˜¯å¦æœ‰å¦™è¯­\"\"\"\n",
    "    # ç®€å•æ£€æŸ¥ - ç¬‘è¯æ˜¯å¦åŒ…å« \"?\" æˆ– \"!\" ä½œä¸ºå¦™è¯­å­˜åœ¨çš„ä»£ç†\n",
    "    if \"?\" in state[\"joke\"] or \"!\" in state[\"joke\"]:\n",
    "        return \"Fail\" # ç¬‘è¯æœªèƒ½é€šè¿‡å¦™è¯­æ£€æŸ¥\n",
    "    return \"Pass\" # ç¬‘è¯é€šè¿‡å¦™è¯­æ£€æŸ¥\n",
    "\n",
    "def improve_joke(state: State):\n",
    "    \"\"\"ç¬¬äºŒä¸ª LLM è°ƒç”¨ï¼Œé€šè¿‡æ·»åŠ æ–‡å­—æ¸¸æˆæ¥æ”¹è¿›ç¬‘è¯\"\"\"\n",
    "    msg = llm.invoke(f\"é€šè¿‡æ·»åŠ æ–‡å­—æ¸¸æˆä½¿è¿™ä¸ªç¬‘è¯æ›´æœ‰è¶£ï¼š{state['joke']}\") # è°ƒç”¨ LLM æ¥æ”¹è¿›ç¬‘è¯\n",
    "    return {\"improved_joke\": msg.content} # è¿”å›æ”¹è¿›åçš„ç¬‘è¯ï¼Œæ›´æ–°çŠ¶æ€ä¸­çš„ 'improved_joke'\n",
    "\n",
    "def polish_joke(state: State):\n",
    "    \"\"\"ç¬¬ä¸‰ä¸ª LLM è°ƒç”¨ï¼Œç”¨äºæœ€ç»ˆæ¶¦è‰²ï¼Œæ·»åŠ ä»¤äººæƒŠè®¶çš„è½¬æŠ˜\"\"\"\n",
    "    msg = llm.invoke(f\"ä¸ºè¿™ä¸ªç¬‘è¯æ·»åŠ ä¸€ä¸ªä»¤äººæƒŠè®¶çš„è½¬æŠ˜ï¼š{state['improved_joke']}\") # è°ƒç”¨ LLM æ¥æ¶¦è‰²ç¬‘è¯\n",
    "    return {\"final_joke\": msg.content} # è¿”å›æ¶¦è‰²åçš„ç¬‘è¯ï¼Œæ›´æ–°çŠ¶æ€ä¸­çš„ 'final_joke'\n",
    "\n",
    "# ä½¿ç”¨ StateGraph æ„å»ºå·¥ä½œæµï¼Œä½¿ç”¨å®šä¹‰çš„çŠ¶æ€è¿›è¡Œåˆå§‹åŒ–\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# å°†èŠ‚ç‚¹æ·»åŠ åˆ°å·¥ä½œæµå›¾ä¸­ï¼Œå°†å®ƒä»¬ä¸å®šä¹‰çš„å‡½æ•°å…³è”èµ·æ¥\n",
    "workflow.add_node(\"generate_joke\", generate_joke)\n",
    "workflow.add_node(\"improve_joke\", improve_joke)\n",
    "workflow.add_node(\"polish_joke\", polish_joke)\n",
    "\n",
    "# å®šä¹‰è¾¹ç¼˜ä»¥è¿æ¥èŠ‚ç‚¹å¹¶å»ºç«‹å·¥ä½œæµåºåˆ—\n",
    "workflow.add_edge(START, \"generate_joke\") # å¼€å§‹èŠ‚ç‚¹è¿æ¥åˆ° 'generate_joke' èŠ‚ç‚¹\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_joke\", check_punchline, {\"Pass\": \"improve_joke\", \"Fail\": END} # 'generate_joke' ä¹‹åçš„æ¡ä»¶è¾¹ç¼˜ï¼ŒåŸºäº 'check_punchline' è¾“å‡º\n",
    ")\n",
    "workflow.add_edge(\"improve_joke\", \"polish_joke\") # 'improve_joke' èŠ‚ç‚¹è¿æ¥åˆ° 'polish_joke' èŠ‚ç‚¹\n",
    "workflow.add_edge(\"polish_joke\", END) # 'polish_joke' èŠ‚ç‚¹è¿æ¥åˆ°ç»“æŸèŠ‚ç‚¹\n",
    "\n",
    "# å°†å·¥ä½œæµå›¾ç¼–è¯‘ä¸ºå¯æ‰§è¡Œé“¾\n",
    "chain = workflow.compile()\n",
    "\n",
    "\n",
    "# ä½¿ç”¨åˆå§‹çŠ¶æ€ï¼ˆä¸»é¢˜ï¼š\"cats\"ï¼‰è°ƒç”¨ç¼–è¯‘é“¾\n",
    "state = chain.invoke({\"topic\": \"cats\"})\n",
    "print(\"åˆå§‹ç¬‘è¯ï¼š\")\n",
    "print(state[\"joke\"])\n",
    "\n",
    "if \"improved_joke\" in state: # æ£€æŸ¥ 'improved_joke' æ˜¯å¦å­˜åœ¨äºçŠ¶æ€ä¸­ï¼ŒæŒ‡ç¤ºå¦™è¯­æ£€æŸ¥å¤±è´¥\n",
    "    print(\"\\næ”¹è¿›åçš„ç¬‘è¯ï¼š\")\n",
    "    print(state[\"improved_joke\"])\n",
    "    print(\"\\næœ€ç»ˆç¬‘è¯ï¼š\")\n",
    "    print(state[\"final_joke\"])\n",
    "\n",
    "# ä¿å­˜å›¾åƒ\n",
    "from draw import save_graph_as_png\n",
    "save_graph_as_png(chain, \"./graphs/c7/augumented_chain.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-7-1",
   "metadata": {},
   "source": [
    "**ğŸ’¡ æ ¸å¿ƒæ¦‚å¿µè§£æ**ï¼š\n",
    "\n",
    "åœ¨è¿™æ®µä»£ç ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†æç¤ºé“¾çš„å…³é”®ç‰¹æ€§ï¼š\n",
    "\n",
    "- **é¡ºåºå¤„ç†**ï¼šæ¯ä¸ªæ­¥éª¤çš„è¾“å‡ºæˆä¸ºä¸‹ä¸€ä¸ªæ­¥éª¤çš„è¾“å…¥\n",
    "- **é—¨æ§æœºåˆ¶**ï¼š`check_punchline` å‡½æ•°ä½œä¸ºè´¨é‡æ§åˆ¶æ£€æŸ¥ç‚¹\n",
    "- **æ¡ä»¶åˆ†æ”¯**ï¼šæ ¹æ®é—¨æ§ç»“æœå†³å®šæ˜¯ç›´æ¥ç»“æŸè¿˜æ˜¯ç»§ç»­æ”¹è¿›\n",
    "- **çŠ¶æ€ç®¡ç†**ï¼šä½¿ç”¨ TypedDict æ¸…æ™°å®šä¹‰æ•°æ®æµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-7-2",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 7-2ï¼šåŸºäº Functional API çš„æç¤ºé“¾å·¥ä½œæµå®ç°\n",
    "\n",
    "æ¥ä¸‹æ¥è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨ LangGraph çš„ Functional API å®ç°ç›¸åŒçš„æç¤ºé“¾é€»è¾‘ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.func import entrypoint, task\n",
    "\n",
    "llm = ChatOpenAI(model=\"Qwen/Qwen3-8B\")\n",
    "\n",
    "# ä½¿ç”¨ @task è£…é¥°å™¨å®šä¹‰çš„ä»»åŠ¡ï¼Œä»£è¡¨å·¥ä½œæµä¸­çš„æ­¥éª¤\n",
    "@task\n",
    "def generate_joke(topic: str):\n",
    "    \"\"\"ç¬¬ä¸€ä¸ª LLM è°ƒç”¨ï¼Œç”Ÿæˆåˆå§‹ç¬‘è¯\"\"\"\n",
    "    msg = llm.invoke(f\"å†™ä¸€ä¸ªå…³äº {topic} çš„ç®€çŸ­ç¬‘è¯\") # è°ƒç”¨ LLM ä»¥æ ¹æ®ä¸»é¢˜ç”Ÿæˆç¬‘è¯\n",
    "    return msg.content # è¿”å›ç”Ÿæˆçš„ç¬‘è¯\n",
    "\n",
    "def check_punchline(joke: str):\n",
    "    \"\"\"é—¨æ§å‡½æ•°ï¼Œæ£€æŸ¥ç¬‘è¯æ˜¯å¦æœ‰å¦™è¯­\"\"\"\n",
    "    # ç®€å•æ£€æŸ¥ - ç¬‘è¯æ˜¯å¦åŒ…å« \"?\" æˆ– \"!\"\n",
    "    if \"?\" in joke or \"!\" in joke:\n",
    "        return \"Fail\" # ç¬‘è¯æœªèƒ½é€šè¿‡å¦™è¯­æ£€æŸ¥\n",
    "    return \"Pass\" # ç¬‘è¯é€šè¿‡å¦™è¯­æ£€æŸ¥\n",
    "\n",
    "@task\n",
    "def improve_joke(joke: str):\n",
    "    \"\"\"ç¬¬äºŒä¸ª LLM è°ƒç”¨ï¼Œæ”¹è¿›ç¬‘è¯\"\"\"\n",
    "    msg = llm.invoke(f\"é€šè¿‡æ·»åŠ æ–‡å­—æ¸¸æˆä½¿è¿™ä¸ªç¬‘è¯æ›´æœ‰è¶£ï¼š{joke}\") # è°ƒç”¨ LLM ä»¥æ”¹è¿›ç¬‘è¯\n",
    "    return msg.content # è¿”å›æ”¹è¿›åçš„ç¬‘è¯\n",
    "\n",
    "@task\n",
    "def polish_joke(joke: str):\n",
    "    \"\"\"ç¬¬ä¸‰ä¸ª LLM è°ƒç”¨ï¼Œç”¨äºæœ€ç»ˆæ¶¦è‰²\"\"\"\n",
    "    msg = llm.invoke(f\"ä¸ºè¿™ä¸ªç¬‘è¯æ·»åŠ ä¸€ä¸ªä»¤äººæƒŠè®¶çš„è½¬æŠ˜ï¼š{joke}\") # è°ƒç”¨ LLM ä»¥æ¶¦è‰²ç¬‘è¯\n",
    "    return msg.content # è¿”å›æ¶¦è‰²åçš„ç¬‘è¯\n",
    "\n",
    "# å…¥å£ç‚¹è£…é¥°å‡½æ•°ä½¿ç”¨ Functional API å®šä¹‰å·¥ä½œæµ\n",
    "@entrypoint()\n",
    "def workflow(topic: str):\n",
    "    original_joke = generate_joke(topic).result() # æ‰§è¡Œ 'generate_joke' ä»»åŠ¡\n",
    "    if check_punchline(original_joke) == \"Pass\": # åŸºäº 'check_punchline' è¾“å‡ºçš„æ¡ä»¶æ£€æŸ¥\n",
    "        return original_joke # å¦‚æœå¦™è¯­æ£€æŸ¥é€šè¿‡ï¼Œåˆ™è¿”å›åŸå§‹ç¬‘è¯\n",
    "\n",
    "    improved_joke = improve_joke(original_joke).result() # å¦‚æœå¦™è¯­æ£€æŸ¥å¤±è´¥ï¼Œåˆ™æ‰§è¡Œ 'improve_joke' ä»»åŠ¡\n",
    "    return polish_joke(improved_joke).result() # æ‰§è¡Œ 'polish_joke' ä»»åŠ¡å¹¶è¿”å›æœ€ç»ˆç»“æœ\n",
    "\n",
    "# è°ƒç”¨å·¥ä½œæµ\n",
    "state = workflow.invoke(\"cats\")\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-7-2",
   "metadata": {},
   "source": [
    "**ğŸ’¡ Functional API çš„ä¼˜åŠ¿**ï¼š\n",
    "\n",
    "- **æ›´ç®€æ´çš„ä»£ç **ï¼šä½¿ç”¨ `@task` è£…é¥°å™¨å’Œå‡½æ•°å¼ç¼–ç¨‹é£æ ¼\n",
    "- **ç±»å‹å®‰å…¨**ï¼šå‡½æ•°å‚æ•°æä¾›æ¸…æ™°çš„ç±»å‹æç¤º\n",
    "- **æ˜“äºæµ‹è¯•**ï¼šæ¯ä¸ªä»»åŠ¡éƒ½æ˜¯ç‹¬ç«‹çš„å‡½æ•°ï¼Œä¾¿äºå•å…ƒæµ‹è¯•\n",
    "- **çµæ´»çš„æ§åˆ¶æµ**ï¼šä½¿ç”¨ Python çš„åŸç”Ÿæ§åˆ¶ç»“æ„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7-1-3",
   "metadata": {},
   "source": [
    "### 7.1.3 è·¯ç”± (Routing)\n",
    "\n",
    "è·¯ç”±å·¥ä½œæµæ—¨åœ¨é€šè¿‡å¯¹è¾“å…¥è¿›è¡Œåˆ†ç±»å¹¶å°†å…¶å®šå‘åˆ°ä¸“é—¨çš„ä¸‹æ¸¸ä»»åŠ¡æ¥å¤„ç†å„ç§è¾“å…¥ã€‚å½“å¤„ç†éœ€è¦å¤„ç†å„ç§è¾“å…¥ç±»å‹çš„å¤æ‚åº”ç”¨ç¨‹åºæ—¶ï¼Œæ­¤æ¨¡å¼å°¤å…¶æœ‰ä»·å€¼ï¼Œæ¯ç§è¾“å…¥ç±»å‹éƒ½éœ€è¦ä¸åŒçš„å¤„ç†æ–¹æ³•ã€‚\n",
    "\n",
    "è·¯ç”±èƒŒåçš„æ ¸å¿ƒæ€æƒ³æ˜¯å®æ–½å†³ç­–æ­¥éª¤ï¼Œè¯¥æ­¥éª¤åˆ†æè¾“å…¥å¹¶ç¡®å®šæœ€åˆé€‚çš„åç»­å¤„ç†è·¯å¾„ã€‚è¿™å…è®¸å…³æ³¨ç‚¹åˆ†ç¦»ï¼Œä»è€Œå¯ä»¥ä¸ºæ¯ä¸ªè¾“å…¥ç±»åˆ«å¼€å‘æ›´é›†ä¸­å’Œä¼˜åŒ–çš„æç¤ºå’Œæµç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-7-3",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 7-3ï¼šåŸºäº Graph API çš„è·¯ç”±å·¥ä½œæµå®ç°\n",
    "\n",
    "è®©æˆ‘ä»¬å®ç°ä¸€ä¸ªæ™ºèƒ½å†…å®¹è·¯ç”±å™¨ï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·è¾“å…¥ç”Ÿæˆæ•…äº‹ã€ç¬‘è¯æˆ–è¯—æ­Œï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2048d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸ºä»€ä¹ˆçŒ«æ€»æ˜¯å–œæ¬¢ååœ¨ç”µè„‘é”®ç›˜ä¸Šï¼Ÿ\n",
      "\n",
      "å› ä¸ºå®ƒä»¬æƒ³è¦æŒæ§â€œé¼ æ ‡â€!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from llm_utils import llm\n",
    "\n",
    "# è·¯ç”±å·¥ä½œæµçš„çŠ¶æ€å®šä¹‰\n",
    "class State(TypedDict):\n",
    "    input: str\n",
    "    decision: str\n",
    "    output: str\n",
    "\n",
    "# å›¾ä¸­çš„èŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹å¤„ç†ç‰¹å®šçš„è·¯ç”± (story, joke, poem)\n",
    "def llm_call_1(state: State):\n",
    "    \"\"\"å†™ä¸€ä¸ªæ•…äº‹\"\"\"\n",
    "    result = llm.invoke(state[\"input\"]) # è°ƒç”¨ LLM æ ¹æ®è¾“å…¥å†™ä¸€ä¸ªæ•…äº‹\n",
    "    return {\"output\": result.content} # è¿”å›æ•…äº‹ï¼Œæ›´æ–°çŠ¶æ€ä¸­çš„ 'output'\n",
    "\n",
    "def llm_call_2(state: State):\n",
    "    \"\"\"å†™ä¸€ä¸ªç¬‘è¯\"\"\"\n",
    "    result = llm.invoke(state[\"input\"]) # è°ƒç”¨ LLM æ ¹æ®è¾“å…¥å†™ä¸€ä¸ªç¬‘è¯\n",
    "    return {\"output\": result.content} # è¿”å›ç¬‘è¯ï¼Œæ›´æ–°çŠ¶æ€ä¸­çš„ 'output'\n",
    "\n",
    "def llm_call_3(state: State):\n",
    "    \"\"\"å†™ä¸€é¦–è¯—\"\"\"\n",
    "    result = llm.invoke(state[\"input\"]) # è°ƒç”¨ LLM æ ¹æ®è¾“å…¥å†™ä¸€é¦–è¯—\n",
    "    return {\"output\": result.content} # è¿”å›è¯—æ­Œï¼Œæ›´æ–°çŠ¶æ€ä¸­çš„ 'output'\n",
    "\n",
    "def llm_call_router(state: State):\n",
    "    \"\"\"ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºå°†è¾“å…¥è·¯ç”±åˆ°é€‚å½“çš„èŠ‚ç‚¹\"\"\"\n",
    "    # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºè°ƒç”¨å¢å¼ºå‹ LLMï¼Œä»¥å……å½“è·¯ç”±é€»è¾‘\n",
    "    \n",
    "    # åˆ›å»ºé“¾å¼è°ƒç”¨\n",
    "    chain = llm | StrOutputParser()\n",
    "    \n",
    "    response = chain.invoke([\n",
    "        SystemMessage(\n",
    "            content=\"You are a router that directs user input to the appropriate handler. Return a JSON object with a 'step' key and one of these values: 'story', 'joke', or 'poem'. For example: {'step': 'joke'}\"\n",
    "        ),\n",
    "        HumanMessage(content=state[\"input\"]),\n",
    "    ])\n",
    "    \n",
    "    # è§£æ JSON å­—ç¬¦ä¸²\n",
    "    try:\n",
    "        decision = json.loads(response) # è¿™è¡Œä»£ç çš„ä½œç”¨æ˜¯å°† JSON æ ¼å¼çš„å­—ç¬¦ä¸²è§£æä¸º Python å¯¹è±¡ï¼ˆé€šå¸¸æ˜¯å­—å…¸æˆ–åˆ—è¡¨ï¼‰\n",
    "        return {\"decision\": decision[\"step\"]}\n",
    "    except (json.JSONDecodeError, KeyError):\n",
    "        # å¦‚æœè§£æå¤±è´¥ï¼Œé»˜è®¤è¿”å› joke è·¯ç”±\n",
    "        return {\"decision\": \"joke\"}\n",
    "\n",
    "# æ¡ä»¶è¾¹ç¼˜å‡½æ•°ï¼Œæ ¹æ®å†³ç­–è·¯ç”±åˆ°é€‚å½“çš„èŠ‚ç‚¹\n",
    "def route_decision(state: State):\n",
    "    # æ ¹æ®çŠ¶æ€ä¸­çš„ 'decision' è¿”å›æ‚¨æƒ³è¦è®¿é—®çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°\n",
    "    if state[\"decision\"] == \"story\":\n",
    "        return \"llm_call_1\"\n",
    "    elif state[\"decision\"] == \"joke\":\n",
    "        return \"llm_call_2\"\n",
    "    elif state[\"decision\"] == \"poem\":\n",
    "        return \"llm_call_3\"\n",
    "\n",
    "# ä½¿ç”¨ StateGraph æ„å»ºè·¯ç”±å·¥ä½œæµ\n",
    "router_builder = StateGraph(State)\n",
    "\n",
    "# å°†èŠ‚ç‚¹æ·»åŠ åˆ°å›¾ä¸­\n",
    "router_builder.add_node(\"llm_call_1\", llm_call_1)\n",
    "router_builder.add_node(\"llm_call_2\", llm_call_2)\n",
    "router_builder.add_node(\"llm_call_3\", llm_call_3)\n",
    "router_builder.add_node(\"llm_call_router\", llm_call_router)\n",
    "\n",
    "# å®šä¹‰è¾¹ç¼˜ä»¥è¿æ¥èŠ‚ç‚¹å¹¶å»ºç«‹è·¯ç”±é€»è¾‘\n",
    "router_builder.add_edge(START, \"llm_call_router\") # å¼€å§‹èŠ‚ç‚¹è¿æ¥åˆ°è·¯ç”±å™¨èŠ‚ç‚¹\n",
    "router_builder.add_conditional_edges(\n",
    "    \"llm_call_router\",\n",
    "    route_decision,\n",
    "    {  # ç”± route_decision è¿”å›çš„åç§°ï¼šè¦è®¿é—®çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„åç§°\n",
    "        \"llm_call_1\": \"llm_call_1\",\n",
    "        \"llm_call_2\": \"llm_call_2\",\n",
    "        \"llm_call_3\": \"llm_call_3\",\n",
    "    },\n",
    ") # ä»è·¯ç”±å™¨åˆ°ä¸“ç”¨èŠ‚ç‚¹çš„æ¡ä»¶è¾¹ç¼˜ï¼ŒåŸºäºè·¯ç”±å†³ç­–\n",
    "router_builder.add_edge(\"llm_call_1\", END) # ä¸“ç”¨èŠ‚ç‚¹è¿æ¥åˆ°ç»“æŸèŠ‚ç‚¹\n",
    "router_builder.add_edge(\"llm_call_2\", END)\n",
    "router_builder.add_edge(\"llm_call_3\", END)\n",
    "\n",
    "# ç¼–è¯‘è·¯ç”±å·¥ä½œæµå›¾\n",
    "router_workflow = router_builder.compile()\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹è¾“å…¥è°ƒç”¨è·¯ç”±å·¥ä½œæµ\n",
    "state = router_workflow.invoke({\"input\": \"ç»™æˆ‘å†™ä¸€ä¸ªå…³äºçŒ«çš„ç¬‘è¯\"})\n",
    "print(state[\"output\"]) \n",
    "# ä¿å­˜å›¾åƒ\n",
    "# ä¿å­˜ Mermaid ç”Ÿæˆçš„ PNG å›¾åƒåˆ°æ–‡ä»¶\n",
    "from draw import save_graph_as_png\n",
    "save_graph_as_png(router_workflow, \"./graphs/c7/7-3router_workflow.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-7-3",
   "metadata": {},
   "source": [
    "**ğŸ’¡ è·¯ç”±æœºåˆ¶å…³é”®ç‰¹æ€§**ï¼š\n",
    "\n",
    "- **æ™ºèƒ½åˆ†ç±»**ï¼šè·¯ç”±å™¨èŠ‚ç‚¹ä½¿ç”¨ LLM çš„ç†è§£èƒ½åŠ›æ¥åˆ†æè¾“å…¥æ„å›¾\n",
    "- **ç»“æ„åŒ–è¾“å‡º**ï¼šä½¿ç”¨ JSON æ ¼å¼ç¡®ä¿è·¯ç”±å†³ç­–çš„å¯é æ€§\n",
    "- **ä¸“é—¨å¤„ç†**ï¼šæ¯ä¸ªè·¯ç”±ç›®æ ‡éƒ½æœ‰ä¸“é—¨çš„å¤„ç†é€»è¾‘\n",
    "- **å¯æ‰©å±•æ€§**ï¼šæ˜“äºæ·»åŠ æ–°çš„è·¯ç”±ç›®æ ‡å’Œå¤„ç†å™¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-7-4",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 7-4ï¼šåŸºäº Functional API çš„è·¯ç”±å·¥ä½œæµå®ç°\n",
    "\n",
    "è®©æˆ‘ä»¬ç”¨ Functional API å®ç°ç›¸åŒçš„è·¯ç”±é€»è¾‘ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.func import entrypoint, task\n",
    "\n",
    "llm = ChatOpenAI(model=\"Qwen/Qwen2.5-7B-Instruct\")\n",
    "\n",
    "@task\n",
    "def llm_call_1(input: str):\n",
    "    \"\"\"å†™ä¸€ä¸ªæ•…äº‹\"\"\"\n",
    "    result = llm.invoke(input) # è°ƒç”¨ LLM æ ¹æ®è¾“å…¥å†™ä¸€ä¸ªæ•…äº‹\n",
    "    return result.content # è¿”å›æ•…äº‹\n",
    "\n",
    "@task\n",
    "def llm_call_2(input: str):\n",
    "    \"\"\"å†™ä¸€ä¸ªç¬‘è¯\"\"\"\n",
    "    result = llm.invoke(input) # è°ƒç”¨ LLM æ ¹æ®è¾“å…¥å†™ä¸€ä¸ªç¬‘è¯\n",
    "    return result.content # è¿”å›ç¬‘è¯\n",
    "\n",
    "@task\n",
    "def llm_call_3(input: str):\n",
    "    \"\"\"å†™ä¸€é¦–è¯—\"\"\"\n",
    "    result = llm.invoke(input) # è°ƒç”¨ LLM æ ¹æ®è¾“å…¥å†™ä¸€é¦–è¯—\n",
    "    return result.content # è¿”å›è¯—æ­Œ\n",
    "\n",
    "def llm_call_router(input: str):\n",
    "    \"\"\"ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºå°†è¾“å…¥è·¯ç”±åˆ°é€‚å½“çš„èŠ‚ç‚¹\"\"\"\n",
    "    # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºè°ƒç”¨å¢å¼ºå‹ LLMï¼Œä»¥å……å½“è·¯ç”±é€»è¾‘\n",
    "    model = ChatOpenAI(model=\"Qwen/Qwen2.5-7B-Instruct\", model_kwargs={ \"response_format\": { \"type\": \"json_object\" } })\n",
    "    ai_msg = model.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"You are a router that directs user input to the appropriate handler. Return a JSON object with a 'step' key and one of these values: 'story', 'joke', or 'poem'. For example: {'step': 'joke'}\" # è·¯ç”± LLM çš„ç³»ç»Ÿæ¶ˆæ¯\n",
    "            ),\n",
    "            HumanMessage(content=input), # ç”¨æˆ·è¾“å…¥æ¶ˆæ¯\n",
    "        ]\n",
    "    )\n",
    "    decision = json.loads(ai_msg.content)\n",
    "    return {\"decision\": decision[\"step\"]} # è¿”å›è·¯ç”±å†³ç­–\n",
    "\n",
    "# å…¥å£ç‚¹è£…é¥°å‡½æ•°å®šä¹‰è·¯ç”±å·¥ä½œæµ\n",
    "@entrypoint()\n",
    "def router_workflow(input: str):\n",
    "    next_step = llm_call_router(input)[\"decision\"] # è·å–è·¯ç”±å†³ç­–çš„ 'decision' å€¼\n",
    "    llm_call = None # åˆå§‹åŒ– llm_call å˜é‡\n",
    "    \n",
    "    if next_step == \"story\": # åŸºäºè·¯ç”±å™¨å†³ç­–çš„æ¡ä»¶è·¯ç”±\n",
    "        llm_call = llm_call_1 # å¦‚æœè·¯ç”±æ˜¯ 'story'ï¼Œåˆ™åˆ†é… 'llm_call_1' ä»»åŠ¡\n",
    "    elif next_step == \"joke\":\n",
    "        llm_call = llm_call_2 # å¦‚æœè·¯ç”±æ˜¯ 'joke'ï¼Œåˆ™åˆ†é… 'llm_call_2' ä»»åŠ¡\n",
    "    elif next_step == \"poem\":\n",
    "        llm_call = llm_call_3 # å¦‚æœè·¯ç”±æ˜¯ 'poem'ï¼Œåˆ™åˆ†é… 'llm_call_3' ä»»åŠ¡\n",
    "        \n",
    "    if llm_call is None:\n",
    "        raise ValueError(f\"Invalid routing decision: {next_step}\")\n",
    "        \n",
    "    return llm_call(input) # æ‰§è¡Œé€‰å®šçš„ LLM è°ƒç”¨ä»»åŠ¡å¹¶è¿”å›ç»“æœ\n",
    "\n",
    "# è°ƒç”¨è·¯ç”±å·¥ä½œæµ\n",
    "for step in router_workflow.stream(\"ç»™æˆ‘å†™ä¸€ä¸ªå…³äºçŒ«çš„ç¬‘è¯\", stream_mode=\"updates\"):\n",
    "    print(step)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7-1-4",
   "metadata": {},
   "source": [
    "### 7.1.4 å¹¶è¡ŒåŒ– (Parallelization)\n",
    "\n",
    "å¹¶è¡ŒåŒ–æ˜¯å¦ä¸€ç§å·¥ä½œæµæ¨¡å¼ï¼Œå®ƒåˆ©ç”¨å¢å¼ºå‹ LLM åŒæ—¶å¤„ç†ä»»åŠ¡ä¸åŒæ–¹é¢çš„èƒ½åŠ›ã€‚å¹¶è¡ŒåŒ–ä¸æ˜¯æŒ‰é¡ºåºå¤„ç†ä»»åŠ¡ï¼Œè€Œæ˜¯å…è®¸åŒæ—¶è¿›è¡Œ LLM è°ƒç”¨ï¼Œå…¶è¾“å‡ºç¨åä»¥ç¼–ç¨‹æ–¹å¼èšåˆã€‚\n",
    "\n",
    "è¿™ç§æ–¹æ³•å¯ä»¥ä½“ç°åœ¨ä¸¤ä¸ªä¸»è¦å˜ä½“ä¸­ï¼š\n",
    "- **åˆ†æ®µ (Sectioning)**ï¼šå°†ä»»åŠ¡åˆ†è§£ä¸ºå¯ä»¥å¹¶è¡Œæ‰§è¡Œçš„ç‹¬ç«‹å­ä»»åŠ¡\n",
    "- **æŠ•ç¥¨ (Voting)**ï¼šå¤šæ¬¡è¿è¡Œç›¸åŒçš„ä»»åŠ¡ä»¥è·å¾—æ›´ç¨³å¥å’Œå¯é çš„ç»“æœ\n",
    "\n",
    "å¹¶è¡ŒåŒ–çš„ä¸»è¦å¥½å¤„æ˜¯æé«˜äº†æ•ˆç‡ï¼Œå°¤å…¶æ˜¯åœ¨å­ä»»åŠ¡çœŸæ­£ç‹¬ç«‹å¹¶ä¸”å¯ä»¥å¹¶å‘å¤„ç†çš„æƒ…å†µä¸‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-7-5",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 7-5ï¼šåŸºäº Graph API çš„å¹¶è¡ŒåŒ–å·¥ä½œæµå®ç°\n",
    "\n",
    "è®©æˆ‘ä»¬å®ç°ä¸€ä¸ªå¹¶è¡Œå†…å®¹ç”Ÿæˆå·¥ä½œæµï¼ŒåŒæ—¶ç”Ÿæˆæ•…äº‹ã€ç¬‘è¯å’Œè¯—æ­Œï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¿™æ˜¯ä¸€ä¸ªå…³äº cats çš„æ•…äº‹ã€ç¬‘è¯å’Œè¯—æ­Œï¼\n",
      "\n",
      "æ•…äº‹ï¼š\n",
      "åœ¨ä¸€ä¸ªå®é™çš„å°é•‡ä¸Šï¼Œä½ç€ä¸€åªåå«å°ç™½çš„çŒ«ã€‚å°ç™½æ˜¯ä¸€åªå¯çˆ±çš„ç™½è‰²é•¿æ¯›çŒ«ï¼Œçœ¼ç›åƒä¸¤é¢—ç»¿å®çŸ³ï¼Œå¥¹çš„æ¯›å‘åœ¨é˜³å…‰ä¸‹é—ªé—ªå‘å…‰ã€‚å°ç™½æ¯å¤©éƒ½åœ¨å°é•‡çš„è¡—é“ä¸Šæ¼«æ­¥ï¼Œæ¢ç´¢æ¯ä¸€ä¸ªè§’è½ï¼Œè·Ÿé•‡ä¸Šçš„äººä»¬æ‰“æ‹›å‘¼ã€‚\n",
      "\n",
      "å°ç™½æœ€å–œæ¬¢çš„åœ°æ–¹æ˜¯é•‡ä¸­å¿ƒçš„ä¸€å®¶å°å’–å•¡é¦†ï¼Œå’–å•¡é¦†çš„è€æ¿æ˜¯ä¸€ä½å’Œè”¼çš„è€å¥¶å¥¶ï¼Œå¥¹æ¯æ¬¡çœ‹åˆ°å°ç™½éƒ½ä¼šç»™å¥¹ä¸€å°ç¢—ç‰›å¥¶ã€‚å°ç™½ä¸ä»…å–œæ¬¢ç‰›å¥¶ï¼Œæ›´å–œæ¬¢ååœ¨å’–å•¡é¦†çš„çª—è¾¹ï¼Œè§‚å¯Ÿè¡—ä¸Šæ¥æ¥å¾€å¾€çš„äººå’Œè½¦ï¼Œå¬äººä»¬çš„æ¬¢å£°ç¬‘è¯­ã€‚\n",
      "\n",
      "æœ‰ä¸€å¤©ï¼Œå°ç™½åœ¨å’–å•¡é¦†çš„çª—è¾¹ï¼Œçªç„¶æ³¨æ„åˆ°ä¸€ä¸ªå°å¥³å­©ååœ¨è¡—è§’ï¼Œç¥æƒ…æ²®ä¸§ã€‚å°ç™½å¿ƒé‡Œä¸€åŠ¨ï¼Œå†³å®šå»çœ‹çœ‹å‘ç”Ÿäº†ä»€ä¹ˆäº‹ã€‚å¥¹è½»å·§åœ°è·³ä¸‹çª—å°ï¼Œèµ°åˆ°å°å¥³å­©çš„èº«è¾¹ã€‚å°å¥³å­©æŠ¬èµ·å¤´ï¼Œçœ‹åˆ°å°ç™½ï¼Œè„¸ä¸Šéœ²å‡ºäº†å¾®å¾®çš„ç¬‘å®¹ã€‚\n",
      "\n",
      "â€œä½ å¥½ï¼Œå°çŒ«å’ªã€‚â€å°å¥³å­©è½»å£°è¯´é“ï¼Œâ€œä½ çŸ¥é“å—ï¼Ÿæˆ‘ä¸¢äº†æˆ‘çš„é£ç­ã€‚â€å¥¹æŒ‡ç€å¤©ç©ºï¼Œå‡ æœµç™½äº‘æ­£æ‚ æ‚ è¡è¡ï¼Œé£ç­æ—©å·²é£å¾—ä¸è§è¸ªå½±ã€‚\n",
      "\n",
      "å°ç™½å¬äº†ï¼Œå¿ƒé‡Œæƒ³ï¼šâ€œè¦æ˜¯æˆ‘èƒ½å¸®åŠ©å¥¹æ‰¾åˆ°é£ç­è¯¥å¤šå¥½ï¼â€äºæ˜¯ï¼Œå¥¹å¼€å§‹åœ¨å‘¨å›´å››å¤„æ¢ç´¢ï¼Œè¯•å›¾æ‰¾åˆ°é£ç­çš„è¸ªè¿¹ã€‚å°ç™½ç©¿è¿‡èŠ±å›ã€çˆ¬ä¸Šäº†çŸ®å¢™ï¼ŒæŠŠç›®å…‰æŠ•å‘æ›´é«˜çš„åœ°æ–¹ï¼Œå¸Œæœ›èƒ½æ‰¾åˆ°é‚£åªé£ç­ã€‚\n",
      "\n",
      "å°±åœ¨è¿™æ—¶ï¼Œå°ç™½åœ¨ä¸€æ£µå¤§æ ‘çš„æ ‘æä¸Šå‘ç°äº†é‚£ä¸ªäº”å½©æ–‘æ–“çš„é£ç­ï¼å¥¹å…´å¥‹åœ°â€œå–µå–µâ€å«äº†èµ·æ¥ï¼Œå¸å¼•äº†è·¯è¿‡çš„è¡Œäººã€‚äººä»¬çœ‹åˆ°å°ç™½åœ¨æ ‘ä¸‹ä»°æœ›ï¼Œçº·çº·åœä¸‹è„šæ­¥ï¼Œè·Ÿéšå¥¹çš„ç›®å…‰ã€‚\n",
      "\n",
      "å°å¥³å­©å¬åˆ°å°ç™½çš„å«å£°ï¼ŒæŠ¬å¤´ä¸€çœ‹ï¼Œç«‹åˆ»æƒŠå–œåœ°è·³äº†èµ·æ¥ï¼šâ€œæˆ‘çš„é£ç­ï¼è°¢è°¢ä½ ï¼Œå°çŒ«å’ªï¼â€å¥¹è¿å¿™è·‘åˆ°æ ‘ä¸‹ï¼Œå’Œå‘¨å›´çš„äººä¸€èµ·æƒ³åŠæ³•æŠŠé£ç­æ‹¿ä¸‹æ¥ã€‚æœ€åï¼Œå‡ ä½å¥½å¿ƒçš„é‚»å±…ç”¨é•¿æ†å°†é£ç­è½»æ¾åœ°å–äº†ä¸‹æ¥ã€‚\n",
      "\n",
      "å°å¥³å­©é«˜å…´åœ°æŠ±ä½äº†é£ç­ï¼Œè„¸ä¸Šæ´‹æº¢ç€ç¿çƒ‚çš„ç¬‘å®¹ã€‚å¥¹è¹²ä¸‹èº«ï¼Œè½»è½»æŠšæ‘¸ç€å°ç™½çš„å¤´ï¼šâ€œè°¢è°¢ä½ ï¼Œå°ç™½ï¼Œä½ çœŸæ˜¯ä¸€åªäº†ä¸èµ·çš„çŒ«å’ªï¼â€å°ç™½ä¹Ÿå¼€å¿ƒåœ°ç”¨å¤´è¹­äº†è¹­å°å¥³å­©çš„æ‰‹ï¼Œå¿ƒé‡Œæš–æš–çš„ã€‚\n",
      "\n",
      "ä»é‚£å¤©èµ·ï¼Œå°ç™½å’Œå°å¥³å­©æˆäº†å¥½æœ‹å‹ã€‚æ¯å¤©ï¼Œå°å¥³å­©éƒ½ä¼šå¸¦ç€å°ç™½ä¸€èµ·åˆ°å’–å•¡é¦†ï¼Œå’Œå¥¹åˆ†äº«ç¾å‘³çš„ç‚¹å¿ƒå’Œç‰›å¥¶ã€‚å°ç™½ä¹Ÿå˜å¾—æ›´åŠ å¼€æœ—ï¼Œé™ªä¼´ç€å°å¥³å­©åº¦è¿‡äº†è®¸å¤šä¸ªå¿«ä¹çš„æ—¥å­ã€‚\n",
      "\n",
      "å°é•‡ä¸Šçš„äººä»¬éƒ½çŸ¥é“äº†å°ç™½å’Œå°å¥³å­©çš„æ•…äº‹ï¼Œä»–ä»¬éƒ½è¯´ï¼šâ€œè¿™åªçŒ«å’ªä¸ä»…æ˜¯æˆ‘ä»¬çš„æœ‹å‹ï¼Œè¿˜æ˜¯å°å¥³å­©çš„å¹¸è¿æ˜Ÿï¼â€å°ç™½åœ¨å°é•‡ä¸Šç•™ä¸‹äº†ä¸€æ®µç¾å¥½çš„å›å¿†ï¼Œä¹Ÿæ˜ç™½äº†å‹è°Šçš„çè´µã€‚\n",
      "\n",
      "ç¬‘è¯ï¼š\n",
      "ä¸ºä»€ä¹ˆçŒ«å’ªæ€»æ˜¯ååœ¨ç”µè„‘é”®ç›˜ä¸Šï¼Ÿ\n",
      "\n",
      "å› ä¸ºå®ƒä»¬å–œæ¬¢â€œæŒ‰çŒ«â€é”®ï¼\n",
      "\n",
      "è¯—æ­Œï¼š\n",
      "åœ¨é™è°§çš„å¤œæ™šï¼Œæœˆå…‰æŸ”å’Œï¼Œ  \n",
      "å°çŒ«æ‚„ç„¶æ¼«æ­¥ï¼Œä¼¼ä¹åœ¨æ­Œå”±ã€‚  \n",
      "å®ƒä»¬çš„çœ¼ç›æ˜äº®ï¼Œç’€ç’¨å¦‚æ˜Ÿï¼Œ  \n",
      "åœ¨é»‘å¹•ä¸­é—ªçƒï¼Œè‹¥éšè‹¥ç°çš„çµã€‚\n",
      "\n",
      "æ¯›å‘å¦‚ä¸ç»¸èˆ¬ï¼Œæ¸©æš–åˆè½»æŸ”ï¼Œ  \n",
      "æ¯ä¸ªè½»å·§çš„æ­¥ä¼ï¼Œéƒ½æ˜¯ä¸€åœºèˆè¹ˆã€‚  \n",
      "å®ƒä»¬åœ¨çª—è¾¹å®ˆå€™ï¼Œæ¢¦å¢ƒçš„å®ˆæŠ¤è€…ï¼Œ  \n",
      "æˆ–åœ¨é˜³å…‰ä¸‹æ‰“ç›¹ï¼Œæ²‰é†‰äºæ¸©æš–çš„é˜³å…‰ã€‚\n",
      "\n",
      "å’ªå’ªçš„å‘¼å”¤ï¼Œå¦‚å¾®é£ç»†è¯­ï¼Œ  \n",
      "å……æ»¡äº†æ¸©æƒ…ï¼Œåˆ†äº«æˆ‘çš„å¿ƒè¯­ã€‚  \n",
      "æ„‰æ‚¦çš„å°çˆªå­ï¼Œè½»è½»åœ°æŠšæ‘¸ï¼Œ  \n",
      "åœ¨ç”Ÿæ´»çš„æ¯ä¸ªè§’è½ï¼Œå¢æ·»ä¸€ä»½æ¬¢æ„‰ã€‚\n",
      "\n",
      "å®ƒä»¬æ˜¯å®¶ä¸­çš„ç²¾çµï¼Œæ¢ç´¢çš„å†’é™©è€…ï¼Œ  \n",
      "æ— å£°çš„ä¼´ä¾£ï¼Œç»™äºˆæˆ‘æ— å°½çš„æŸ”å’Œã€‚  \n",
      "çŒ«å’ªçš„ä¸–ç•Œï¼Œç¥ç§˜è€Œå¥‡å¦™ï¼Œ  \n",
      "æ¯ä¸€ä¸ªç¬é—´ï¼Œéƒ½æ˜¯çˆ±çš„å¬å”¤ã€‚  \n",
      "\n",
      "å½“å¤œå¹•é™ä¸´ï¼Œç¯å…‰æ¸æš—ï¼Œ  \n",
      "æˆ‘é™é™å®ˆå€™ï¼Œä¸ä½ å…±åº¦æ—¶å…‰ã€‚  \n",
      "åœ¨è¿™æ¸©æš–çš„ç¬é—´ï¼Œæˆ‘è½»è½»ä½è¯­ï¼Œ  \n",
      "æˆ‘å¿ƒä¸­çš„çŒ«å’ªï¼Œä½ æ˜¯æˆ‘çµé­‚çš„ä¸€éƒ¨åˆ†ã€‚  \n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from llm_utils import llm\n",
    "# å¹¶è¡Œå·¥ä½œæµçš„å›¾çŠ¶æ€å®šä¹‰\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    joke: str\n",
    "    story: str\n",
    "    poem: str\n",
    "    combined_output: str\n",
    "\n",
    "\n",
    "\n",
    "# å›¾ä¸­çš„èŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹å¹¶è¡Œç”Ÿæˆä¸åŒç±»å‹çš„å†…å®¹\n",
    "def call_llm_1(state: State):\n",
    "    \"\"\"ç¬¬ä¸€ä¸ª LLM è°ƒç”¨ï¼Œç”Ÿæˆåˆå§‹ç¬‘è¯\"\"\"\n",
    "    msg = llm.invoke(f\"å†™ä¸€ä¸ªå…³äº {state['topic']} çš„ç¬‘è¯\") # è°ƒç”¨ LLM ä»¥æ ¹æ®ä¸»é¢˜å†™ä¸€ä¸ªç¬‘è¯\n",
    "    return {\"joke\": msg.content} # è¿”å›ç¬‘è¯ï¼Œæ›´æ–°çŠ¶æ€ä¸­çš„ 'joke'\n",
    "\n",
    "def call_llm_2(state: State):\n",
    "    \"\"\"ç¬¬äºŒä¸ª LLM è°ƒç”¨ï¼Œç”Ÿæˆæ•…äº‹\"\"\"\n",
    "    msg = llm.invoke(f\"å†™ä¸€ä¸ªå…³äº {state['topic']} çš„æ•…äº‹\") # è°ƒç”¨ LLM ä»¥æ ¹æ®ä¸»é¢˜å†™ä¸€ä¸ªæ•…äº‹\n",
    "    return {\"story\": msg.content} # è¿”å›æ•…äº‹ï¼Œæ›´æ–°çŠ¶æ€ä¸­çš„ 'story'\n",
    "\n",
    "def call_llm_3(state: State):\n",
    "    \"\"\"ç¬¬ä¸‰ä¸ª LLM è°ƒç”¨ï¼Œç”Ÿæˆè¯—æ­Œ\"\"\"\n",
    "    msg = llm.invoke(f\"å†™ä¸€é¦–å…³äº {state['topic']} çš„è¯—æ­Œ\") # è°ƒç”¨ LLM ä»¥æ ¹æ®ä¸»é¢˜å†™ä¸€é¦–è¯—\n",
    "    return {\"poem\": msg.content} # è¿”å›è¯—æ­Œï¼Œæ›´æ–°çŠ¶æ€ä¸­çš„ 'poem'\n",
    "\n",
    "def aggregator(state: State):\n",
    "    \"\"\"å°†ç¬‘è¯ã€æ•…äº‹å’Œè¯—æ­Œç»„åˆæˆå•ä¸ªè¾“å‡º\"\"\"\n",
    "    combined = f\"è¿™æ˜¯ä¸€ä¸ªå…³äº {state['topic']} çš„æ•…äº‹ã€ç¬‘è¯å’Œè¯—æ­Œï¼\\n\\n\" # å¼€å§‹ç»„åˆè¾“å‡º\n",
    "    combined += f\"æ•…äº‹ï¼š\\n{state['story']}\\n\\n\" # å°†æ•…äº‹æ·»åŠ åˆ°ç»„åˆè¾“å‡º\n",
    "    combined += f\"ç¬‘è¯ï¼š\\n{state['joke']}\\n\\n\" # å°†ç¬‘è¯æ·»åŠ åˆ°ç»„åˆè¾“å‡º\n",
    "    combined += f\"è¯—æ­Œï¼š\\n{state['poem']}\" # å°†è¯—æ­Œæ·»åŠ åˆ°ç»„åˆè¾“å‡º\n",
    "    return {\"combined_output\": combined} # è¿”å›ç»„åˆè¾“å‡ºï¼Œæ›´æ–°çŠ¶æ€ä¸­çš„ 'combined_output'\n",
    "\n",
    "# ä½¿ç”¨ StateGraph æ„å»ºå¹¶è¡Œå·¥ä½œæµ\n",
    "parallel_builder = StateGraph(State)\n",
    "\n",
    "# å°†èŠ‚ç‚¹æ·»åŠ åˆ°å›¾ä¸­\n",
    "parallel_builder.add_node(\"call_llm_1\", call_llm_1)\n",
    "parallel_builder.add_node(\"call_llm_2\", call_llm_2)\n",
    "parallel_builder.add_node(\"call_llm_3\", call_llm_3)\n",
    "parallel_builder.add_node(\"aggregator\", aggregator)\n",
    "\n",
    "# å®šä¹‰è¾¹ç¼˜ä»¥è¿æ¥èŠ‚ç‚¹å¹¶å»ºç«‹å¹¶è¡Œæ‰§è¡Œ\n",
    "parallel_builder.add_edge(START, \"call_llm_1\") # å¼€å§‹èŠ‚ç‚¹è¿æ¥åˆ° 'call_llm_1' ä»¥è¿›è¡Œå¹¶è¡Œæ‰§è¡Œ\n",
    "parallel_builder.add_edge(START, \"call_llm_2\") # å¼€å§‹èŠ‚ç‚¹è¿æ¥åˆ° 'call_llm_2' ä»¥è¿›è¡Œå¹¶è¡Œæ‰§è¡Œ\n",
    "parallel_builder.add_edge(START, \"call_llm_3\") # å¼€å§‹èŠ‚ç‚¹è¿æ¥åˆ° 'call_llm_3' ä»¥è¿›è¡Œå¹¶è¡Œæ‰§è¡Œ\n",
    "parallel_builder.add_edge(\"call_llm_1\", \"aggregator\") # 'call_llm_1' èŠ‚ç‚¹åœ¨å®Œæˆåè¿æ¥åˆ°èšåˆå™¨\n",
    "parallel_builder.add_edge(\"call_llm_2\", \"aggregator\") # 'call_llm_2' èŠ‚ç‚¹åœ¨å®Œæˆåè¿æ¥åˆ°èšåˆå™¨\n",
    "parallel_builder.add_edge(\"call_llm_3\", \"aggregator\") # 'call_llm_3' èŠ‚ç‚¹åœ¨å®Œæˆåè¿æ¥åˆ°èšåˆå™¨\n",
    "parallel_builder.add_edge(\"aggregator\", END) # èšåˆå™¨èŠ‚ç‚¹è¿æ¥åˆ°ç»“æŸèŠ‚ç‚¹\n",
    "\n",
    "# ç¼–è¯‘å¹¶è¡Œå·¥ä½œæµå›¾\n",
    "parallel_workflow = parallel_builder.compile()\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹è¾“å…¥è°ƒç”¨å¹¶è¡Œå·¥ä½œæµ\n",
    "state = parallel_workflow.invoke({\"topic\": \"cats\"})\n",
    "print(state[\"combined_output\"]) \n",
    "\n",
    "# ä¿å­˜å›¾åƒ\n",
    "from draw import save_graph_as_png\n",
    "save_graph_as_png(parallel_workflow, \"./graphs/c7/Parallelization_workflow.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explanation-7-5",
   "metadata": {},
   "source": [
    "**ğŸ’¡ å¹¶è¡ŒåŒ–çš„å…³é”®ä¼˜åŠ¿**ï¼š\n",
    "\n",
    "- **æ•ˆç‡æå‡**ï¼šå¤šä¸ª LLM è°ƒç”¨åŒæ—¶æ‰§è¡Œï¼Œå‡å°‘æ€»ä½“ç­‰å¾…æ—¶é—´\n",
    "- **ç‹¬ç«‹å¤„ç†**ï¼šæ¯ä¸ªä»»åŠ¡ä¸“æ³¨äºç‰¹å®šæ–¹é¢ï¼Œé¿å…ä¸Šä¸‹æ–‡æ··ä¹±\n",
    "- **ç»“æœèšåˆ**ï¼šé€šè¿‡èšåˆå™¨èŠ‚ç‚¹ç»„åˆæ‰€æœ‰ç»“æœ\n",
    "- **å¯æ‰©å±•æ€§**ï¼šæ˜“äºæ·»åŠ æ›´å¤šå¹¶è¡Œå¤„ç†åˆ†æ”¯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-7-6",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 7-6ï¼šåŸºäº Functional API çš„å¹¶è¡ŒåŒ–å·¥ä½œæµå®ç°\n",
    "\n",
    "è®©æˆ‘ä»¬ç”¨ Functional API å®ç°ç›¸åŒçš„å¹¶è¡Œå¤„ç†é€»è¾‘ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.func import entrypoint, task\n",
    "\n",
    "llm = ChatOpenAI(model=\"Qwen/Qwen3-8B\")\n",
    "\n",
    "@task\n",
    "def call_llm_1(topic: str):\n",
    "    \"\"\"ç¬¬ä¸€ä¸ª LLM è°ƒç”¨ï¼Œç”Ÿæˆåˆå§‹ç¬‘è¯\"\"\"\n",
    "    msg = llm.invoke(f\"å†™ä¸€ä¸ªå…³äº {topic} çš„ç¬‘è¯\") # è°ƒç”¨ LLM ä»¥æ ¹æ®ä¸»é¢˜å†™ä¸€ä¸ªç¬‘è¯\n",
    "    return msg.content # è¿”å›ç¬‘è¯\n",
    "\n",
    "@task\n",
    "def call_llm_2(topic: str):\n",
    "    \"\"\"ç¬¬äºŒä¸ª LLM è°ƒç”¨ï¼Œç”Ÿæˆæ•…äº‹\"\"\"\n",
    "    msg = llm.invoke(f\"å†™ä¸€ä¸ªå…³äº {topic} çš„æ•…äº‹\") # è°ƒç”¨ LLM ä»¥æ ¹æ®ä¸»é¢˜å†™ä¸€ä¸ªæ•…äº‹\n",
    "    return msg.content # è¿”å›æ•…äº‹\n",
    "\n",
    "@task\n",
    "def call_llm_3(topic):\n",
    "    \"\"\"ç¬¬ä¸‰ä¸ª LLM è°ƒç”¨ï¼Œç”Ÿæˆè¯—æ­Œ\"\"\"\n",
    "    msg = llm.invoke(f\"å†™ä¸€é¦–å…³äº {topic} çš„è¯—æ­Œ\") # è°ƒç”¨ LLM ä»¥æ ¹æ®ä¸»é¢˜å†™ä¸€é¦–è¯—\n",
    "    return msg.content # è¿”å›è¯—æ­Œ\n",
    "\n",
    "@task\n",
    "def aggregator(topic, joke, story, poem):\n",
    "    \"\"\"å°†ç¬‘è¯å’Œæ•…äº‹ç»„åˆæˆå•ä¸ªè¾“å‡º\"\"\"\n",
    "    combined = f\"è¿™æ˜¯ä¸€ä¸ªå…³äº {topic} çš„æ•…äº‹ã€ç¬‘è¯å’Œè¯—æ­Œï¼\\n\\n\" # å¼€å§‹ç»„åˆè¾“å‡º\n",
    "    combined += f\"æ•…äº‹ï¼š\\n{story}\\n\\n\" # å°†æ•…äº‹æ·»åŠ åˆ°ç»„åˆè¾“å‡º\n",
    "    combined += f\"ç¬‘è¯ï¼š\\n{joke}\\n\\n\" # å°†ç¬‘è¯æ·»åŠ åˆ°ç»„åˆè¾“å‡º\n",
    "    combined += f\"è¯—æ­Œï¼š\\n{poem}\" # å°†è¯—æ­Œæ·»åŠ åˆ°ç»„åˆè¾“å‡º\n",
    "    return combined # è¿”å›ç»„åˆè¾“å‡º\n",
    "\n",
    "# å…¥å£ç‚¹è£…é¥°å‡½æ•°å®šä¹‰å¹¶è¡Œå·¥ä½œæµ\n",
    "@entrypoint()\n",
    "def parallel_workflow(topic: str):\n",
    "    joke_fut = call_llm_1(topic) # æ‰§è¡Œ 'call_llm_1' ä»»åŠ¡å¹¶è·å–æœŸè´§ä»¥è¿›è¡Œå¹¶è¡Œæ‰§è¡Œ\n",
    "    story_fut = call_llm_2(topic) # æ‰§è¡Œ 'call_llm_2' ä»»åŠ¡å¹¶è·å–æœŸè´§ä»¥è¿›è¡Œå¹¶è¡Œæ‰§è¡Œ\n",
    "    poem_fut = call_llm_3(topic) # æ‰§è¡Œ 'call_llm_3' ä»»åŠ¡å¹¶è·å–æœŸè´§ä»¥è¿›è¡Œå¹¶è¡Œæ‰§è¡Œ\n",
    "    return aggregator(\n",
    "        topic, joke_fut.result(), story_fut.result(), poem_fut.result() # åœ¨æ‰€æœ‰å¹¶è¡Œä»»åŠ¡å®Œæˆåæ‰§è¡Œ 'aggregator' ä»»åŠ¡\n",
    "    ).result() # ä»èšåˆå™¨è·å–æœ€ç»ˆç»“æœ\n",
    "\n",
    "# è°ƒç”¨å¹¶è¡Œå·¥ä½œæµ\n",
    "for step in parallel_workflow.stream(\"cats\", stream_mode=\"updates\"):\n",
    "    print(step)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "todo-update-1",
   "metadata": {},
   "source": [
    "**ğŸ’¡ Functional API ä¸­çš„å¹¶è¡Œå¤„ç†**ï¼š\n",
    "\n",
    "- **Future å¯¹è±¡**ï¼šé€šè¿‡ `.result()` æ–¹æ³•ç­‰å¾…å¼‚æ­¥ä»»åŠ¡å®Œæˆ\n",
    "- **ç®€æ´è¯­æ³•**ï¼šå¹¶è¡Œæ‰§è¡Œé€šè¿‡åŒæ—¶å¯åŠ¨å¤šä¸ªä»»åŠ¡å®ç°\n",
    "- **è‡ªåŠ¨åŒæ­¥**ï¼šèšåˆå™¨ä¼šç­‰å¾…æ‰€æœ‰å‰ç½®ä»»åŠ¡å®Œæˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dj67jjxa5xq",
   "metadata": {},
   "source": [
    "### 7.1.5 åè°ƒå™¨-å·¥ä½œè€… (Orchestrator-Worker)\n",
    "\n",
    "åè°ƒå™¨-å·¥ä½œè€…å·¥ä½œæµæ¨¡å¼ä¸“ä¸ºå­ä»»åŠ¡éœ€æ±‚äº‹å…ˆæœªçŸ¥ä¸”éœ€è¦åœ¨æ‰§è¡ŒæœŸé—´åŠ¨æ€ç¡®å®šçš„å¤æ‚ä»»åŠ¡è€Œè®¾è®¡ã€‚åœ¨æ­¤æ¨¡å¼ä¸­ï¼Œä¸­å¤®å¢å¼ºå‹ LLM å……å½“\"åè°ƒå™¨ (Orchestrator)\"ï¼Œè´Ÿè´£å°†åˆå§‹ä»»åŠ¡åˆ†è§£ä¸ºæ›´å°ã€æ›´æ˜“äºç®¡ç†çš„å­ä»»åŠ¡ï¼Œå¹¶å°†è¿™äº›å­ä»»åŠ¡å§”æ´¾ç»™\"å·¥ä½œè€… (Worker)\"å¢å¼ºå‹ LLMã€‚\n",
    "\n",
    "æ­¤å·¥ä½œæµç‰¹åˆ«é€‚ç”¨äºéš¾ä»¥æˆ–ä¸å¯èƒ½é¢„å…ˆé¢„æµ‹å¿…è¦å­ä»»åŠ¡çš„å¤æ‚åœºæ™¯ï¼Œä¾‹å¦‚ç¼–ç ä»»åŠ¡ã€å¤æ‚æœç´¢ä»»åŠ¡ç­‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yhnp7oyv2k8",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 7-7ï¼šåŸºäº Graph API çš„\"åè°ƒå™¨-å·¥ä½œè€…\"å·¥ä½œæµå®ç°\n",
    "\n",
    "è®©æˆ‘ä»¬å®ç°ä¸€ä¸ªæŠ¥å‘Šç”Ÿæˆçš„åè°ƒå™¨-å·¥ä½œè€…ç³»ç»Ÿï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ppbtmr227s",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "\n",
    "\n",
    "# ç”¨äºç»“æ„åŒ–è¾“å‡ºçš„æ¨¡å¼ï¼Œç”¨äºè§„åˆ’æŠ¥å‘Šç« èŠ‚\n",
    "class Section(BaseModel):\n",
    "    name: str = Field(\n",
    "        description=\"æŠ¥å‘Šç« èŠ‚çš„åç§°\", # æŠ¥å‘Šç« èŠ‚çš„åç§°\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"æœ¬ç« èŠ‚ä¸­è¦æ¶µç›–çš„ä¸»è¦ä¸»é¢˜å’Œæ¦‚å¿µçš„ç®€è¦æ¦‚è¿°\", # ç« èŠ‚å†…å®¹çš„æè¿°\n",
    "    )\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: List[Section] = Field(\n",
    "        description=\"æŠ¥å‘Šçš„ç« èŠ‚\", # æŠ¥å‘Šç« èŠ‚åˆ—è¡¨\n",
    "    )\n",
    "\n",
    "# ç”¨äºè§„åˆ’æŠ¥å‘Šç« èŠ‚çš„å¢å¼ºå‹ LLMï¼Œä½¿ç”¨ç»“æ„åŒ–è¾“å‡º\n",
    "llm = ChatOpenAI(model=\"Qwen/Qwen2.5-7B-Instruct\")\n",
    "planner = llm.with_structured_output(Sections, method=\"function_calling\")\n",
    "\n",
    "# åè°ƒå™¨-å·¥ä½œè€…å·¥ä½œæµçš„å›¾çŠ¶æ€å®šä¹‰\n",
    "class State(TypedDict):\n",
    "    topic: str  # æŠ¥å‘Šä¸»é¢˜\n",
    "    sections: list[Section]  # ç”±åè°ƒå™¨è§„åˆ’çš„æŠ¥å‘Šç« èŠ‚åˆ—è¡¨\n",
    "    completed_sections: Annotated[\n",
    "        list, operator.add\n",
    "    ]  # æ‰€æœ‰å·¥ä½œè€…å¹¶è¡Œå†™å…¥æ­¤é”®ï¼Œä½¿ç”¨ operator.add è¿›è¡Œåˆ—è¡¨è¿æ¥\n",
    "    final_report: str  # æœ€ç»ˆåˆæˆæŠ¥å‘Š\n",
    "\n",
    "\n",
    "# å·¥ä½œè€…çŠ¶æ€å®šä¹‰ï¼Œç‰¹å®šäºå·¥ä½œè€…èŠ‚ç‚¹\n",
    "class WorkerState(TypedDict):\n",
    "    section: Section\n",
    "    completed_sections: Annotated[list, operator.add] # å·¥ä½œè€…ä¹Ÿå†™å…¥å…±äº«çš„ 'completed_sections' é”®\n",
    "\n",
    "# å›¾ä¸­çš„èŠ‚ç‚¹\n",
    "def orchestrator(state: State):\n",
    "    \"\"\"åè°ƒå™¨ï¼Œä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºç”ŸæˆæŠ¥å‘Šè®¡åˆ’\"\"\"\n",
    "    # ä½¿ç”¨ planner LLM å’Œç»“æ„åŒ–è¾“å‡ºç”ŸæˆæŠ¥å‘Šç« èŠ‚è®¡åˆ’\n",
    "    report_sections = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"ç”ŸæˆæŠ¥å‘Šè®¡åˆ’ã€‚\"), # planner LLM çš„ç³»ç»Ÿæ¶ˆæ¯\n",
    "            HumanMessage(content=f\"è¿™æ˜¯æŠ¥å‘Šä¸»é¢˜ï¼š{state['topic']}\"), # åŒ…å«æŠ¥å‘Šä¸»é¢˜çš„ç”¨æˆ·è¾“å…¥æ¶ˆæ¯\n",
    "        ]\n",
    "    )\n",
    "    return {\"sections\": report_sections.sections} # è¿”å›è®¡åˆ’çš„ç« èŠ‚ï¼Œæ›´æ–°çŠ¶æ€ä¸­çš„ 'sections'\n",
    "\n",
    "def llm_call(state: WorkerState):\n",
    "    \"\"\"å·¥ä½œè€…æ ¹æ®åˆ†é…çš„ç« èŠ‚è¯¦ç»†ä¿¡æ¯ç¼–å†™æŠ¥å‘Šç« èŠ‚\"\"\"\n",
    "    # ä½¿ç”¨ LLM æ ¹æ®ç« èŠ‚åç§°å’Œæè¿°ç”ŸæˆæŠ¥å‘Šç« èŠ‚å†…å®¹\n",
    "    section = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"æŒ‰ç…§æä¾›çš„åç§°å’Œæè¿°ç¼–å†™æŠ¥å‘Šç« èŠ‚ã€‚æ¯èŠ‚ä¸åŒ…å«åºè¨€ã€‚ä½¿ç”¨ markdown æ ¼å¼ã€‚\" # å·¥ä½œè€… LLM çš„ç³»ç»Ÿæ¶ˆæ¯\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=f\"è¿™æ˜¯ç« èŠ‚åç§°ï¼š{state['section'].name} å’Œæè¿°ï¼š{state['section'].description}\" # åŒ…å«ç« èŠ‚è¯¦ç»†ä¿¡æ¯çš„ç”¨æˆ·æ¶ˆæ¯\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    # å°†ç”Ÿæˆçš„ç« èŠ‚å†…å®¹å†™å…¥å…±äº«çš„ 'completed_sections' é”®\n",
    "    return {\"completed_sections\": [section.content]}\n",
    "\n",
    "def synthesizer(state: State):\n",
    "    \"\"\"ä»å„ä¸ªç« èŠ‚è¾“å‡ºåˆæˆå®Œæ•´æŠ¥å‘Š\"\"\"\n",
    "    # ä»å…±äº«çŠ¶æ€æ£€ç´¢å·²å®Œæˆç« èŠ‚çš„åˆ—è¡¨\n",
    "    completed_sections = state[\"completed_sections\"]\n",
    "\n",
    "    # å°†å·²å®Œæˆç« èŠ‚æ ¼å¼åŒ–ä¸ºå•ä¸ªå­—ç¬¦ä¸²ä»¥ç”¨äºæœ€ç»ˆæŠ¥å‘Š\n",
    "    completed_report_sections = \"\\n\\n---\\n\\n\".join(completed_sections)\n",
    "\n",
    "    return {\"final_report\": completed_report_sections} # è¿”å›æœ€ç»ˆæŠ¥å‘Šï¼Œæ›´æ–°çŠ¶æ€ä¸­çš„ 'final_report'\n",
    "\n",
    "# æ¡ä»¶è¾¹ç¼˜å‡½æ•°ï¼Œç”¨äºå°†å·¥ä½œè€…åŠ¨æ€åˆ†é…ç»™è®¡åˆ’ä¸­çš„æ¯ä¸ªç« èŠ‚\n",
    "def assign_workers(state: State):\n",
    "    \"\"\"ä½¿ç”¨ Send API å°†å·¥ä½œè€…åˆ†é…ç»™è®¡åˆ’ä¸­çš„æ¯ä¸ªç« èŠ‚ï¼Œä»¥å®ç°åŠ¨æ€å·¥ä½œè€…åˆ›å»º\"\"\"\n",
    "    # ä½¿ç”¨ Send API ä¸ºæ¯ä¸ªç« èŠ‚åŠ¨æ€åˆ›å»ºå’Œå‘é€ 'llm_call' å·¥ä½œè€…èŠ‚ç‚¹\n",
    "    return [Send(\"llm_call\", {\"section\": s}) for s in state[\"sections\"]]\n",
    "\n",
    "# ä½¿ç”¨ StateGraph æ„å»ºåè°ƒå™¨-å·¥ä½œè€…å·¥ä½œæµ\n",
    "orchestrator_worker_builder = StateGraph(State)\n",
    "\n",
    "# å°†èŠ‚ç‚¹æ·»åŠ åˆ°å›¾ä¸­\n",
    "orchestrator_worker_builder.add_node(\"orchestrator\", orchestrator)\n",
    "orchestrator_worker_builder.add_node(\"llm_call\", llm_call) # å·¥ä½œè€…èŠ‚ç‚¹\n",
    "orchestrator_worker_builder.add_node(\"synthesizer\", synthesizer)\n",
    "\n",
    "# å®šä¹‰è¾¹ç¼˜ä»¥è¿æ¥èŠ‚ç‚¹å¹¶å»ºç«‹åè°ƒå™¨-å·¥ä½œè€…æµç¨‹\n",
    "orchestrator_worker_builder.add_edge(START, \"orchestrator\") # å¼€å§‹èŠ‚ç‚¹è¿æ¥åˆ°åè°ƒå™¨\n",
    "orchestrator_worker_builder.add_conditional_edges(\n",
    "    \"orchestrator\", assign_workers, [\"llm_call\"] # ä»åè°ƒå™¨åˆ°ä½¿ç”¨ Send API åŠ¨æ€åˆ›å»ºçš„å·¥ä½œè€…èŠ‚ç‚¹çš„æ¡ä»¶è¾¹ç¼˜\n",
    ")\n",
    "orchestrator_worker_builder.add_edge(\"llm_call\", \"synthesizer\") # å·¥ä½œè€…èŠ‚ç‚¹åœ¨å®Œæˆåè¿æ¥åˆ°åˆæˆå™¨\n",
    "orchestrator_worker_builder.add_edge(\"synthesizer\", END) # åˆæˆå™¨èŠ‚ç‚¹è¿æ¥åˆ°ç»“æŸèŠ‚ç‚¹\n",
    "\n",
    "# ç¼–è¯‘åè°ƒå™¨-å·¥ä½œè€…å·¥ä½œæµå›¾\n",
    "orchestrator_worker = orchestrator_worker_builder.compile()\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹æŠ¥å‘Šä¸»é¢˜è°ƒç”¨åè°ƒå™¨-å·¥ä½œè€…å·¥ä½œæµ\n",
    "state = orchestrator_worker.invoke({\"topic\": \"åˆ›å»ºå…³äº LLM ç¼©æ”¾å®šå¾‹çš„æŠ¥å‘Š\"})\n",
    "\n",
    "from IPython.display import Markdown\n",
    "Markdown(state[\"final_report\"]) # ä»¥ Markdown æ ¼å¼æ˜¾ç¤ºæœ€ç»ˆæŠ¥å‘Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ywhte0757f",
   "metadata": {},
   "source": [
    "**ğŸ’¡ åè°ƒå™¨-å·¥ä½œè€…çš„å…³é”®ç‰¹æ€§**ï¼š\n",
    "\n",
    "- **åŠ¨æ€ä»»åŠ¡åˆ†è§£**ï¼šåè°ƒå™¨æ ¹æ®è¾“å…¥åŠ¨æ€ç”Ÿæˆå­ä»»åŠ¡\n",
    "- **Send API**ï¼šå…è®¸è¿è¡Œæ—¶åŠ¨æ€åˆ›å»ºå·¥ä½œè€…èŠ‚ç‚¹\n",
    "- **å…±äº«çŠ¶æ€**ï¼šä½¿ç”¨ `operator.add` èšåˆå¤šä¸ªå·¥ä½œè€…çš„è¾“å‡º\n",
    "- **ç»“æ„åŒ–è¾“å‡º**ï¼šä½¿ç”¨ Pydantic æ¨¡å‹ç¡®ä¿ä»»åŠ¡è§„åˆ’çš„ä¸€è‡´æ€§\n",
    "- **çµæ´»æ‰©å±•**ï¼šå¯ä»¥æ ¹æ®ä»»åŠ¡å¤æ‚æ€§åˆ›å»ºä»»æ„æ•°é‡çš„å·¥ä½œè€…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfouwqfokhl",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 7-8ï¼šåŸºäº Functional API çš„\"åè°ƒå™¨-å·¥ä½œè€…\"å·¥ä½œæµå®ç°\n",
    "\n",
    "è®©æˆ‘ä»¬ç”¨ Functional API å®ç°ç›¸åŒçš„åè°ƒå™¨-å·¥ä½œè€…é€»è¾‘ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lbvlglvna5n",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.func import entrypoint, task\n",
    "\n",
    "\n",
    "# ç”¨äºç»“æ„åŒ–è¾“å‡ºçš„æ¨¡å¼ï¼Œç”¨äºè§„åˆ’æŠ¥å‘Šç« èŠ‚\n",
    "class Section(BaseModel):\n",
    "    name: str = Field(\n",
    "        description=\"æŠ¥å‘Šç« èŠ‚çš„åç§°\", # æŠ¥å‘Šç« èŠ‚çš„åç§°\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"æœ¬ç« èŠ‚ä¸­è¦æ¶µç›–çš„ä¸»è¦ä¸»é¢˜å’Œæ¦‚å¿µçš„ç®€è¦æ¦‚è¿°\", # ç« èŠ‚å†…å®¹çš„æè¿°\n",
    "    )\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: List[Section] = Field(\n",
    "        description=\"æŠ¥å‘Šçš„ç« èŠ‚\", # æŠ¥å‘Šç« èŠ‚åˆ—è¡¨\n",
    "    )\n",
    "\n",
    "# ç”¨äºè§„åˆ’æŠ¥å‘Šç« èŠ‚çš„å¢å¼ºå‹ LLMï¼Œä½¿ç”¨ç»“æ„åŒ–è¾“å‡º\n",
    "llm = ChatOpenAI(model=\"Qwen/Qwen2.5-7B-Instruct\")\n",
    "planner = llm.with_structured_output(Sections, method=\"function_calling\")\n",
    "\n",
    "@task\n",
    "def orchestrator(topic: str):\n",
    "    \"\"\"åè°ƒå™¨ï¼Œä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºç”ŸæˆæŠ¥å‘Šè®¡åˆ’\"\"\"\n",
    "    # ä½¿ç”¨ planner LLM å’Œç»“æ„åŒ–è¾“å‡ºç”ŸæˆæŠ¥å‘Šç« èŠ‚è®¡åˆ’\n",
    "    report_sections = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"ç”ŸæˆæŠ¥å‘Šè®¡åˆ’ã€‚\"), # planner LLM çš„ç³»ç»Ÿæ¶ˆæ¯\n",
    "            HumanMessage(content=f\"è¿™æ˜¯æŠ¥å‘Šä¸»é¢˜ï¼š{topic}\"), # åŒ…å«æŠ¥å‘Šä¸»é¢˜çš„ç”¨æˆ·æ¶ˆæ¯\n",
    "        ]\n",
    "    )\n",
    "    return report_sections.sections # è¿”å›è®¡åˆ’çš„ç« èŠ‚\n",
    "\n",
    "@task\n",
    "def llm_call(section: Section):\n",
    "    \"\"\"å·¥ä½œè€…æ ¹æ®åˆ†é…çš„ç« èŠ‚è¯¦ç»†ä¿¡æ¯ç¼–å†™æŠ¥å‘Šç« èŠ‚\"\"\"\n",
    "    # ä½¿ç”¨ LLM æ ¹æ®ç« èŠ‚åç§°å’Œæè¿°ç”ŸæˆæŠ¥å‘Šç« èŠ‚å†…å®¹\n",
    "    result = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"ç¼–å†™æŠ¥å‘Šç« èŠ‚ã€‚\"), # å·¥ä½œè€… LLM çš„ç³»ç»Ÿæ¶ˆæ¯\n",
    "            HumanMessage(\n",
    "                content=f\"è¿™æ˜¯ç« èŠ‚åç§°ï¼š{section.name} å’Œæè¿°ï¼š{section.description}\" # åŒ…å«ç« èŠ‚è¯¦ç»†ä¿¡æ¯çš„ç”¨æˆ·æ¶ˆæ¯\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return result.content # è¿”å›ç”Ÿæˆçš„ç« èŠ‚å†…å®¹\n",
    "\n",
    "@task\n",
    "def synthesizer(completed_sections: list[str]):\n",
    "    \"\"\"ä»å„ä¸ªç« èŠ‚è¾“å‡ºåˆæˆå®Œæ•´æŠ¥å‘Š\"\"\"\n",
    "    # å°†å·²å®Œæˆç« èŠ‚æ ¼å¼åŒ–ä¸ºå•ä¸ªå­—ç¬¦ä¸²ä»¥ç”¨äºæœ€ç»ˆæŠ¥å‘Š\n",
    "    final_report = \"\\n\\n---\\n\\n\".join(completed_sections)\n",
    "    return final_report # è¿”å›æœ€ç»ˆæŠ¥å‘Š\n",
    "\n",
    "# å…¥å£ç‚¹è£…é¥°å‡½æ•°å®šä¹‰åè°ƒå™¨-å·¥ä½œè€…å·¥ä½œæµ\n",
    "@entrypoint()\n",
    "def orchestrator_worker(topic: str):\n",
    "    sections = orchestrator(topic).result() # æ‰§è¡Œåè°ƒå™¨ä»»åŠ¡ä»¥è·å–æŠ¥å‘Šç« èŠ‚è®¡åˆ’\n",
    "    section_futures = [llm_call(section) for section in sections] # å¹¶è¡ŒåŠ¨æ€åˆ›å»ºå’Œæ‰§è¡Œæ¯ä¸ªç« èŠ‚çš„å·¥ä½œè€…ä»»åŠ¡\n",
    "    final_report = synthesizer(\n",
    "        [section_fut.result() for section_fut in section_futures] # åœ¨æ‰€æœ‰å·¥ä½œè€…ä»»åŠ¡å®Œæˆåæ‰§è¡Œåˆæˆå™¨ä»»åŠ¡\n",
    "    ).result() # è·å–æœ€ç»ˆåˆæˆæŠ¥å‘Š\n",
    "\n",
    "    return final_report # è¿”å›æœ€ç»ˆæŠ¥å‘Š\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹æŠ¥å‘Šä¸»é¢˜è°ƒç”¨åè°ƒå™¨-å·¥ä½œè€…å·¥ä½œæµ\n",
    "report = orchestrator_worker.invoke(\"åˆ›å»ºå…³äº LLM ç¼©æ”¾å®šå¾‹çš„æŠ¥å‘Š\")\n",
    "\n",
    "from IPython.display import Markdown\n",
    "Markdown(report) # ä»¥ Markdown æ ¼å¼æ˜¾ç¤ºæœ€ç»ˆæŠ¥å‘Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20lpfn9iizf",
   "metadata": {},
   "source": [
    "### 7.1.6 è¯„ä¼°å™¨-ä¼˜åŒ–å™¨ (Evaluator-Optimizer)\n",
    "\n",
    "\"è¯„ä¼°å™¨-ä¼˜åŒ–å™¨\"å·¥ä½œæµä½“ç°äº†ä¸€ç§è¿­ä»£æ”¹è¿›è¿‡ç¨‹ï¼Œæ¨¡ä»¿äº†äººç±»é€šå¸¸é€šè¿‡åé¦ˆå’Œä¿®è®¢æ¥æ”¹è¿›å…¶å·¥ä½œçš„æ–¹å¼ã€‚åœ¨æ­¤æ¨¡å¼ä¸­ï¼Œä¸€ä¸ªå¢å¼ºå‹ LLM è°ƒç”¨è´Ÿè´£ç”Ÿæˆåˆå§‹å“åº”ï¼Œè€Œå¦ä¸€ä¸ªå¢å¼ºå‹ LLM è°ƒç”¨ï¼ˆ\"è¯„ä¼°å™¨ (Evaluator)\"ï¼‰çš„ä»»åŠ¡æ˜¯æä¾›å¯¹æ­¤å“åº”çš„åé¦ˆã€‚\n",
    "\n",
    "å¯ä»¥é‡å¤è¿›è¡Œç”Ÿæˆã€è¯„ä¼°å’Œåé¦ˆçš„å¾ªç¯å¤šæ¬¡ï¼Œç›´åˆ°è·å¾—ä»¤äººæ»¡æ„çš„ç»“æœæˆ–è¾¾åˆ°é¢„å®šä¹‰çš„è¿­ä»£æ¬¡æ•°ã€‚å½“å­˜åœ¨å¯ä»¥æ˜ç¡®è¡¨è¾¾å’Œè¯„ä¼°çš„æ˜ç¡®è¯„ä¼°æ ‡å‡†ï¼Œå¹¶ä¸”è¿­ä»£æ”¹è¿›èƒ½å¤Ÿæ˜¾è‘—å¢åŠ è¾“å‡ºä»·å€¼æ—¶ï¼Œè¯„ä¼°å™¨-ä¼˜åŒ–å™¨å·¥ä½œæµå°¤å…¶æœ‰æ•ˆã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9djskjxb3nv",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 7-9ï¼šåŸºäº Graph API çš„\"è¯„ä¼°å™¨-ä¼˜åŒ–å™¨\"å·¥ä½œæµå®ç°\n",
    "\n",
    "è®©æˆ‘ä»¬å®ç°ä¸€ä¸ªç¬‘è¯ç”Ÿæˆå’Œæ”¹è¿›çš„è¯„ä¼°å™¨-ä¼˜åŒ–å™¨ç³»ç»Ÿï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bqncuzcyxkw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¥½çš„ï¼Œä»¥ä¸‹æ˜¯ä¸€ä¸ªå…³äºæ€§çš„è¯é¢˜ç¬‘è¯ï¼Œç»“åˆäº†æ¯”å–»å’ŒåŒå…³è¯­ï¼š\n",
      "\n",
      "ä¸ºä»€ä¹ˆå¥èº«æˆ¿çš„æƒ…ä¾£æ€»æ˜¯å¾ˆå°‘ï¼Ÿ\n",
      "\n",
      "å› ä¸ºä»–ä»¬ä¸€ç›´åœ¨â€œé”»ç‚¼æ„Ÿæƒ…â€ï¼Œä½†æ¯æ¬¡éƒ½æŠŠâ€œé‡å¿ƒâ€æ”¾åœ¨äº†ä¸¾é‡ä¸Šï¼Œæ²¡æ—¶é—´å»â€œæŠ¬å¤´â€çœ‹çœ‹å½¼æ­¤çš„å¿ƒæ„ï¼\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import TypedDict, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from llm_utils import llm\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "# ç”¨äºç»“æ„åŒ–è¾“å‡ºçš„æ¨¡å¼ï¼Œç”¨äºè¯„ä¼°ï¼Œå®šä¹‰åé¦ˆç»“æ„\n",
    "class Feedback(BaseModel):\n",
    "    grade: Literal[\"funny\", \"not funny\"] = Field(\n",
    "        description=\"åˆ¤æ–­ç¬‘è¯æ˜¯å¦æœ‰è¶£ã€‚\", # è¯„ä¼°ç­‰çº§ï¼šæœ‰è¶£æˆ–ä¸å¥½ç¬‘\n",
    "    )\n",
    "    feedback: str = Field(\n",
    "        description=\"å¦‚æœç¬‘è¯ä¸å¥½ç¬‘ï¼Œè¯·æä¾›æœ‰å…³å¦‚ä½•æ”¹è¿›å®ƒçš„åé¦ˆã€‚\", # å¦‚æœç¬‘è¯ä¸å¥½ç¬‘ï¼Œåˆ™æä¾›å…³äºå¦‚ä½•æ”¹è¿›å®ƒçš„åé¦ˆ\n",
    "    )\n",
    "\n",
    "# ç”¨äºè¯„ä¼°çš„å¢å¼ºå‹ LLMï¼Œé…ç½®ä¸ºè¾“å‡º Feedback æ¨¡å¼\n",
    "evaluator = llm.with_structured_output(Feedback)\n",
    "\n",
    "# è¯„ä¼°å™¨-ä¼˜åŒ–å™¨å·¥ä½œæµçš„å›¾çŠ¶æ€å®šä¹‰\n",
    "class State(TypedDict):\n",
    "    joke: str\n",
    "    topic: str\n",
    "    feedback: str\n",
    "    funny_or_not: str\n",
    "\n",
    "# å›¾ä¸­çš„èŠ‚ç‚¹\n",
    "def llm_call_generator(state: State):\n",
    "    \"\"\"LLM ç”Ÿæˆç¬‘è¯ï¼Œå¯èƒ½ä¼šç»“åˆä¹‹å‰è¯„ä¼°çš„åé¦ˆ\"\"\"\n",
    "    if state.get(\"feedback\"): # æ£€æŸ¥çŠ¶æ€ä¸­æ˜¯å¦å­˜åœ¨åé¦ˆï¼ŒæŒ‡ç¤ºä¹‹å‰çš„è¯„ä¼°\n",
    "        msg = llm.invoke(\n",
    "            f\"å†™ä¸€ä¸ªå…³äº {state['topic']} çš„ç¬‘è¯ï¼Œä½†è¦è€ƒè™‘åé¦ˆï¼š{state['feedback']}\" # è°ƒç”¨ LLM ç”Ÿæˆç¬‘è¯ï¼Œç»“åˆåé¦ˆ\n",
    "        )\n",
    "    else:\n",
    "        msg = llm.invoke(f\"å†™ä¸€ä¸ªå…³äº {state['topic']} çš„ç¬‘è¯\") # è°ƒç”¨ LLM ç”Ÿæˆåˆå§‹ç¬‘è¯ï¼Œä¸å¸¦åé¦ˆ\n",
    "    return {\"joke\": msg.content} # è¿”å›ç”Ÿæˆçš„ç¬‘è¯ï¼Œæ›´æ–°çŠ¶æ€ä¸­çš„ 'joke'\n",
    "\n",
    "def llm_call_evaluator(state: State):\n",
    "    \"\"\"LLM ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºè¯„ä¼°ç”Ÿæˆçš„ç¬‘è¯\"\"\"\n",
    "    grade = evaluator.invoke(f\"è¯„ä»·ç¬‘è¯ {state['joke']}\") # è°ƒç”¨è¯„ä¼°å™¨ LLM æ¥è¯„ä»·ç¬‘è¯\n",
    "    return {\"funny_or_not\": grade.grade, \"feedback\": grade.feedback} # è¿”å›è¯„ä¼°ç­‰çº§å’Œåé¦ˆï¼Œæ›´æ–°çŠ¶æ€ä¸­çš„ 'funny_or_not' å’Œ 'feedback'\n",
    "\n",
    "# æ¡ä»¶è¾¹ç¼˜å‡½æ•°ï¼Œç”¨äºæ ¹æ®è¯„ä¼°ç»“æœè¿›è¡Œè·¯ç”±ï¼Œåˆ›å»ºåé¦ˆå¾ªç¯\n",
    "def route_joke(state: State):\n",
    "    \"\"\"æ ¹æ®è¯„ä¼°å™¨çš„åé¦ˆï¼Œè·¯ç”±å›ç¬‘è¯ç”Ÿæˆå™¨æˆ–ç»“æŸ\"\"\"\n",
    "    if state[\"funny_or_not\"] == \"funny\": # æ£€æŸ¥ç¬‘è¯æ˜¯å¦è¢«è¯„ä¼°ä¸ºæœ‰è¶£\n",
    "        return \"Accepted\" # å¦‚æœç¬‘è¯è¢«æ¥å—ï¼Œåˆ™è·¯ç”±åˆ°ç»“æŸ\n",
    "    elif state[\"funny_or_not\"] == \"not funny\": # æ£€æŸ¥ç¬‘è¯æ˜¯å¦è¢«è¯„ä¼°ä¸ºä¸å¥½ç¬‘\n",
    "        return \"Rejected + Feedback\" # å¦‚æœç¬‘è¯è¢«æ‹’ç»ï¼Œåˆ™è·¯ç”±å›ç”Ÿæˆå™¨ä»¥ç»“åˆåé¦ˆ\n",
    "\n",
    "# æ„å»ºè¯„ä¼°å™¨-ä¼˜åŒ–å™¨å·¥ä½œæµï¼Œä½¿ç”¨ StateGraph\n",
    "optimizer_builder = StateGraph(State)\n",
    "\n",
    "# å°†èŠ‚ç‚¹æ·»åŠ åˆ°å›¾ä¸­\n",
    "optimizer_builder.add_node(\"llm_call_generator\", llm_call_generator)\n",
    "optimizer_builder.add_node(\"llm_call_evaluator\", llm_call_evaluator)\n",
    "\n",
    "# å®šä¹‰è¾¹ç¼˜ä»¥è¿æ¥èŠ‚ç‚¹å¹¶å»ºç«‹åé¦ˆå¾ªç¯\n",
    "optimizer_builder.add_edge(START, \"llm_call_generator\") # å¼€å§‹èŠ‚ç‚¹è¿æ¥åˆ°ç¬‘è¯ç”Ÿæˆå™¨\n",
    "optimizer_builder.add_edge(\"llm_call_generator\", \"llm_call_evaluator\") # ç”Ÿæˆå™¨èŠ‚ç‚¹è¿æ¥åˆ°è¯„ä¼°å™¨èŠ‚ç‚¹\n",
    "optimizer_builder.add_conditional_edges(\n",
    "    \"llm_call_evaluator\",\n",
    "    route_joke,\n",
    "    {  # ç”± route_joke è¿”å›çš„åç§°ï¼šè¦è®¿é—®çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„åç§°\n",
    "        \"Accepted\": END, # å¦‚æœç¬‘è¯è¢«æ¥å—ï¼Œåˆ™è·¯ç”±åˆ°ç»“æŸ\n",
    "        \"Rejected + Feedback\": \"llm_call_generator\", # å¦‚æœç¬‘è¯è¢«æ‹’ç»ï¼Œåˆ™è·¯ç”±å›ç”Ÿæˆå™¨ï¼Œåˆ›å»ºåé¦ˆå¾ªç¯\n",
    "    },\n",
    ")\n",
    "\n",
    "# ç¼–è¯‘è¯„ä¼°å™¨-ä¼˜åŒ–å™¨å·¥ä½œæµå›¾\n",
    "optimizer_workflow = optimizer_builder.compile()\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹ä¸»é¢˜è°ƒç”¨è¯„ä¼°å™¨-ä¼˜åŒ–å™¨å·¥ä½œæµ\n",
    "state = optimizer_workflow.invoke({\"topic\": \"sex\"})\n",
    "print(state[\"joke\"]) \n",
    "\n",
    "# ä¿å­˜ Mermaid ç”Ÿæˆçš„ PNG å›¾åƒåˆ°æ–‡ä»¶\n",
    "# from draw import save_graph_as_png\n",
    "# save_graph_as_png(optimizer_workflow, \"./graphs/c7/evaluator_optimizer_workflow.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98i0hb88t8p",
   "metadata": {},
   "source": [
    "**ğŸ’¡ è¯„ä¼°å™¨-ä¼˜åŒ–å™¨çš„å…³é”®æœºåˆ¶**ï¼š\n",
    "\n",
    "- **è¿­ä»£æ”¹è¿›**ï¼šé€šè¿‡åé¦ˆå¾ªç¯ä¸æ–­ä¼˜åŒ–è¾“å‡ºè´¨é‡\n",
    "- **ç»“æ„åŒ–è¯„ä¼°**ï¼šä½¿ç”¨ Pydantic æ¨¡å‹ç¡®ä¿è¯„ä¼°çš„ä¸€è‡´æ€§\n",
    "- **æ¡ä»¶è·¯ç”±**ï¼šæ ¹æ®è¯„ä¼°ç»“æœå†³å®šæ˜¯å¦ç»§ç»­ä¼˜åŒ–\n",
    "- **çŠ¶æ€è®°å¿†**ï¼šä¿æŒåé¦ˆä¿¡æ¯ä»¥æŒ‡å¯¼åç»­æ”¹è¿›\n",
    "- **è´¨é‡é—¨æ§**ï¼šåªæœ‰è¾¾åˆ°æ ‡å‡†çš„è¾“å‡ºæ‰ä¼šè¢«æ¥å—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xz8hbmaru4",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 7-10ï¼šåŸºäº Functional API çš„\"è¯„ä¼°å™¨-ä¼˜åŒ–å™¨\"å·¥ä½œæµå®ç°\n",
    "\n",
    "è®©æˆ‘ä»¬ç”¨ Functional API å®ç°ç›¸åŒçš„è¯„ä¼°å™¨-ä¼˜åŒ–å™¨é€»è¾‘ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ta9y4a0uff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.func import entrypoint, task\n",
    "\n",
    "\n",
    "# ç”¨äºç»“æ„åŒ–è¾“å‡ºçš„æ¨¡å¼ï¼Œç”¨äºè¯„ä¼°ï¼Œå®šä¹‰åé¦ˆç»“æ„\n",
    "class Feedback(BaseModel):\n",
    "    grade: Literal[\"funny\", \"not funny\"] = Field(\n",
    "        description=\"åˆ¤æ–­ç¬‘è¯æ˜¯å¦æœ‰è¶£ã€‚\", # è¯„ä¼°ç­‰çº§ï¼šæœ‰è¶£æˆ–ä¸å¥½ç¬‘\n",
    "    )\n",
    "    feedback: str = Field(\n",
    "        description=\"å¦‚æœç¬‘è¯ä¸å¥½ç¬‘ï¼Œè¯·æä¾›æœ‰å…³å¦‚ä½•æ”¹è¿›å®ƒçš„åé¦ˆã€‚\", # å¦‚æœç¬‘è¯ä¸å¥½ç¬‘ï¼Œåˆ™æä¾›å…³äºå¦‚ä½•æ”¹è¿›å®ƒçš„åé¦ˆ\n",
    "    )\n",
    "\n",
    "# ç”¨äºè¯„ä¼°çš„å¢å¼ºå‹ LLMï¼Œä½¿ç”¨ç»“æ„åŒ–è¾“å‡º\n",
    "evaluator = llm.with_structured_output(Feedback, method=\"function_calling\")\n",
    "\n",
    "# å·¥ä½œæµä¸­çš„èŠ‚ç‚¹ï¼Œå®šä¹‰ä¸ºä»»åŠ¡\n",
    "@task\n",
    "def llm_call_generator(topic: str, feedback: str = None):\n",
    "    \"\"\"LLM ç”Ÿæˆç¬‘è¯ï¼Œå¯èƒ½ä¼šç»“åˆåé¦ˆ\"\"\"\n",
    "    if feedback: # æ£€æŸ¥æ˜¯å¦æä¾›äº†åé¦ˆ\n",
    "        msg = llm.invoke(\n",
    "            f\"å†™ä¸€ä¸ªå…³äº {topic} çš„ç¬‘è¯ï¼Œä½†è¦è€ƒè™‘åé¦ˆï¼š{feedback}\" # è°ƒç”¨ LLM ç”Ÿæˆç¬‘è¯ï¼Œç»“åˆåé¦ˆ\n",
    "        )\n",
    "    else:\n",
    "        msg = llm.invoke(f\"å†™ä¸€ä¸ªå…³äº {topic} çš„ç¬‘è¯\") # è°ƒç”¨ LLM ç”Ÿæˆåˆå§‹ç¬‘è¯ï¼Œä¸å¸¦åé¦ˆ\n",
    "    return msg.content # è¿”å›ç”Ÿæˆçš„ç¬‘è¯\n",
    "\n",
    "@task\n",
    "def llm_call_evaluator(joke: str):\n",
    "    \"\"\"LLM ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºè¯„ä¼°ç”Ÿæˆçš„ç¬‘è¯\"\"\"\n",
    "    feedback = evaluator.invoke(f\"è¯„ä»·ç¬‘è¯ {joke}\") # è°ƒç”¨è¯„ä¼°å™¨ LLM æ¥è¯„ä»·ç¬‘è¯\n",
    "    return feedback # è¿”å›è¯„ä¼°åé¦ˆ\n",
    "\n",
    "# å…¥å£ç‚¹è£…é¥°å‡½æ•°å®šä¹‰è¯„ä¼°å™¨-ä¼˜åŒ–å™¨å·¥ä½œæµ\n",
    "@entrypoint()\n",
    "def optimizer_workflow(topic: str):\n",
    "    feedback = None # å°†åé¦ˆåˆå§‹åŒ–ä¸º Noneï¼Œç”¨äºç¬¬ä¸€æ¬¡è¿­ä»£\n",
    "    max_iterations = 3 # è®¾ç½®æœ€å¤§è¿­ä»£æ¬¡æ•°ä»¥é¿å…æ— é™å¾ªç¯\n",
    "    iteration = 0\n",
    "    \n",
    "    while iteration < max_iterations: # è¿­ä»£åé¦ˆå¾ªç¯çš„å¼€å§‹\n",
    "        joke = llm_call_generator(topic, feedback).result() # æ‰§è¡Œç”Ÿæˆå™¨ä»»åŠ¡ä»¥åˆ›å»ºç¬‘è¯\n",
    "        evaluation = llm_call_evaluator(joke).result() # æ‰§è¡Œè¯„ä¼°å™¨ä»»åŠ¡ä»¥è¯„ä»·ç¬‘è¯å¹¶è·å–åé¦ˆ\n",
    "        \n",
    "        if evaluation.grade == \"funny\": # æ£€æŸ¥ç¬‘è¯æ˜¯å¦è¢«è¯„ä¼°ä¸ºæœ‰è¶£\n",
    "            return joke # å¦‚æœç¬‘è¯æœ‰è¶£ï¼Œåˆ™è¿”å›ç¬‘è¯\n",
    "        \n",
    "        feedback = evaluation.feedback # æ›´æ–°åé¦ˆç”¨äºä¸‹ä¸€æ¬¡è¿­ä»£\n",
    "        iteration += 1\n",
    "        \n",
    "    return joke # å¦‚æœè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œè¿”å›æœ€åçš„ç¬‘è¯\n",
    "\n",
    "# è°ƒç”¨è¯„ä¼°å™¨-ä¼˜åŒ–å™¨å·¥ä½œæµ\n",
    "result = optimizer_workflow.invoke(\"Cats\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jlnhvab1dfl",
   "metadata": {},
   "source": [
    "## 7.2 LangGraph ä¸­çš„å¤šæ™ºèƒ½ä½“æ¶æ„\n",
    "\n",
    "éšç€æˆ‘ä»¬åœ¨æ„å»º AI æ™ºèƒ½ä½“æ–¹é¢ä¸æ–­è¿›æ­¥ï¼Œæˆ‘ä»¬æ—¨åœ¨è§£å†³çš„ä»»åŠ¡çš„å¤æ‚æ€§é€šå¸¸éœ€è¦è¶…è¶Šå•ä¸€çš„ã€å•ç‰‡å¼çš„æ™ºèƒ½ä½“è®¾è®¡ã€‚å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æ¦‚å¿µå› æ­¤å˜å¾—éå¸¸å®è´µã€‚æˆ‘ä»¬ä¸å†ä¾èµ–å•ä¸ªæ™ºèƒ½ä½“æ¥å¤„ç†æ‰€æœ‰äº‹æƒ…ï¼Œè€Œæ˜¯å°†æˆ‘ä»¬çš„ AI åº”ç”¨ç¨‹åºåˆ†è§£ä¸ºä¸€ç»„æ›´å°ã€æ›´ä¸“æ³¨çš„æ™ºèƒ½ä½“ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“éƒ½å…·æœ‰ç‰¹å®šçš„èŒè´£å’Œä¸“ä¸šçŸ¥è¯†ã€‚\n",
    "\n",
    "å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºï¼š\n",
    "\n",
    "- **æ¨¡å—åŒ–**ï¼šå°†å¤æ‚çš„æ™ºèƒ½ä½“åˆ†è§£ä¸ºæ›´å°çš„ã€ç‹¬ç«‹çš„æ™ºèƒ½ä½“ç®€åŒ–äº†å¼€å‘ã€æµ‹è¯•å’Œç»´æŠ¤\n",
    "- **ä¸“ä¸šåŒ–**ï¼šä½¿æˆ‘ä»¬èƒ½å¤Ÿåˆ›å»ºé’ˆå¯¹ç‰¹å®šé¢†åŸŸæˆ–ä»»åŠ¡é‡èº«å®šåˆ¶çš„ä¸“å®¶æ™ºèƒ½ä½“\n",
    "- **å—æ§é€šä¿¡**ï¼šå…è®¸å¼€å‘äººå‘˜æ˜¾å¼å®šä¹‰å’Œç®¡ç†æ™ºèƒ½ä½“å¦‚ä½•é€šä¿¡ã€äº¤æ¢ä¿¡æ¯ä»¥åŠåè°ƒå…¶è¡ŒåŠ¨\n",
    "\n",
    "LangGraph ä¸ºæ„å»ºå’Œç¼–æ’å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæä¾›äº†å¼ºå¤§çš„æ¡†æ¶ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢ç´¢å‡ ç§å…³é”®å¤šæ™ºèƒ½ä½“æ¶æ„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9mbea871jaq",
   "metadata": {},
   "source": [
    "### 7.2.1 ä¸»ç®¡æ¶æ„\n",
    "\n",
    "ä¸»ç®¡ï¼ˆSupervisorï¼‰æ¶æ„æ˜¯å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„æ ¸å¿ƒæ¨¡å¼ï¼Œå½“éœ€è¦æ˜ç¡®çš„ç¼–æ’ç‚¹æ¥ç®¡ç†å’ŒæŒ‡å¯¼ä»»åŠ¡æµæ—¶ï¼Œå®ƒå°¤å…¶æœ‰æ•ˆã€‚åœ¨è¿™ç§æ¶æ„ä¸­ï¼ŒæŒ‡å®šçš„ä¸»ç®¡æ™ºèƒ½ä½“å……å½“ä¸­å¤®åè°ƒå‘˜çš„è§’è‰²ï¼Œç›‘ç£å’ŒæŒ‡å¯¼å¤šä¸ªä¸“ä¸šæ™ºèƒ½ä½“çš„æ´»åŠ¨ã€‚\n",
    "\n",
    "LangChain å›¢é˜Ÿæ–°æ¨å‡ºçš„ LangGraph Supervisor ç±»åº“æä¾›äº†ä¸€ç§ç®€åŒ–çš„æ–¹å¼æ¥åˆ›å»ºåŸºäºä¸»ç®¡çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bs3i020xjc",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 7-11ï¼šä½¿ç”¨ LangGraph Supervisor ç±»åº“æ­å»ºå…·æœ‰æ•°å­¦å’Œç ”ç©¶æ™ºèƒ½ä½“çš„ä¸»ç®¡æ¶æ„\n",
    "\n",
    "é¦–å…ˆå®‰è£…å¿…è¦çš„åº“ï¼Œç„¶åæ„å»ºä¸€ä¸ªåŒ…å«æ•°å­¦ä¸“å®¶å’Œç ”ç©¶ä¸“å®¶çš„ä¸»ç®¡ç³»ç»Ÿï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wo6v33fpkkj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¦–å…ˆå®‰è£… langgraph-supervisor åº“ï¼ˆå¦‚æœå°šæœªå®‰è£…ï¼‰\n",
    "# !pip install langgraph-supervisor\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from llm_utils import llm\n",
    "\n",
    "# 1. ä¸ºä¸“ä¸šæ™ºèƒ½ä½“å®šä¹‰å·¥å…·ï¼š\n",
    "# å®šä¹‰è¡¨ç¤ºæ¯ä¸ªä¸“ä¸šæ™ºèƒ½ä½“å·¥å…·çš„å‡½æ•°ã€‚\n",
    "# 'add' å’Œ 'multiply' ç”¨äºæ•°å­¦æ™ºèƒ½ä½“ï¼Œ'web_search' ç”¨äºç ”ç©¶æ™ºèƒ½ä½“ã€‚\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"æ·»åŠ ä¸¤ä¸ªæ•°å­—ã€‚\"\"\"\n",
    "    return a + b\n",
    "\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"ä¹˜ä¸¤ä¸ªæ•°å­—ã€‚\"\"\"\n",
    "    return a * b\n",
    "\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"åœ¨ç½‘ç»œä¸Šæœç´¢ä¿¡æ¯ã€‚\"\"\"\n",
    "    return (\n",
    "        \"ä»¥ä¸‹æ˜¯ FAANG å…¬å¸ 2024 å¹´çš„å‘˜å·¥äººæ•°ï¼š\\n\"\n",
    "        \"1. **Facebook (Meta)**: 67,317 åå‘˜å·¥ã€‚\\n\"\n",
    "        \"2. **Apple**: 164,000 åå‘˜å·¥ã€‚\\n\"\n",
    "        \"3. **Amazon**: 1,551,000 åå‘˜å·¥ã€‚\\n\"\n",
    "        \"4. **Netflix**: 14,000 åå‘˜å·¥ã€‚\\n\"\n",
    "        \"5. **Google (Alphabet)**: 181,269 åå‘˜å·¥ã€‚\"\n",
    "    )\n",
    "\n",
    "# 2. ä½¿ç”¨ create_react_agent åˆ›å»ºä¸“ä¸šæ™ºèƒ½ä½“ï¼š\n",
    "# ä½¿ç”¨ LangGraph çš„é¢„æ„å»º create_react_agent åˆ›å»ºæ¯ä¸ªä¸“ä¸šæ™ºèƒ½ä½“ã€‚\n",
    "# æ¯ä¸ªæ™ºèƒ½ä½“éƒ½é…ç½®äº†ç‰¹å®šçš„æ¨¡å‹ã€å·¥å…·ã€åç§°å’Œæç¤ºã€‚\n",
    "math_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[add, multiply], # æ•°å­¦æ™ºèƒ½ä½“çš„å·¥å…·æ˜¯ 'add' å’Œ 'multiply'\n",
    "    name=\"math_expert\", # æ ‡è¯†æ•°å­¦æ™ºèƒ½ä½“çš„åç§°\n",
    "    prompt=\"ä½ æ˜¯ä¸€åæ•°å­¦ä¸“å®¶ã€‚å§‹ç»ˆä¸€æ¬¡ä½¿ç”¨ä¸€ä¸ªå·¥å…·ã€‚\" # æŒ‡å¯¼æ•°å­¦æ™ºèƒ½ä½“è¡Œä¸ºçš„æç¤º\n",
    ")\n",
    "\n",
    "research_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[web_search], # ç ”ç©¶æ™ºèƒ½ä½“çš„å·¥å…·æ˜¯ 'web_search'\n",
    "    name=\"research_expert\", # æ ‡è¯†ç ”ç©¶æ™ºèƒ½ä½“çš„åç§°\n",
    "    prompt=\"ä½ æ˜¯ä¸€åä¸–ç•Œä¸€æµçš„ç ”ç©¶å‘˜ï¼Œå¯ä»¥è®¿é—®ç½‘ç»œæœç´¢ã€‚ä¸è¦åšä»»ä½•æ•°å­¦è¿ç®—ã€‚\" # æŒ‡å¯¼ç ”ç©¶æ™ºèƒ½ä½“è¡Œä¸ºçš„æç¤º\n",
    ")\n",
    "\n",
    "# 3. ä½¿ç”¨ create_supervisor åˆ›å»ºä¸»ç®¡å·¥ä½œæµï¼š\n",
    "# ä½¿ç”¨ LangGraph Supervisor çš„ create_supervisor åˆ›å»ºä¸»ç®¡å·¥ä½œæµã€‚\n",
    "# ä¼ é€’ä¸“ä¸šæ™ºèƒ½ä½“åˆ—è¡¨ã€ä¸»ç®¡æ¨¡å‹ä»¥åŠä¸»ç®¡çš„æç¤ºã€‚\n",
    "workflow = create_supervisor(\n",
    "    [research_agent, math_agent], # ç”±ä¸»ç®¡ç®¡ç†çš„ä¸“ä¸šæ™ºèƒ½ä½“åˆ—è¡¨\n",
    "    model=llm, # ä¸»ç®¡æ™ºèƒ½ä½“çš„æ¨¡å‹\n",
    "    prompt=\"ä½ æ˜¯ä¸€åå›¢é˜Ÿä¸»ç®¡ï¼Œç®¡ç†ç€ä¸€åç ”ç©¶ä¸“å®¶å’Œä¸€åæ•°å­¦ä¸“å®¶ã€‚ç ”ç©¶ä¸“å®¶èƒ½å¤Ÿåˆ©ç”¨ç½‘ç»œæœç´¢å·¥å…·è¿›è¡ŒæŸ¥è¯¢ã€‚\", # æŒ‡å¯¼ä¸»ç®¡è¡Œä¸ºçš„æç¤º\n",
    ")\n",
    "\n",
    "# 4. ç¼–è¯‘å¹¶è¿è¡Œå·¥ä½œæµï¼š\n",
    "# å°†å·¥ä½œæµç¼–è¯‘ä¸º LangGraph åº”ç”¨ç¨‹åºï¼Œå¹¶ä½¿ç”¨ç”¨æˆ·æ¶ˆæ¯è°ƒç”¨å®ƒã€‚\n",
    "app = workflow.compile() # å°†å·¥ä½œæµç¼–è¯‘ä¸ºå¯æ‰§è¡Œçš„ LangGraph åº”ç”¨ç¨‹åº\n",
    "result = app.invoke({ # ä½¿ç”¨ç”¨æˆ·æ¶ˆæ¯è°ƒç”¨å·²ç¼–è¯‘çš„åº”ç”¨ç¨‹åº\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"2024 å¹´ FAANG å…¬å¸çš„æ€»å‘˜å·¥äººæ•°æ˜¯å¤šå°‘ï¼Ÿ\" # ç”¨æˆ·å…³äº FAANG å…¬å¸å‘˜å·¥äººæ•°çš„æŸ¥è¯¢\n",
    "        }\n",
    "    ]\n",
    "})\n",
    "print(result[\"messages\"][-1].content)\n",
    "# ä¿å­˜å›¾\n",
    "from draw import save_graph_as_png\n",
    "save_graph_as_png(app, \"./graphs/c7/supervisor_workflow.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6hq5q5mc0ad",
   "metadata": {},
   "source": [
    "### 7.2.2 å±‚æ¬¡åŒ–æ¶æ„ (Hierarchical Architecture)\n",
    "\n",
    "å±‚æ¬¡åŒ–æ¶æ„é€šè¿‡å¤šå±‚æ¬¡çš„æ™ºèƒ½ä½“ç»„ç»‡æ¥å¤„ç†å¤æ‚ä»»åŠ¡ã€‚æ¯å±‚éƒ½æœ‰ç‰¹å®šçš„èŒè´£ï¼Œä¸Šå±‚æ™ºèƒ½ä½“è´Ÿè´£é«˜çº§å†³ç­–ï¼Œä¸‹å±‚æ™ºèƒ½ä½“æ‰§è¡Œå…·ä½“ä»»åŠ¡ã€‚\n",
    "\n",
    "**æ ¸å¿ƒç‰¹ç‚¹ï¼š**\n",
    "- å¤šå±‚æ¬¡ç»„ç»‡ç»“æ„\n",
    "- æ¸…æ™°çš„èŒè´£åˆ†å·¥\n",
    "- å±‚æ¬¡é—´çš„é€šä¿¡æœºåˆ¶\n",
    "- é€’å½’çš„ä»»åŠ¡åˆ†è§£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wcc56l188xg",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 7-12ï¼šå…·æœ‰ç ”ç©¶å’Œå†™ä½œå›¢é˜Ÿçš„åˆ†å±‚ä¸»ç®¡ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3gqhtd6h1es",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from llm_utils import llm as model\n",
    "\n",
    "# --- 1. å®šä¹‰ç ”ç©¶å›¢é˜Ÿæ™ºèƒ½ä½“å’Œä¸»ç®¡ ---\n",
    "# å®šä¹‰ç ”ç©¶å›¢é˜Ÿï¼ˆmath_expert å’Œ research_expertï¼‰çš„å·¥å…·å’Œæ™ºèƒ½ä½“\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"æ·»åŠ ä¸¤ä¸ªæ•°å­—ã€‚\"\"\"\n",
    "    return a + b\n",
    "\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"ä¹˜ä¸¤ä¸ªæ•°å­—ã€‚\"\"\"\n",
    "    return a * b\n",
    "\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"åœ¨ç½‘ç»œä¸Šæœç´¢ä¿¡æ¯ã€‚\"\"\"\n",
    "    return (\n",
    "        \"ä»¥ä¸‹æ˜¯ FAANG å…¬å¸ 2024 å¹´çš„å‘˜å·¥äººæ•°ï¼š\\n\"\n",
    "        \"1. **Facebook (Meta)**: 67,317 åå‘˜å·¥ã€‚\\n\"\n",
    "        \"2. **Apple**: 164,000 åå‘˜å·¥ã€‚\\n\"\n",
    "        \"3. **Amazon**: 1,551,000 åå‘˜å·¥ã€‚\\n\"\n",
    "        \"4. **Netflix**: 14,000 åå‘˜å·¥ã€‚\\n\"\n",
    "        \"5. **Google (Alphabet)**: 181,269 åå‘˜å·¥ã€‚\"\n",
    "    )\n",
    "\n",
    "math_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[add, multiply],\n",
    "    name=\"math_expert\",\n",
    "    prompt=\"ä½ æ˜¯ä¸€åæ•°å­¦ä¸“å®¶ã€‚\"\n",
    ")\n",
    "\n",
    "research_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[web_search],\n",
    "    name=\"research_expert\",\n",
    "    prompt=\"ä½ æ˜¯ä¸€åä¸–ç•Œä¸€æµçš„ç ”ç©¶å‘˜ï¼Œå¯ä»¥è®¿é—®ç½‘ç»œæœç´¢ã€‚ä¸è¦åšä»»ä½•æ•°å­¦è¿ç®—ã€‚\"\n",
    ")\n",
    "\n",
    "research_team_supervisor = create_supervisor(\n",
    "    [research_agent, math_agent], # ç ”ç©¶å›¢é˜Ÿå†…çš„æ™ºèƒ½ä½“\n",
    "    model=model,\n",
    "    prompt=\"ä½ æ­£åœ¨ç®¡ç†ä¸€ä¸ªç ”ç©¶å›¢é˜Ÿï¼Œè¯¥å›¢é˜Ÿç”±ç ”ç©¶å’Œæ•°å­¦ä¸“å®¶ç»„æˆã€‚ç ”ç©¶ä¸“å®¶èƒ½å¤Ÿåˆ©ç”¨ç½‘ç»œæœç´¢å·¥å…·è¿›è¡ŒæŸ¥è¯¢ã€‚\", # ç ”ç©¶å›¢é˜Ÿä¸»ç®¡çš„æç¤º\n",
    ")\n",
    "research_team = research_team_supervisor.compile(name=\"research_team\") # ç¼–è¯‘ç ”ç©¶å›¢é˜Ÿå·¥ä½œæµå¹¶å‘½å\n",
    "\n",
    "# --- 2. å®šä¹‰å†™ä½œå›¢é˜Ÿæ™ºèƒ½ä½“å’Œä¸»ç®¡ ---\n",
    "# å®šä¹‰å†™ä½œå›¢é˜Ÿï¼ˆwriting_expert å’Œ publishing_expertï¼‰çš„å·¥å…·å’Œæ™ºèƒ½ä½“\n",
    "def write_report(topic: str) -> str:\n",
    "    \"\"\"æ’°å†™å…³äºç»™å®šä¸»é¢˜çš„æŠ¥å‘Šã€‚\"\"\"\n",
    "    return f\"å…³äº {topic} çš„æŠ¥å‘Šï¼š... ï¼ˆæŠ¥å‘Šçš„è¯¦ç»†å†…å®¹ï¼‰\"\n",
    "\n",
    "def publish_report(report: str) -> str:\n",
    "    \"\"\"å‘å¸ƒæŠ¥å‘Šã€‚\"\"\"\n",
    "    return f\"æŠ¥å‘Šå·²å‘å¸ƒï¼š{report}\"\n",
    "\n",
    "writing_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[write_report],\n",
    "    name=\"writing_expert\",\n",
    "    prompt=\"ä½ æ˜¯ä¸€åå†™ä½œä¸“å®¶ã€‚\"\n",
    ")\n",
    "\n",
    "publishing_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[publish_report],\n",
    "    name=\"publishing_expert\",\n",
    "    prompt=\"ä½ æ˜¯ä¸€åå‡ºç‰ˆä¸“å®¶ã€‚\"\n",
    ")\n",
    "\n",
    "writing_team_supervisor = create_supervisor(\n",
    "    [writing_agent, publishing_agent], # å†™ä½œå›¢é˜Ÿå†…çš„æ™ºèƒ½ä½“\n",
    "    model=model,\n",
    "    prompt=\"ä½ æ­£åœ¨ç®¡ç†ä¸€ä¸ªå†™ä½œå›¢é˜Ÿï¼Œè¯¥å›¢é˜Ÿç”±å†™ä½œå’Œå‡ºç‰ˆä¸“å®¶ç»„æˆã€‚\", # å†™ä½œå›¢é˜Ÿä¸»ç®¡çš„æç¤º\n",
    ")\n",
    "writing_team = writing_team_supervisor.compile(name=\"writing_team\") # ç¼–è¯‘å†™ä½œå›¢é˜Ÿå·¥ä½œæµå¹¶å‘½å\n",
    "\n",
    "# --- 3. å®šä¹‰é¡¶å±‚ä¸»ç®¡ ---\n",
    "# å®šä¹‰é¡¶å±‚ä¸»ç®¡ä»¥ç®¡ç†ç ”ç©¶å›¢é˜Ÿå’Œå†™ä½œå›¢é˜Ÿ\n",
    "top_level_supervisor_agent = create_supervisor(\n",
    "    [research_team, writing_team], # ä¼ é€’å·²ç¼–è¯‘çš„ç ”ç©¶å’Œå†™ä½œå›¢é˜Ÿå·¥ä½œæµä½œä¸ºæ™ºèƒ½ä½“\n",
    "    model=model,\n",
    "    prompt=\"ä½ æ˜¯ä¸€åé¡¶å±‚ä¸»ç®¡ï¼Œç®¡ç†ç€ç ”ç©¶å›¢é˜Ÿå’Œå†™ä½œå›¢é˜Ÿã€‚\", # é¡¶å±‚ä¸»ç®¡çš„æç¤º\n",
    ")\n",
    "top_level_supervisor = top_level_supervisor_agent.compile(name=\"top_level_supervisor\") # ç¼–è¯‘é¡¶å±‚ä¸»ç®¡å·¥ä½œæµå¹¶å‘½å\n",
    "\n",
    "# --- 4. è°ƒç”¨é¡¶å±‚ä¸»ç®¡ ---\n",
    "# ä½¿ç”¨ç”¨æˆ·æŸ¥è¯¢è°ƒç”¨é¡¶å±‚ä¸»ç®¡\n",
    "result = top_level_supervisor.invoke({\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"2024 å¹´ FAANG å…¬å¸çš„æ€»å‘˜å·¥äººæ•°æ˜¯å¤šå°‘ï¼Ÿ\" # ç”¨æˆ·æŸ¥è¯¢\n",
    "        }\n",
    "    ]\n",
    "})\n",
    "print(result[\"messages\"][-1].content)\n",
    "# ä¿å­˜å›¾\n",
    "from draw import save_graph_as_png\n",
    "save_graph_as_png(top_level_supervisor, \"./graphs/c7/multi_agent_hierarchy_workflow.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hi459ml977",
   "metadata": {},
   "source": [
    "**ğŸ’¡ å±‚æ¬¡åŒ–æ¶æ„å…³é”®ç‰¹æ€§**ï¼š\n",
    "\n",
    "- **æ¸…æ™°çš„å±‚æ¬¡ç»“æ„**ï¼šé«˜çº§ç®¡ç†å±‚ã€ä¸­çº§ç®¡ç†å±‚ã€æ‰§è¡Œå±‚å„å¸å…¶èŒ\n",
    "- **è‡ªä¸Šè€Œä¸‹çš„ä»»åŠ¡åˆ†è§£**ï¼šä»é«˜çº§è®¡åˆ’åˆ°è¯¦ç»†ä»»åŠ¡å†åˆ°å…·ä½“æ‰§è¡Œ\n",
    "- **åŠ¨æ€å·¥ä½œè€…åˆ†é…**ï¼šæ ¹æ®è§„åˆ’ç»“æœåŠ¨æ€åˆ›å»ºå·¥ä½œè€…èŠ‚ç‚¹\n",
    "- **å±‚æ¬¡é—´é€šä¿¡**ï¼šæ¯å±‚éƒ½æœ‰æ˜ç¡®çš„è¾“å…¥è¾“å‡ºæ¥å£\n",
    "- **é€’å½’ç®¡ç†ç»“æ„**ï¼šå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•ä¸ºæ›´æ·±å±‚æ¬¡çš„ç®¡ç†ç»“æ„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tqxdlfk4yxg",
   "metadata": {},
   "source": [
    "### 7.2.3 ç½‘ç»œæ¶æ„ (Network Architecture)\n",
    "\n",
    "ç½‘ç»œæ¶æ„ï¼ˆä¹Ÿç§°ä¸ºç¾¤ä½“æ¶æ„ Swarm Architectureï¼‰å…è®¸æ™ºèƒ½ä½“ä¹‹é—´è¿›è¡Œæ›´çµæ´»ã€è‡ªç»„ç»‡çš„äº¤äº’ã€‚åœ¨è¿™ç§æ¶æ„ä¸­ï¼Œæ™ºèƒ½ä½“å¯ä»¥ç›´æ¥ç›¸äº’é€šä¿¡ï¼Œå½¢æˆåŠ¨æ€çš„åä½œç½‘ç»œã€‚\n",
    "\n",
    "**æ ¸å¿ƒç‰¹ç‚¹ï¼š**\n",
    "- å»ä¸­å¿ƒåŒ–çš„åä½œæ¨¡å¼\n",
    "- æ™ºèƒ½ä½“é—´çš„ç›´æ¥é€šä¿¡\n",
    "- åŠ¨æ€çš„è§’è‰²åˆ†é…\n",
    "- è‡ªé€‚åº”çš„å·¥ä½œæµç¨‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cqn061bww9a",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 7-13ï¼šAlice å’Œ Bob çš„ç®€å•äº¤äº’ç½‘ç»œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mha9bt3xd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¦–å…ˆå®‰è£… langgraph-swarm åº“\n",
    "# !pip install langgraph-swarm\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph_swarm import create_handoff_tool, create_swarm\n",
    "\n",
    "# è¿™é‡Œæ¨èä½¿ç”¨ SiliconCloud å¹³å°ä¸Šå‚èµ›é‡è¾ƒå¤§ä¸”æ”¯æŒå·¥å…·è°ƒç”¨çš„ä»˜è´¹æ¨¡å‹\n",
    "model = ChatOpenAI(model=\"Qwen/Qwen3-8B\")\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"æ·»åŠ ä¸¤ä¸ªæ•°å­—\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# 1. åˆ›å»ºä¸“ä¸šæ™ºèƒ½ä½“ï¼ˆAlice å’Œ Bobï¼‰ï¼š\n",
    "# ä½¿ç”¨ create_react_agent å®šä¹‰ä¸¤ä¸ªä¸“ä¸šæ™ºèƒ½ä½“ Alice å’Œ Bobã€‚\n",
    "# Alice æ˜¯ä¸€ä½æ•°å­¦ä¸“å®¶ï¼Œæ‹¥æœ‰ 'add' å·¥å…·å’Œä¸€ä¸ªç§»äº¤ç»™ Bob çš„ç§»äº¤å·¥å…·ã€‚\n",
    "alice = create_react_agent(\n",
    "    model,\n",
    "    [add, create_handoff_tool(agent_name=\"Bob\")], # Alice æ‹¥æœ‰ 'add' å·¥å…·å’Œç§»äº¤ç»™ Bob çš„ç§»äº¤å·¥å…·\n",
    "    prompt=\"ä½ æ˜¯ Aliceï¼Œä¸€ä½åŠ æ³•ä¸“å®¶ï¼Œä½¿ç”¨å·¥å…·å®Œæˆæ‰€æœ‰åŠ æ³•ã€‚\",\n",
    "    name=\"Alice\",\n",
    ")\n",
    "\n",
    "# Bob è¯´è¯åƒä¸ªæµ·ç›—ï¼Œå¹¶æ‹¥æœ‰ä¸€ä¸ªç§»äº¤ç»™ Alice ä»¥å¯»æ±‚æ•°å­¦å¸®åŠ©çš„ç§»äº¤å·¥å…·ã€‚\n",
    "bob = create_react_agent(\n",
    "    model,\n",
    "    [create_handoff_tool(agent_name=\"Alice\", description=\"åŠ¡å¿…å°†æ‰€æœ‰æ•°å­¦é—®é¢˜è¯·è½¬ç§»ç»™ Aliceï¼Œå¥¹å¯ä»¥å¸®åŠ©è§£å†³æ•°å­¦é—®é¢˜\")], # Bob æ‹¥æœ‰ä¸€ä¸ªç§»äº¤ç»™ Alice çš„ç§»äº¤å·¥å…·\n",
    "    prompt=\"ä½ æ˜¯ Bobï¼Œä½ è¯´è¯åƒä¸ªæµ·ç›—ã€‚\",\n",
    "    name=\"Bob\",\n",
    ")\n",
    "\n",
    "# 2. åˆ›å»ºç”¨äºå¯¹è¯è®°å¿†çš„å†…å­˜æ£€æŸ¥ç‚¹ï¼š\n",
    "# InMemorySaver ç”¨äºçŸ­æœŸè®°å¿†ï¼Œè¿™å¯¹äºä¿æŒå¯¹è¯çš„è¿ç»­æ€§è‡³å…³é‡è¦ã€‚\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# 3. ä½¿ç”¨ create_swarm åˆ›å»º Swarm å·¥ä½œæµï¼š\n",
    "# create_swarm å‡½æ•°ä½¿ç”¨ Alice å’Œ Bob è®¾ç½® swarm æ¶æ„ã€‚\n",
    "# default_active_agent=\"Alice\" å°† Alice è®¾ç½®ä¸ºæ–°å¯¹è¯çš„èµ·å§‹æ™ºèƒ½ä½“ã€‚\n",
    "workflow = create_swarm(\n",
    "    [alice, bob], # swarm ä¸­çš„æ™ºèƒ½ä½“åˆ—è¡¨\n",
    "    default_active_agent=\"Alice\" # ç”¨äºå¯åŠ¨æ–°å¯¹è¯çš„é»˜è®¤æ™ºèƒ½ä½“\n",
    ")\n",
    "\n",
    "# 4. ä½¿ç”¨æ£€æŸ¥ç‚¹ç¼–è¯‘å·¥ä½œæµï¼š\n",
    "# ç¼–è¯‘ swarm å·¥ä½œæµï¼Œä¼ é€’æ£€æŸ¥ç‚¹ä»¥è¿›è¡Œå†…å­˜ç®¡ç†ã€‚\n",
    "app = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "# 5. åœ¨å¤šè½®å¯¹è¯ä¸­è°ƒç”¨ Swarmï¼š\n",
    "# å¤šæ¬¡è°ƒç”¨ swarmï¼Œæ¨¡æ‹Ÿå¯¹è¯çº¿ç¨‹ã€‚\n",
    "# config={\"configurable\": {\"thread_id\": \"1\"}} ç¡®ä¿æ¶ˆæ¯åœ¨åŒä¸€å¯¹è¯çº¿ç¨‹ä¸­è¢«è·Ÿè¸ªã€‚\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "turn_1 = app.invoke( # ç¬¬ä¸€è½® - ç”¨æˆ·æƒ³å’Œ Bob è¯´è¯\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"æˆ‘æƒ³å’Œ Bob è¯´è¯\"}]},\n",
    "    config,\n",
    ")\n",
    "print(turn_1[\"messages\"][-1].content) # ç¬¬ä¸€è½®çš„è¾“å‡º\n",
    "turn_2 = app.invoke( # ç¬¬äºŒè½® - ç”¨æˆ·æå‡ºä¸€ä¸ªæ•°å­¦é—®é¢˜\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"5 + 7 ç­‰äºå¤šå°‘ï¼Ÿ\"}]},\n",
    "    config,\n",
    ")\n",
    "print(turn_2[\"messages\"][-1].content) # ç¬¬äºŒè½®çš„è¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kjpeq6s8dlo",
   "metadata": {},
   "source": [
    "## 7.3 æƒ…å¢ƒæ„ŸçŸ¥æ™ºèƒ½ä½“ï¼šåå°ä¸»åŠ¨å¼ AI æ¶æ„ä¸æ¨¡å¼\n",
    "\n",
    "ä¼ ç»Ÿçš„äººå·¥æ™ºèƒ½åº”ç”¨ç¨‹åºï¼Œå°¤å…¶æ˜¯é‚£äº›åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) çš„åº”ç”¨ç¨‹åºï¼Œä¸»è¦é‡‡ç”¨åŸºäºèŠå¤©çš„ç”¨æˆ·ä½“éªŒã€‚è™½ç„¶èŠå¤©æ¨¡å¼çš„ç”¨æˆ·å‹å¥½ä¸”æ˜“äºå®æ–½ï¼Œä½†å®ƒæœ¬è´¨ä¸Šå°†å‘èµ·å’Œç®¡ç†äº¤äº’çš„è´£ä»»å®Œå…¨æ”¾åœ¨äººç±»ç”¨æˆ·èº«ä¸Šã€‚\n",
    "\n",
    "ä¸€ç§å˜é©æ€§çš„æ›¿ä»£æ–¹æ¡ˆåœ¨äºæƒ…å¢ƒæ„ŸçŸ¥æ™ºèƒ½ä½“ï¼ˆAmbient Agentï¼‰æ¶æ„ã€‚è¿™äº›æ¶æ„è®¾æƒ³ AI æ™ºèƒ½ä½“åœ¨åå°ä¸»åŠ¨ä¸”æŒç»­åœ°è¿è¡Œï¼Œå‹¤å‹‰åœ°ç›‘æ§ç›¸å…³ä¿¡æ¯æµå¹¶è‡ªä¸»åœ°å¯¹é‡è¦äº‹ä»¶åšå‡ºååº”ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eu16upd6mrf",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 7-14ï¼šLangGraph ä¸­å¯ç”¨çš„äººæœºç¯è·¯äº¤äº’ç»“æ„ä½“\n",
    "\n",
    "è®©æˆ‘ä»¬å®šä¹‰ç”¨äºå®ç°äººæœºç¯è·¯äº¤äº’çš„æ•°æ®ç»“æ„ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70w65gnuvw",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal, Optional, Union\n",
    "\n",
    "# HumanInterruptConfigï¼šå®šä¹‰äººå·¥ä¸­æ–­æ“ä½œçš„é…ç½®é€‰é¡¹ã€‚\n",
    "class HumanInterruptConfig(TypedDict):\n",
    "    allow_ignore: bool  # allow_ignoreï¼šå¸ƒå°”å€¼ï¼Œæ˜¯å¦å…è®¸ç”¨æˆ·å¿½ç•¥ä¸­æ–­ã€‚\n",
    "    allow_respond: bool # allow_respondï¼šå¸ƒå°”å€¼ï¼Œæ˜¯å¦å…è®¸ç”¨æˆ·å‘é€è‡ªç”±æ ¼å¼çš„å“åº”ã€‚\n",
    "    allow_edit: bool    # allow_editï¼šå¸ƒå°”å€¼ï¼Œæ˜¯å¦å…è®¸ç”¨æˆ·ç¼–è¾‘æ“ä½œå‚æ•°ã€‚\n",
    "    allow_accept: bool  # allow_acceptï¼šå¸ƒå°”å€¼ï¼Œæ˜¯å¦å…è®¸ç”¨æˆ·æŒ‰åŸæ ·æ¥å—æ“ä½œã€‚\n",
    "\n",
    "\n",
    "# ActionRequestï¼šå®šä¹‰å‘äººç±»è¯·æ±‚çš„æ“ä½œã€‚\n",
    "class ActionRequest(TypedDict):\n",
    "    action: str      # actionï¼šå­—ç¬¦ä¸²ï¼Œæ“ä½œçš„æè¿°æ€§åç§°æˆ–æ ‡é¢˜ã€‚\n",
    "    args: dict       # argsï¼šå­—å…¸ï¼Œä¸æ“ä½œå…³è”çš„å‚æ•°ï¼ˆä¾‹å¦‚ï¼Œå·¥å…·è°ƒç”¨å‚æ•°ï¼‰ã€‚\n",
    "\n",
    "\n",
    "# HumanInterruptï¼šè¡¨ç¤ºäººå·¥ä¸­æ–­è¯·æ±‚çš„ä¸»è¦æ¨¡å¼ã€‚\n",
    "class HumanInterrupt(TypedDict):\n",
    "    action_request: ActionRequest         # action_requestï¼šActionRequestï¼Œæœ‰å…³è¯·æ±‚æ“ä½œçš„è¯¦ç»†ä¿¡æ¯ã€‚\n",
    "    config: HumanInterruptConfig         # configï¼šHumanInterruptConfigï¼Œäººå·¥å“åº”çš„é…ç½®é€‰é¡¹ã€‚\n",
    "    description: Optional[str]          # descriptionï¼šå¯é€‰å­—ç¬¦ä¸²ï¼Œä¸­æ–­çš„è¯¦ç»†æè¿°ï¼Œå¯ä»¥æ˜¯ Markdown æ ¼å¼ã€‚\n",
    "\n",
    "\n",
    "# HumanResponseï¼šä» Agent Inbox UI æ¥æ”¶çš„äººå·¥å“åº”æ¨¡å¼ã€‚\n",
    "class HumanResponse(TypedDict):\n",
    "    type: Literal['accept', 'ignore', 'response', 'edit'] # typeï¼šLiteral Stringï¼Œæ¥è‡ªç”¨æˆ·çš„å“åº”ç±»å‹ï¼ˆacceptã€ignoreã€responseã€editï¼‰ã€‚\n",
    "    args: Union[None, str, ActionRequest]                # argsï¼šUnion[None, String, ActionRequest]ï¼Œä¸å“åº”å…³è”çš„å‚æ•°ï¼Œæ ¹æ®\"type\"è€Œå˜åŒ–ã€‚\n",
    "                                                        #     - å¯¹äº\"accept\"å’Œ\"edit\"ï¼šActionRequestï¼Œå…¶ä¸­åŒ…å«å¯èƒ½å·²ä¿®æ”¹çš„å‚æ•°ã€‚\n",
    "                                                        #     - å¯¹äº\"response\"ï¼šåŒ…å«ç”¨æˆ·æ–‡æœ¬å“åº”çš„å­—ç¬¦ä¸²ã€‚\n",
    "                                                        #     - å¯¹äº\"ignore\"ï¼šNoneã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ie9v4jfm3",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ 7-15ï¼šåœ¨ LangGraph å›¾å‡½æ•°ä¸­ä½¿ç”¨ HumanInterrupt å’Œ HumanResponse\n",
    "\n",
    "ä»¥ä¸‹ç¤ºä¾‹æ¼”ç¤ºäº†å¦‚ä½•åœ¨ LangGraph å·¥ä½œæµä¸­å®ç°äººæœºç¯è·¯äº¤äº’ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hhw7p6t8hc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal, Optional, Union\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import interrupt\n",
    "from langchain_core.messages import ToolMessage, HumanMessage, AIMessage\n",
    "\n",
    "# å‡è®¾è¿™äº›å·¥å…·åœ¨å…¶ä»–åœ°æ–¹å®šä¹‰\n",
    "tools_by_name = {\n",
    "    \"hypothetical_tool\": lambda **kwargs: f\"å·¥å…·æ‰§è¡Œç»“æœ: {kwargs}\"\n",
    "}\n",
    "\n",
    "# å®šä¹‰å›¾çŠ¶æ€ï¼Œç»§æ‰¿æ¶ˆæ¯çŠ¶æ€ä»¥ç”¨äºå¯¹è¯å†å²è®°å½•\n",
    "class AgentState(TypedDict):\n",
    "    messages: list\n",
    "    tool_calls: list\n",
    "\n",
    "# å®šä¹‰å¯èƒ½è§¦å‘äººå·¥ä¸­æ–­çš„å›¾å‡½æ•°\n",
    "def agent_node(state: AgentState):\n",
    "    \"\"\"æ™ºèƒ½ä½“èŠ‚ç‚¹ï¼Œå†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·æˆ–è¯·æ±‚äººå·¥è¾“å…¥ã€‚\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1] if messages else None\n",
    "\n",
    "    # å‡è®¾æ™ºèƒ½ä½“å†³å®šè°ƒç”¨å·¥å…·å¹¶å…·æœ‰å·¥å…·è°ƒç”¨è¯¦ç»†ä¿¡æ¯\n",
    "    tool_call_name = \"hypothetical_tool\"\n",
    "    tool_call_args = {\"input_arg\": \"example_value\"}\n",
    "\n",
    "    # æ„å»º HumanInterrupt å¯¹è±¡\n",
    "    request: HumanInterrupt = {\n",
    "        \"action_request\": {\n",
    "            \"action\": tool_call_name, # æ“ä½œåç§°æ˜¯å·¥å…·åç§°\n",
    "            \"args\": tool_call_args  # æ“ä½œå‚æ•°æ˜¯å·¥å…·å‚æ•°\n",
    "        },\n",
    "        \"config\": {\n",
    "            \"allow_ignore\": True, # å…è®¸ç”¨æˆ·å¿½ç•¥å·¥å…·è°ƒç”¨\n",
    "            \"allow_respond\": True, # å…è®¸ç”¨æˆ·æä¾›è‡ªç”±æ ¼å¼çš„å“åº”\n",
    "            \"allow_edit\": True,  # å…è®¸ç”¨æˆ·ç¼–è¾‘å·¥å…·å‚æ•°\n",
    "            \"allow_accept\": True # å…è®¸ç”¨æˆ·æŒ‰åŸæ ·æ¥å—å·¥å…·è°ƒç”¨\n",
    "        },\n",
    "        \"description\": f\"æ™ºèƒ½ä½“å»ºè®®ä½¿ç”¨å‚æ•°ï¼š`{tool_call_args}` è°ƒç”¨å·¥å…·ï¼š`{tool_call_name}`ã€‚ ä½ æ‰¹å‡†å—ï¼Ÿ\", # Agent Inbox UI çš„æè¿°\n",
    "    }\n",
    "\n",
    "    # è°ƒç”¨ interrupt å‡½æ•°ï¼Œåœ¨åˆ—è¡¨ä¸­ä¼ é€’ HumanInterrupt è¯·æ±‚\n",
    "    response_list = interrupt([request])\n",
    "    response = response_list[0] if response_list else None # ä»åˆ—è¡¨ä¸­æå–ç¬¬ä¸€ä¸ªå“åº”\n",
    "\n",
    "    if response:\n",
    "        if response['type'] == \"accept\":\n",
    "            # ç”¨æˆ·æ¥å—äº†å·¥å…·è°ƒç”¨ï¼Œç»§ç»­æ‰§è¡Œå·¥å…·\n",
    "            tool_result = tools_by_name[tool_call_name](**response['args']['args']) # ä½¿ç”¨ï¼ˆå¯èƒ½å·²ä¿®æ”¹çš„ï¼‰å‚æ•°æ‰§è¡Œå·¥å…·\n",
    "            output_message = ToolMessage(content=str(tool_result), tool_call_id=\"example_id\") # ä½¿ç”¨ç»“æœåˆ›å»º ToolMessage\n",
    "        elif response['type'] == \"edit\":\n",
    "            # ç”¨æˆ·ç¼–è¾‘äº†å·¥å…·è°ƒç”¨å‚æ•°ï¼Œä½¿ç”¨ç¼–è¾‘åçš„å‚æ•°æ‰§è¡Œå·¥å…·\n",
    "            edited_args = response['args']['args'] # ä» ActionRequest ä¸­æå–ç¼–è¾‘åçš„å‚æ•°\n",
    "            tool_result = tools_by_name[tool_call_name](**edited_args) # ä½¿ç”¨ç¼–è¾‘åçš„å‚æ•°æ‰§è¡Œå·¥å…·\n",
    "            output_message = ToolMessage(content=str(tool_result), tool_call_id=\"example_id\") # ä½¿ç”¨ç»“æœåˆ›å»º ToolMessage\n",
    "        elif response['type'] == \"response\":\n",
    "            # ç”¨æˆ·æä¾›äº†æ–‡æœ¬å“åº”ï¼Œæ®æ­¤å¤„ç†\n",
    "            user_response_text = response['args'] # æå–ç”¨æˆ·çš„æ–‡æœ¬å“åº”\n",
    "            output_message = AIMessage(content=f\"ç”¨æˆ·å“åº”ï¼š{user_response_text}ã€‚ æ ¹æ®å“åº”ç»§ç»­è¿›è¡Œã€‚\") # åˆ›å»º AIMessage ä»¥ç¡®è®¤å“åº”\n",
    "        elif response['type'] == \"ignore\":\n",
    "            # ç”¨æˆ·å¿½ç•¥äº†ä¸­æ–­ï¼Œæ®æ­¤å¤„ç†\n",
    "            output_message = AIMessage(content=\"äººå·¥ä¸­æ–­è¢«å¿½ç•¥ã€‚ ç»§ç»­è¿›è¡Œï¼Œä¸è¿›è¡Œå·¥å…·è°ƒç”¨ã€‚\") # åˆ›å»º AIMessageï¼ŒæŒ‡ç¤ºä¸­æ–­è¢«å¿½ç•¥\n",
    "        else:\n",
    "            output_message = AIMessage(content=\"æœªçŸ¥çš„äººå·¥å“åº”ç±»å‹ã€‚\") # å¤„ç†æ„å¤–çš„å“åº”ç±»å‹\n",
    "    else:\n",
    "        # æœªæ”¶åˆ°å“åº”ï¼ˆä¾‹å¦‚ï¼Œä¸­æ–­å¤„ç†è¶…æ—¶æˆ–é”™è¯¯ï¼‰\n",
    "        output_message = AIMessage(content=\"æœªæ”¶åˆ°äººå·¥å“åº”ï¼Œç»§ç»­è¿›è¡Œï¼Œä¸è¿›è¡Œå¹²é¢„ã€‚\") # å¤„ç†æœªæ”¶åˆ°å“åº”çš„æƒ…å†µ\n",
    "\n",
    "    return {\"messages\": [output_message]} # è¿”å›æ›´æ–°çš„æ¶ˆæ¯çŠ¶æ€\n",
    "\n",
    "\n",
    "# æ„å»º LangGraph å·¥ä½œæµ\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"agent_step\", agent_node)\n",
    "builder.add_edge(START, \"agent_step\")\n",
    "builder.add_edge(\"agent_step\", END)\n",
    "\n",
    "# ç¼–è¯‘å·¥ä½œæµ\n",
    "workflow = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wb13gdsv69o",
   "metadata": {},
   "source": [
    "## ğŸ“š æœ¬ç« æ€»ç»“\n",
    "\n",
    "é€šè¿‡æœ¬ç« çš„å­¦ä¹ ï¼Œæˆ‘ä»¬æ·±å…¥æ¢ç´¢äº† AI æ™ºèƒ½ä½“ç³»ç»Ÿçš„æ¶æ„è®¾è®¡ä¸èŒƒå¼åº”ç”¨ï¼Œä»åŸºç¡€çš„æ™ºèƒ½ä½“å·¥ä½œæµæ¨¡å¼ï¼ˆæç¤ºé“¾ã€è·¯ç”±ã€å¹¶è¡ŒåŒ–ã€åè°ƒå™¨-å·¥ä½œè€…ã€è¯„ä¼°å™¨-ä¼˜åŒ–å™¨ï¼‰åˆ°å¤æ‚çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ¶æ„ï¼ˆä¸»ç®¡ã€å±‚æ¬¡åŒ–ã€ç½‘ç»œæ¶æ„ï¼‰ï¼Œå†åˆ°å‰ç»æ€§çš„æƒ…å¢ƒæ„ŸçŸ¥æ™ºèƒ½ä½“æ¶æ„ã€‚æˆ‘ä»¬æŒæ¡äº† LangGraph ä¸­çš„å…³é”®æŠ€æœ¯å®ç°ï¼ŒåŒ…æ‹¬ Graph API ä¸ Functional API çš„çµæ´»åº”ç”¨ã€Send API çš„åŠ¨æ€å·¥ä½œè€…åˆ›å»ºã€ç»“æ„åŒ–è¾“å‡ºä¸çŠ¶æ€ç®¡ç†ã€ä»¥åŠäººæœºç¯è·¯äº¤äº’æœºåˆ¶ï¼Œä¸ºæ„å»ºå¤æ‚ã€é«˜æ•ˆä¸”å¯æ‰©å±•çš„æ™ºèƒ½ä½“åº”ç”¨ç³»ç»Ÿå¥ å®šäº†åšå®çš„æŠ€æœ¯åŸºç¡€ã€‚åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†è¿›ä¸€æ­¥æ¢è®¨æ™ºèƒ½ä½“çš„é«˜çº§åº”ç”¨åœºæ™¯å’Œä¼˜åŒ–ç­–ç•¥ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
